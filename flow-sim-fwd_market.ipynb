{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on condition of notebook\n",
    "\n",
    "I have implemented a new methodology and have the algorithm set up so that either old algorithm or new algorithm can be used.  Next step is to get rid of the old approach.  \n",
    "\n",
    "Since the new approach load data directly from dataframes, it should be possible to get rid of much of the OrderBook material, keeping only the dataframes which generate the orders.  This will require making some changes to calculate trading volume and uncleared quantities from the bk.bks, not the OrderBook itself.\n",
    "\n",
    "The new approach has almost the same speed as the old (maybe 1-2 percent slower due to more bells and whistles).  The new approach is more configurable, so new dense or sparse books can be added.  I have not gotten the sparse and dense books to work yet.\n",
    "\n",
    "Steps needed:\n",
    "\n",
    "1. Redo functions to calculate volume and market statistics to use bk.bks.\n",
    "\n",
    "2. Take legacy material out of OrderBook class, leaving behind only dataframes.\n",
    "\n",
    "3. Take legacy material out of estimation, leaving only bk.bks.\n",
    "\n",
    "4. Add and debug positive numbers of generic sparse orders and dense orders.  This cannot be done until legacy material taken out of optimization.\n",
    "\n",
    "5. Return calculated market results: x, p, pa, q-x\n",
    "\n",
    "5. Figure out how to pass market result back to dataframes in order book.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Our Testing Strategy\n",
    "\n",
    "After extensive testing, the results of which are not presented here, we decided to do quadratic programming calculations using the Python package Pytorch.\n",
    "\n",
    "The quadratic programming algorithm was originally tested in several ways:\n",
    "\n",
    "### Commercial Packages\n",
    "\n",
    "We considered using free academic versions of commercial packages like Gurobi or Mosek but found the interface too clunky, too slow, and too hard to learn.  \n",
    "\n",
    "One issue is that our quadratic programming problem has \"easy\" assumptions (diagonal positive definite quadratic matrix and box inequality constraints) but is \"big\" (hundreds of equality constraints and hundreds of thousands or millions of inequality constraints).\n",
    "\n",
    "Gurobi says is does not handle sparse matrices and uses cpus rather than gpus.  Maybe this is just the interface, and we did not figure out how to use it properly.\n",
    "\n",
    "Using Gurobi or other commercial packages is a possiblity for the future.\n",
    "\n",
    "\n",
    "### Cvxopt Package\n",
    "\n",
    "The Cvxopt package uses an interior point algorithm which works well. It has several disadvantages:\n",
    "\n",
    "1. It uses its own sparse and dense matrix algebra language, which has its own commands (with difficult conversions back and forth to numpy/scipy).\n",
    "\n",
    "2. It is difficult to edit code to make the algorithm work differently.  Cvxopt does offer the option to supply custom solvers. We used this option to solve the linearized system with a Cholesky decomposition of a matrix whose dimensions are the number of assets.  The Cvxopt default would try to solve an impossible gigantic system with a bigger Cholesky decomposition.\n",
    "\n",
    "3. It does not perform calculations on a gpu.\n",
    "\n",
    "4. It is slower than alternatives. Perhaps the sparse matrix calculations are not parallelized???\n",
    "\n",
    "### Numpy and Scipy\n",
    "\n",
    "A variation on the Cvxopt algorithm was implemented in Numpy and Scipy direclty (using a variation of the algorithm described by Vandenberghe (2011???). This provided more flexibility but had several shortcomings: \n",
    "\n",
    "1. Numpy does not seem to parallelize element-by-element operations on vectors, even though they are parallelized on matrix-matrix operations (using mkl). \n",
    "\n",
    "2. Scipy uses a single core for sparse matrix and vector operations. \n",
    "\n",
    "3. Numpy and Scipy do not use a gpu.\n",
    "\n",
    "### OSQP\n",
    "\n",
    "OSQP is a gradient-based optimization algorithm for quadratic programming. In general first-order methods (gradient) can achieve quick progress early in the optimization process, then slow down as they converge to equilibrium. In contrast, second order methods (based on hessians or linearizing first-oder conditions, such as interior point methods), converge very fast (quadratically) when close to the optimum. \n",
    "\n",
    "We downloaded the OSQP algorithm from the Stellato website and also wrote our own version based on the paper by Stellato et al. In both cases, the algorithm slowed down greatly before getting close to equilibrium prices. Even after thousands of iterations, it was not close to convergence.\n",
    "\n",
    "For our problem, it is necessary to calculate market-clearing prices accurately, even for very poorly conditioned problems (low liquidity limit order books). This rules out OSQP.\n",
    "\n",
    "More generally, each iteration of the interior point method is surprisingly simple. It requires mostly element-by-element calculations plus a few sparse-matrix--vector products, except for two bigger ones:  a Cholesky decomposition and the construction of the symmetric positive definite matrix to be decomposed. The number of rows and columns of this matrix is equal to the number of assets.  If the number of assets is small enough, Cholesky decomposition seems to be the best approach.\n",
    "\n",
    "For a very large number of assets, some other way of solving a linear system will be needed, perhaps conjugate gradient method with some variations?\n",
    "\n",
    "### Gradient method\n",
    "\n",
    "We wrote our own bespoke gradient method and also tried various Scipy optimizers using gradient-like methods.  \n",
    "\n",
    "None of these worked efficiently. These methods have two problems:\n",
    "\n",
    "1. Gradient methods do not achieve enough accuracy.\n",
    "\n",
    "2. Gradient methods do not make smart decisions about search directions because they use local rather than global information.\n",
    "\n",
    "Second-order methods in Scipy were too hard to implement and would also suffer from Scipy not parallelizing sparse matrix-vector products.\n",
    "\n",
    "For example, we tried using conjugate gradient method to solve linearized system.  This did not work well because we want our algorithm to deal well with poorly conditioned linear approximations. Conjugate gradient performs poorly in such cases for two reasons: it takes many iterations, and numerical error accumulates over these many iterations.\n",
    "\n",
    "### Cupy\n",
    "\n",
    "Cupy does calculations on a gpu.  We found it slower and less flexible than Pytorch (discussed next).\n",
    "\n",
    "### Qpsolvers\n",
    "\n",
    "Qpsolvers is a python package which interfaces between generic quadratic programming problems and various quadratic programming packages, including both free and commercial ones.\n",
    "\n",
    "We could not get this package to improve our approach.\n",
    "\n",
    "\n",
    "### Pytorch\n",
    "\n",
    "Pytorch is has a language for arrays which mimics Numpy.  It has several advantages: \n",
    "\n",
    "1. It parallelizes element-by-element calculations on vectors, both on the cpu and gpu. \n",
    "\n",
    "2. It uses multiple cpu and gpu cores for other operations, including some sparse ones (???).\n",
    "\n",
    "3. It makes it easy to do calculations on a gpu. \n",
    "\n",
    "4. The cpu and gpu calculations are fast. \n",
    "\n",
    "Pytorch has other advantages not relevant for this project. It has automatic differentiation, which is useful in optimization problems requiring complicated gradient and hessian calculations.  It also has a convenient optimization infrastructure, which is useful for neural nets and machine learning.  This optimization framework has algorithms for feeding data to optimizers efficiently.\n",
    "\n",
    "Pytorch has disadvantages, which can be overcome: \n",
    "\n",
    "1. There is more overhead than Numpy for each call to the vectorized array operations. This can be reduced (or even eliminated) by compiling Pytorch code with torchscript.\n",
    "\n",
    "2. Sparse matrix-vector products are not implemented on the cpu using Windows (This requires a work-around function described below).\n",
    "\n",
    "After extensive testing, the details of which are not in this notebook, we discovered that:\n",
    "\n",
    "1. On cpus, pytorch is somewhat faster than cvxopt and numpy/scipy.  Pytorch can be further speeded up by compiling with torchscript, but the speedup is typically 30 percent or less.  The cpu calculations are fastest using two cores. More than two cores slows things down. This is true with numpy and scipy as well.  This presumably results from overhead from using multiple cores combined with the sequential nature of the optimization, which limits parallel calculations.\n",
    "\n",
    "2. On the gpu, Pytorch is about 3-5 times faster than Pytorch on the cpu (relatively faster for bigger problems with more orders).  Pytorch is faster on both element-by-element calculations and sparse matrix-matrix and matrix-vector calculations. The quadratic programming algorithm does not have many dense matrix-matrix calculations, but they are faster on the gpu than on cpu as well.\n",
    "\n",
    "Why does pytorch work so well? Pytorch seems to have its own programming language written in C/C++. This language has optimized algorithms for array calculations. This achieves speed and also overcomes Python's global interpreter lock (GIL), making parallelization easier.  It seems to have good algorithms for the gpu. The gpu algorithms are multiple times faster than cpu algorithms for element-by-element calculations, matrix-vector products, matrix-matrix products.  Its sparse gpu calculations are multiple times faster than sparse cpu calculations (contrary to conventional wisdom???). \n",
    "\n",
    "It can compile code on-the-fly with torchscript. This presumably gives C/C++ speeds to algorithms.  With torchscript, pytorch also seems to optimize code on-the-fly by analyzing it as it executes, then recompiling in a manner that speeds up calculations when it detects, for example, that array sizes are constant.  This can backfire in tests which change the size of arrays every few iterations but otherwise generally works well.  It does, however, require running tests three or more times to see maximum benefits. \n",
    "\n",
    "What is the overall computer science strategy behind Pytorch?  We are not sure but here is what we think based on experience and reading online discussions: Two big trends are (1) lazy evaluation based on saving computation graphs, (2) automatic differentiation, (3) parallel calculations, and (4) graphics cards. In general, there is a tradeoff between compiling things in advance and waiting as late as possible into runtime to compile things.  There is also a tradeoff between compiling templates, which can become complicated, and keeping the number of types small by not using many templates. Pytorch takes the approach of having a small number of types (not using templates) and compiling as late as possible while things are running. Having a small number of types might be making it possible to optimize each type better. Indeed, torchscript sometimes seems to wait until a function has run a couple of times, then recompiles it on the fly based on how it is actually used rather than how it might theoretically be used. This allows dynamic optimizations which would not be possible otherwise.\n",
    "\n",
    "Torchscript is a limited language,  with significant constraints on the kinds of code which it can deal with. This explains why the quadratic programming algorithm below is broken into some otherwise nonintuitive steps. For example:\n",
    "\n",
    "1. It also does not allow very convenient printing (presumably because its main uses case does not involve debugging).  \n",
    "\n",
    "2. It likes to type things in a manner understandable by C/C++. Thus, it like dictionaries of objects which are the same type.  This requires workarounds.\n",
    "\n",
    "3. It does not deal with classes very well if the classes define their own functions. In the quadratic programming algorithm below, there is extensive use of functions where classes would otherwise naturally be used.  For example, it would be natural to define linear operators as classes, but this does not seem to work in pytorch.\n",
    "\n",
    "4. It handles torch.tensor types but not numpy and scipy types.\n",
    "\n",
    "The quadratic programming algorithm below requires Pytorch but offers several options, including:\n",
    "\n",
    "1. Switching between cpu and gpu to compare performance and numerical results.\n",
    "\n",
    "2. Turning torchscript (torch.jit.script) on or off. Nevertheless, even when torchscript is not used, the code is essentially the same, conforming to torchscript's simplistic requirements.\n",
    "\n",
    "3. Switching between float32 and float64. We find that float32 is not accurate enough and sometimes gets stuck due to rounding error. But it is twice as fast as float64.\n",
    "\n",
    "### Summary\n",
    "\n",
    "In what follows, there are two steps:\n",
    "\n",
    "1. Simulating an order book:  This is done in numpy since the first version was in numpy, but it could be done more quickly in pytorch.\n",
    "\n",
    "2. Quadratic program to calculate market clearing prices and quantities:  This is done in Pytorch due to computation efficiency, especially using the gpu. \n",
    "\n",
    "Switching from the numpy order book to the pytorch optimization requires an interface to convert objects from one type to another.\n",
    "\n",
    "### Note on QP inputs\n",
    "\n",
    "Quadratic programming algorithms often use a standard form which stacks inequality constraints on top of each other.  Instead of using this approach, our current approach treats the less-than constraints separately from the greater-than constraints, mimicking the mu and lambda notation in the paper rather than the standard quadratic programming approach with stacked constraints, called say z.  We have tried the standard approach as well.  Our approach is perhaps slightly slower since it involves twice as many Python function calls to do unstacked operations. We use it because it is easier to map the approach to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO List\n",
    "\n",
    "For further experimentation, these are possible directions:\n",
    "\n",
    "1. Set up specific matrix-multiplication functions similar to the function for generating the AQA matrix. This would make the algorithm cleaner and easier to follow.\n",
    "\n",
    "2. Add a larger number of user-defined portfolios to the order book. This would increase the number of registered portfolios by an enormous amount.  Mina suggests generating random portolios with a random number of assets in the portfolios. This allows measuring the sensitivity of the algorithm's execution time to the number of registered portfolios. If the portfolios are truly random, PK thinks there may be plenty of liquidity for almost all assets.  This might make a conjugate gradient method more efficient for solving the underlying linear system.\n",
    "\n",
    "3. Put the individual-asset orders and pairs-trade orders into separate arrays.  The current approach stacks them into one array but needs to sort by number of portfolios and needs to carry around an extra parameter to remember the boundary between the sorted groups.  We might have separate sparse arrays for orders with 1, 2, 3,...,k portfolios, then put any orders with a larger number of assets into a separate category.  We need to figure out two numerical boundaries: When is it efficient to use the bespoke method for generating AQA, then after that when to shift from sparse to dense calculations.  For example, we might use a bespoke method for 1, 2, or 3-portfolio orders, use sparse arrays for 4, 5,...,25-portfolios, and dense arrays for 26+ portfolios per order.  This example would involve 5 arrays: 1-portfolio orders (like now), 2-portfolio orders (like now), 3-portfolio orders (need to add), 4-25 portfolio orders (sparse arrays), 25+ portfolio orders (dense arrays).  One advantage of separate arrays for these different portfolios is that the gpu may perform calculations at the same time since calculations are asynchronous. This, of course, assumes that the gpu is not totally occupied already.  The small P1000 gpu on PK's laptop has far fewer cores than newer gpus, so newer gpus may be much faster doing these calculations.\n",
    "\n",
    "4. Develop a strategy for dealing with many assets, say N > 2000.  This would be relevant for corporate bond markets or for markets for all ticker symbols or all stock options simultaneously.  Presumably, Cholesky decomposition, which is an $N^3$ algorithm, will not work well because it offers limited opportunities for parallelization.  Another possibility might be conjugate gradient, but it will have to deal with poorly conditioned problems associated with very low liquidity for very illiquid assets.  Perhaps preconditioning with a Cholesky decomposition or approximation to a Cholesky decomposition might work. We deal with poor conditioning by adding a small amount of exchange trading to make linear approximations better conditioned. Inside the algorithm, another approach used is to add small quantities to the diagonal of the positive defininte matrix to be decomposed.  This makes it more positive definite, so that the Cholesky decomposition does not fail. We need to investigate more carefully whether some kind of dynamic adjustment to exchange inventories and adding elements to the diagonal can improve the performance of the algorithm.  If Cholesky decomposition is not used, the same approach could be used in the context of, say, the conjugate gradient method.  This is related to the problem of handling the rare cases when the algorithm gets stuck. This seems to be related to poor conditioning of the \"liquidity matrix\" in the linear system which needs to be solved.  In general, it can be \"fixed\" by adding more exchange trading. Adding more to the diagonal may or may not work since the resulting search direction may not be good enough. \n",
    "\n",
    "5. Figure out a good way to warm-start an interior point method.  This seems to be a difficult or even impossible problem, based on cursory look at literature on google scholar.  In this notebook, we do have an algorithm which starts iterations using float32 (for speed), then warm-starts when switching to float64 for the final iterations (for accuracy). This sometimes does not work well, perhaps due to rounding error making the float32 approximate solution, used as a warm start the float64 calculations, too far from the central path needed for the float64 calculations.\n",
    "\n",
    "6.  Try free versions of commercial solvers such as Gurobi or Mosek.  The key issues seem to be overcoming a slow interface (which checks the form of the problum), using sparse arrays, and using gpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "This notebook runs runs in an environment created with Anaconda 4.10 using the following conda commands (approximately): \n",
    "\n",
    "**conda create -c defaults --name my_env_name numpy scipy matplotlib pandas numba notebook threadpoolctl tqdm conda**\n",
    "\n",
    "**conda activate my_env_name**\n",
    "\n",
    "**conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch**\n",
    "\n",
    "The first command installs Python from the default directory, which automatically makes numpy use *mkl*. The third command use *cudatoolkit* version 11.3, but another version should probably work as well.  \n",
    "\n",
    "NB: Using more cores by setting GLOBAL_NUM_THREADS = \"8\" instead of GLOBAL_NUM_THREADS = \"1\" may slow things down. \n",
    "The best performance might be obtained with GLOBAL_NUM_THREADS = \"2\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings\n",
    "\n",
    "##### NOTEBOOK_USER\n",
    "\n",
    "This setting currently only affects CSV_PATH, LATEX_PATH, and NAME_SUFFIX, but it can be used for any settings which vary across users.\n",
    "\n",
    "##### RUN_TYPE\n",
    "\n",
    "1. Use **RUN_TYPE = 'workstation'** to reproduce the results in the paper on a workstation.  For the results in the paper, the workstation had an AMD Ryzen Threadripper 3960X processor, 24 cores running at 3.8GHz, and 128GB of memory running at 3600MHz.  This may take 5--6 hours.\n",
    "\n",
    "2. Use **RUN_TYPE = 'laptop'** to produce more limited results than in the paper. This may take 3 hours on a laptop at 2.0Ghz.\n",
    "\n",
    "3. Use **RUN_TYPE = 'test'** for testing to make sure the notebook runs properly. This should take a few minutes.\n",
    "\n",
    "##### CSV_PATH and LATEX_PATH\n",
    "\n",
    "Set to the local directory to which simulation results and latex figures and tables are saved.\n",
    "\n",
    "##### NSEED\n",
    "\n",
    "Change to generate different simulations.\n",
    "\n",
    "##### NAME_SUFFIX\n",
    "\n",
    "This suffix is placed into output files containing simulation results.  Results will have time stamp in name anyway. This can be used to identify a group of simulations more easily, but it does not need to be changed.\n",
    "\n",
    "##### NUM_PRINT\n",
    "\n",
    "This is an integer defining how much output to print, corresponding to number of iterations to print output results. If zero, minimal output is printed. A good value is 1 or 2.\n",
    "\n",
    "##### NUM_THREADS\n",
    "\n",
    "Set to a machine specific number based on number of cores available or based on restriction to say one or two cores.\n",
    "\n",
    "##### GLOBAL_NUM_THREADS\n",
    "\n",
    "This does not need to be changed. It is used with *os.environ[...]* two cells below to set maximum number of threads or cores for various packages.\n",
    "\n",
    "##### B_USE_PYTORCH = True --- This option is no longer used\n",
    "\n",
    "This will use pytorch rather than numpy for the quadratic program.  One advantage of pytorch on the cpu is that it seems to use multiple cores is situations where numpy uses only one core, such as element-by-element operations.  But pytorch seems to have more overhead than numpy for each operation.\n",
    "\n",
    "##### B_USE_GPU = True\n",
    "\n",
    "If using pytorch, setting to true tells pytorch to move the quadratic program algorithm to the gpu.  This seems to speed up execution time by a factor of about 3.\n",
    "\n",
    "Experimentation suggests that a gpu with 4 GB of memory can handle problems with about 5 million orders; a gpu with 8 GB of memory can handle 10 million orders.  If a memory overflow error stops execution, it is necessary to restart the notebook to free up the memory.\n",
    "\n",
    "##### B_TORCHSCRIPT_JIT = False\n",
    "\n",
    "If set to true, this tells pytorch to compile the code.  In tests, this reduces execution time by about 15 percent. A big problem is that if the number of assets or number of orders changes, then the code is recompiled.  This is a big issue when doing the 500 simulations for the figures in which every simulation has a different number of orders or assets; the computation times are very high because they include compile times which are much greater than execution times.  Therefore, I have set this to False as a default setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_USER = 'RZ'\n",
    "#NOTEBOOK_USER = 'PK'\n",
    "#USER = 'DM'\n",
    "\n",
    "# RUN_TYPE = 'workstation'\n",
    "# RUN_TYPE = 'laptop'\n",
    "RUN_TYPE = 'test'  # for quick testing. The value can be 'test' or anything other than 'workstation' or 'laptop'\n",
    "\n",
    "# Set paths for saving results to hard disk:\n",
    "'''\n",
    "CSV_PATH = (\"/home/dmalec/smart_finance/outputs/csv/\" if NOTEBOOK_USER == 'DM'\n",
    "        else \"C:/Users/akyle/ask/code/flow-trading-csv/\") if NOTEBOOK_USER == 'PK' else None\n",
    "\n",
    "LATEX_PATH = (\"/home/dmalec/smart_finance/outputs/latex/\" if NOTEBOOK_USER == 'DM' \n",
    "        else \"C:/Users/akyle/ask/code/flow-trading-latex/\") if NOTEBOOK_USER == 'PK' else None\n",
    "'''\n",
    "CSV_PATH = (\"C:/Users/richa/Documents/energy_forward_market/outputs/csv/\")\n",
    "LATEX_PATH = (\"C:/Users/richa/Documents/energy_forward_market/outputs/latex/\")\n",
    "\n",
    "NSEED0 = 4321  # Sets seed globally for almost all simulations.  Change to get different results.\n",
    "B_SAVE_RESULTS = True if RUN_TYPE == 'workstation' else True if RUN_TYPE == 'laptop' else False\n",
    "NAME_SUFFIX = NOTEBOOK_USER + RUN_TYPE  # Suffix included in file name to identify source\n",
    "# NUM_PRINT: -1 means print nothing, 0 means minimal printing, \n",
    "# n > 0 means print n iterations at top and bottom, and also n subiterations\n",
    "NUM_PRINT = 0 if RUN_TYPE == 'workstation' else 0 if RUN_TYPE == 'laptop' else 0 \n",
    "NUM_THREADS = 2 if RUN_TYPE == 'workstation' else 4 if RUN_TYPE == 'laptop' else 2\n",
    "GLOBAL_NUM_THREADS = str(NUM_THREADS)\n",
    "#B_USE_PYTORCH = True  # This must be True\n",
    "B_USE_GPU = True\n",
    "B_TORCHSCRIPT_JIT = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version='3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]'\n",
      "conda environment =  C:\\Users\\richa\\anaconda3\\envs\\my_env_name\n",
      "np.__version__='1.26.2'\n",
      "scipy.__version__='1.11.4'\n",
      "pd.__version__='2.1.1'\n",
      "numba.__version__='0.58.1'\n",
      "matplotlib.__version__='3.8.0'\n",
      "torch.__version__='2.1.1', torch.version.cuda='11.8'\n",
      "mkl.get_max_threads()=2\n",
      "time stamp =  2023-1204-2042\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mkl\n",
    "#mkl.set_num_threads(1)\n",
    "\n",
    "import threadpoolctl\n",
    "import functools\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "os.environ[\"MKL_NUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "#os.environ[\"NUMEXPR_MAX_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = GLOBAL_NUM_THREADS\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import pandas as pd\n",
    "import numba\n",
    "import numba.cuda\n",
    "import typing\n",
    "\n",
    "#numba.cuda.close()\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import timeit\n",
    "import time\n",
    "import sys\n",
    "#import itertools\n",
    "import cProfile\n",
    "import pstats \n",
    "#import io\n",
    "import dataclasses\n",
    "import tqdm\n",
    "import pprint\n",
    "\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(f\"{sys.version=}\")\n",
    "print(\"conda environment = \", os.environ[\"CONDA_PREFIX\"])\n",
    "print(f\"{np.__version__=}\")\n",
    "print(f\"{scipy.__version__=}\")\n",
    "print(f\"{pd.__version__=}\")\n",
    "print(f\"{numba.__version__=}\")\n",
    "print(f\"{matplotlib.__version__=}\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "except:\n",
    "    print(\"Pytorch not available.\")\n",
    "\n",
    "print(f\"{mkl.get_max_threads()=}\")\n",
    "\n",
    "print(\"time stamp = \", datetime.datetime.now().strftime('%Y-%m%d-%H%M'))\n",
    "tstart = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell checks whether numpy is using mkl.  If it is, you should see something like *libraries = ['mkl_rt']*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Dependencies:\n",
      "  blas:\n",
      "    detection method: pkgconfig\n",
      "    found: true\n",
      "    include directory: C:/Users/richa/anaconda3/envs/my_env_name/Library/include\n",
      "    lib directory: C:/Users/richa/anaconda3/envs/my_env_name/Library/lib\n",
      "    name: mkl-sdl\n",
      "    openblas configuration: unknown\n",
      "    pc file directory: C:\\b\\abs_7267ja_mqz\\croot\\numpy_and_numpy_base_1701295083047\\_h_env\\Library\\lib\\pkgconfig\n",
      "    version: '2023.1'\n",
      "  lapack:\n",
      "    detection method: internal\n",
      "    found: true\n",
      "    include directory: unknown\n",
      "    lib directory: unknown\n",
      "    name: dep1610466607184\n",
      "    openblas configuration: unknown\n",
      "    pc file directory: unknown\n",
      "    version: 1.26.2\n",
      "Compilers:\n",
      "  c:\n",
      "    commands: cl.exe\n",
      "    linker: link\n",
      "    name: msvc\n",
      "    version: 19.29.30153\n",
      "  c++:\n",
      "    commands: cl.exe\n",
      "    linker: link\n",
      "    name: msvc\n",
      "    version: 19.29.30153\n",
      "  cython:\n",
      "    commands: cython\n",
      "    linker: cython\n",
      "    name: cython\n",
      "    version: 3.0.0\n",
      "Machine Information:\n",
      "  build:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: windows\n",
      "  host:\n",
      "    cpu: x86_64\n",
      "    endian: little\n",
      "    family: x86_64\n",
      "    system: windows\n",
      "Python Information:\n",
      "  path: C:\\b\\abs_7267ja_mqz\\croot\\numpy_and_numpy_base_1701295083047\\_h_env\\python.exe\n",
      "  version: '3.11'\n",
      "SIMD Extensions:\n",
      "  baseline:\n",
      "  - SSE\n",
      "  - SSE2\n",
      "  - SSE3\n",
      "  found:\n",
      "  - SSSE3\n",
      "  - SSE41\n",
      "  - POPCNT\n",
      "  - SSE42\n",
      "  - AVX\n",
      "  - F16C\n",
      "  - FMA3\n",
      "  - AVX2\n",
      "  not found:\n",
      "  - AVX512F\n",
      "  - AVX512CD\n",
      "  - AVX512_SKX\n",
      "  - AVX512_CLX\n",
      "  - AVX512_CNL\n",
      "  - AVX512_ICL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows details of the conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : base\n",
      "    active env location : C:\\Users\\richa\\anaconda3\\envs\\my_env_name\n",
      "            shell level : 1\n",
      "       user config file : C:\\Users\\richa\\.condarc\n",
      " populated config files : C:\\Users\\richa\\.condarc\n",
      "          conda version : 23.10.0\n",
      "    conda-build version : not installed\n",
      "         python version : 3.11.5.final.0\n",
      "       virtual packages : __archspec=1=x86_64\n",
      "                          __cuda=12.3=0\n",
      "                          __win=0=0\n",
      "       base environment : C:\\Users\\richa\\anaconda3\\envs\\my_env_name  (writable)\n",
      "      conda av data dir : C:\\Users\\richa\\anaconda3\\envs\\my_env_name\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\Users\\richa\\anaconda3\\envs\\my_env_name\\pkgs\n",
      "                          C:\\Users\\richa\\.conda\\pkgs\n",
      "                          C:\\Users\\richa\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\richa\\anaconda3\\envs\\my_env_name\\envs\n",
      "                          C:\\Users\\richa\\.conda\\envs\n",
      "                          C:\\Users\\richa\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/23.10.0 requests/2.31.0 CPython/3.11.5 Windows/10 Windows/10.0.22621 solver/libmamba conda-libmamba-solver/23.11.1 libmambapy/1.5.3\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to format printing of floats with torch.jit\n",
    "\n",
    "torch.jit does not allow formatting of printed numbers.  This function is a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1234, y=1.23, x=5.68e+00 done\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.ignore\n",
    "def fprn(pre : str, x : float, fmt : str):\n",
    "    print((pre + \"{x:\" + fmt + \"}\").format(x=x), end=\"\")\n",
    "\n",
    "@torch.jit.ignore\n",
    "def fprni(pre : str, x : int):\n",
    "    print((pre + \"{x:}\").format(x=x), end=\"\")\n",
    "\n",
    "@torch.jit.script\n",
    "def g():\n",
    "    i = 1234\n",
    "    x = 5.678912345\n",
    "    y = 1.23456789\n",
    "    fprni(\"i=\", i)\n",
    "    fprn(\", y=\", y,  \"1.3\")\n",
    "    fprn(\", x=\", x,  \".2e\")\n",
    "    print(\" done\")\n",
    "    \n",
    "g()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to format pandas output nicely in tables\n",
    "\n",
    "The function shows integers without a decimal and shows floats with 3-7 digits of accuracy using exponential notation where appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.23e-03</td>\n",
       "      <td>onetwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0123</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.4567</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.23e+04</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.23e+08</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A        B\n",
       "0 1.23e-11        0\n",
       "1 1.23e-03   onetwo\n",
       "2   0.0123       10\n",
       "3 0.00e+00      100\n",
       "4 123.4567    10000\n",
       "5 1.23e+04    10000\n",
       "6 1.23e+08  1000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_pd = (lambda  x:  \"{:}\".format(x) if type(x) == str\n",
    "             else \"{:}\".format(x) if (type(x)==int and abs(x) <= 10000000)\n",
    "            else \"{:.2e}\".format(x) if abs(x) < 0.00999999\n",
    "            else \"{:.2e}\".format(x) if abs(x) >= 1000.00 \n",
    "            else \"{:.4f}\".format(x)) \n",
    "\n",
    "def test_format_pd():\n",
    "\n",
    "    pd.options.display.float_format = format_pd\n",
    "\n",
    "    df = pd.DataFrame({'A' : [0.00000000001234567, 0.001234567, 0.01234567, 0.00, 123.4567, 12345.67, 123456789.123],\n",
    "                          'B' : [0, 'one' + 'two', 10, 100, 10**4, 10**4, 10**6]})\n",
    "    display(df)\n",
    "    \n",
    "    # print(type(df.loc[1, 'B']) == str)\n",
    "    \n",
    "test_format_pd()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to print summary information about both sparse and dense arrays ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x, <class 'numpy.ndarray'>, float64, shape= (5,) = 5, nnz= 5 , fracnz= 1.0, nans= 1, \n",
      "y, <class 'scipy.sparse._csr.csr_matrix'>, float64, shape= (1, 5) = 5, nnz= 3 , fracnz= 0.6, nans= 1, \n",
      "z, <class 'float'>, 5.0, \n",
      "c, <class 'numpy.ndarray'>, float64, shape= (), 99.99, \n",
      "none, <class 'NoneType'>, None, \n",
      "xt, <class 'torch.Tensor'>, torch.float32, shape= torch.Size([]), tensor(55.5500), \n",
      "xt2, <class 'torch.Tensor'>, torch.float32, shape= torch.Size([1]) = 1, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richa\\AppData\\Local\\Temp\\ipykernel_32736\\2028477231.py:93: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  xt4 = xt3.to_sparse_csr()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nans= 0, L1= 66.66000366210938, \n",
      "xt3, <class 'torch.Tensor'>, torch.float32, shape= torch.Size([2, 3]) = 6, nans= 2, L1= nan, \n",
      "xt4, <class 'torch.Tensor'>, torch.float32, shape= torch.Size([2, 3]) = 6, nnz= 4 , fracnz= 0.6666666666666666, \n",
      "none, <class 'NoneType'>, None, \n",
      "b, <class 'bool'>, True, \n",
      "v, <class 'list'>, len =  3, v= <class 'float'>, \n",
      "d, <class 'dict'>, len =  2, k= <class 'str'>, v= <class 'int'>, \n"
     ]
    }
   ],
   "source": [
    "# Function to print information about arrays. For debugging.\n",
    "\n",
    "def printa(x, s=None):  # Assumption: s == 'x'\n",
    "    if s != None:\n",
    "        try:\n",
    "            print(s, end=\", \")\n",
    "        except:\n",
    "            #print(\"no name\")\n",
    "            pass\n",
    "    try:\n",
    "        print(type(x), end=\", \")\n",
    "    except:\n",
    "        #print(\"no type, \", end=\", \")\n",
    "        pass\n",
    "    if type(x) in [list, set]:\n",
    "        print(\"len = \", len(x), end=\", \")\n",
    "        for v in x:\n",
    "            try:\n",
    "                print(\"v=\", type(v), end=\", \")\n",
    "            except:\n",
    "                pass\n",
    "            #print(\"\")\n",
    "            break\n",
    "    if type(x) in [dict]:\n",
    "        print(\"len = \", len(x), end=\", \")\n",
    "        for k in x:\n",
    "            try:\n",
    "                print(\"k=\", type(k), end=\", \")\n",
    "                print(\"v=\", type(x[k]), end=\", \")\n",
    "            except:\n",
    "                pass\n",
    "            #print(\"\")\n",
    "            break\n",
    "    else:\n",
    "        try:\n",
    "            print(x.dtype, end=\", \")\n",
    "        except:\n",
    "            #print(\"no dtype\", end=\", \")\n",
    "            pass\n",
    "        if np.ndim(x) == 0:\n",
    "            try:\n",
    "                print(\"shape=\", x.shape, end=\", \")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                print(x, end=\", \")\n",
    "            except:\n",
    "                pass\n",
    "        else:    \n",
    "            try:\n",
    "                print(\"shape=\", x.shape, \"=\", np.prod(x.shape), end=\", \")\n",
    "            except:\n",
    "                #print(\"no shape, \", end=\", \")\n",
    "                pass\n",
    "            try:\n",
    "                print(\"nnz=\", x.size, \", fracnz=\", x.size / np.prod(x.shape), end=\", \")\n",
    "            except:\n",
    "                try:\n",
    "                    print(\"nnz=\", x.values().shape[0], \", fracnz=\", x.values().shape[0] / np.prod(x.size()), end=\", \")\n",
    "                except:\n",
    "                    #print(\"nnz undefined\", end=\", \")\n",
    "                    pass\n",
    "                #print(\"nnz undefined\", end=\", \")\n",
    "                pass\n",
    "            try:\n",
    "                print(\"nans=\", (~torch.isfinite(x.data)).sum().item(), end=\", \")\n",
    "                print(\"L1=\", torch.linalg.norm(x, ord=1).item(), end=\", \")\n",
    "            except:\n",
    "                try:\n",
    "                    print(\"nans=\", (~np.isfinite(x.data)).sum(), end=\", \")\n",
    "                    print(\"L1=\", scipy.linalg.norm(x, ord=1), end=\", \")\n",
    "                except:\n",
    "                    #print(\"nnz undefined\", end=\", \")\n",
    "                    pass\n",
    "            #try:\n",
    "            #    if type(x) in [None, True, False, int, float, np.float32, np.float64, np.int32, np.int64, \n",
    "            #                   torch.float32, torch.float64, torch.int32, torch.int64]:\n",
    "            #        print(\"value = \", x)\n",
    "            #except:\n",
    "            #    pass\n",
    "    print(\"\")\n",
    "    \n",
    "def test_printa():\n",
    "    x = np.array([1.00, 0.00, 5.00, 0.00, np.nan])\n",
    "    y = scipy.sparse.csr_matrix(x)\n",
    "    z = 5.00\n",
    "    c = np.array(99.99)\n",
    "    none = None\n",
    "    b = True\n",
    "    xt = torch.tensor(55.55)\n",
    "    xt2 = torch.tensor([66.66])\n",
    "    xt3 = torch.tensor([[66.66, np.nan, 0.00], [66.66, np.nan, 0.00]])\n",
    "    xt4 = xt3.to_sparse_csr()\n",
    "    d = {'a' : 1, 'b' :2}\n",
    "    v = [1.00, 2, 3]\n",
    "    printa(x, 'x')\n",
    "    printa(y, 'y')\n",
    "    printa(z, 'z')\n",
    "    printa(c, 'c')\n",
    "    printa(none, 'none')\n",
    "    printa(xt, 'xt')\n",
    "    printa(xt2, 'xt2')\n",
    "    printa(xt3, 'xt3')\n",
    "    printa(xt4, 'xt4')\n",
    "    printa(None, 'none')\n",
    "    printa(b, 'b')\n",
    "    printa(v, 'v')\n",
    "    printa(d, 'd')\n",
    "    \n",
    "test_printa()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorator function class to time function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.011522054672241211  sec\n",
      "most recent time stored by ftimer =  0.011522054672241211\n"
     ]
    }
   ],
   "source": [
    "class Ftimer:\n",
    "\n",
    "    def __init__(self, bprint):\n",
    "        self.dt = np.nan\n",
    "        \n",
    "    def __call__(self, bprint=True):\n",
    "        def factory(func):\n",
    "            @functools.wraps(func)\n",
    "            def decorator(*args, **kwargs):\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                finally:\n",
    "                    self.dt = time.time() - t0\n",
    "                    if bprint == True:\n",
    "                        print(\"ftimer = \", self.dt, \" sec\")\n",
    "            return decorator\n",
    "        return factory\n",
    "\n",
    "ftimer = Ftimer(bprint=True)\n",
    "\n",
    "@ftimer()\n",
    "def test_ftimer():\n",
    "    n = 10**6\n",
    "    rng = np.random.default_rng()\n",
    "    x = rng.standard_normal((n,))\n",
    "    res = x * x\n",
    "    return res\n",
    "\n",
    "test_ftimer()\n",
    "print(\"most recent time stored by ftimer = \", ftimer.dt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorator to control number of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should print information for both 'mkl' and 'openmp'\n",
      "[{'filepath': 'C:\\\\Users\\\\richa\\\\anaconda3\\\\envs\\\\my_env_name\\\\Library\\\\bin\\\\mkl_rt.2.dll',\n",
      "  'internal_api': 'mkl',\n",
      "  'num_threads': 2,\n",
      "  'prefix': 'mkl_rt',\n",
      "  'threading_layer': 'intel',\n",
      "  'user_api': 'blas',\n",
      "  'version': '2023.1-Product'},\n",
      " {'filepath': 'C:\\\\Users\\\\richa\\\\anaconda3\\\\envs\\\\my_env_name\\\\Library\\\\bin\\\\libiomp5md.dll',\n",
      "  'internal_api': 'openmp',\n",
      "  'num_threads': 2,\n",
      "  'prefix': 'libiomp',\n",
      "  'user_api': 'openmp',\n",
      "  'version': None}]\n",
      "\n",
      "result of test_fthrds()\n",
      "Should be approximately 1.00:  1.0003250263235859\n",
      "nthreads =  1 , user_api =  blas\n"
     ]
    }
   ],
   "source": [
    "def fthrds(nthreads=NUM_THREADS, user_api='blas', bprint=True):\n",
    "    def factory(func):\n",
    "        @functools.wraps(func)\n",
    "        def decorator(*args, **kwargs):\n",
    "            with threadpoolctl.threadpool_limits(limits=nthreads, user_api=user_api): \n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                finally:\n",
    "                    if bprint == True:\n",
    "                        print(\"nthreads = \", nthreads, \", user_api = \", user_api)\n",
    "        return decorator\n",
    "    return factory\n",
    "\n",
    "print(\"Should print information for both 'mkl' and 'openmp'\")\n",
    "pprint.pprint(threadpoolctl.threadpool_info())\n",
    "print(\"\")\n",
    "\n",
    "#@fthrds(nthreads=1, user_api='openmp')\n",
    "@fthrds(nthreads=1, user_api='blas')\n",
    "def test_fthrds():\n",
    "    n = 10**6\n",
    "    rng = np.random.default_rng()\n",
    "    x = rng.standard_normal((n,))\n",
    "    res = x * x\n",
    "    print(\"Should be approximately 1.00: \", res.sum() / float(n))\n",
    "\n",
    "print(\"result of test_fthrds()\")\n",
    "test_fthrds()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology for Simulating an OrderBook\n",
    "\n",
    "We can think of the order book as consisting of three types of orders: (1) orders for individual assets, (2) orders for indexes, and (3) orders for pairs trades to buy one asset or index and sell a different asset or index. If the number of indexes is defined broadly enough, this could cover orders for arbitrary portfolios.  In our simulations, there are equally weighted and value weighted indexes for the market as a whole, for size quantiles (defined by expected dollar volume), and for industry quintiles defined by assets defined by having the same dollar volume rank modulo the number of industries.\n",
    "\n",
    "In the base case Assumptions, we have $N = 500$ assets, $M = 100000$ orders, $num\\_size\\_indexes = 5$ size quantiles, and $num\\_industry\\_indexes = 10$ industry quantiles. This implies $(1 + 5 + 10) * 2 = 32$ index portfolios. While this is a small number of indexes compared to the theoretical number of $2^N$ different value-weighted and equally-weighted indexes, it gives a flavor for how index orders affect the way in which prices are determined. Keeping the number of indexes small also makes the algorithm for calculating prices faster, as discussed further below.\n",
    "\n",
    "The Assumptions clas defines constants which determine the expected number and dollar size of orders for individual assets, indexes, and pairs trades. The actual number and size of orders is the result of simulations. Thus, the actual number of orders for an individual asset is the realization of a randome variabl whose mean and variance is defined in by assumptions but whose realization is random, typically approximating a Poisson process. \n",
    "\n",
    "Our general approach is to make assumptions about the number of orders, then use scaling assumptions to determin the relative expected dollar size of orders, with the actual dollar size determined by a scaling assumptions relating the number of orders to the size of orders. An additional scaling assumption defines expected total dollar order volume across all individual assets (excluding indexes and pairs trades).\n",
    "\n",
    "The scaling relationship between the number and size of orders for individual assets and indexes is obtained by applying the market microstructure invariance hypothesis of Kyle and Obizhaeva (2016). Its main implication is that as dollar volume varies, the dollar size of orders varies with the $1/3$ power of the ratio of dollar volume to return variance, and the number of orders varies with the $2/3$ power of this ratio. Thus, increasing dollar volume by a factor of 8 while holding volatility constant implies that the number of orders increases by a factor of 4 and the size of orders increases by a factor of 2. This hypothesis simplifies the number of assumptions needed, since assumptions about the number of orders imply the expected size of orders, and vice versa.  It is also makes the simulation assumtions more realistic. For example, it is known that orders for thinly traded stocks are much smaller than orders for liquid stocks, and order for large liquid indexes like the market as a whole are very large indeed, approximating conformity with the invariance hypothesis. \n",
    "\n",
    "The value-weighted market index is assumed to have many orders, consistent with actual markets. The invariance hypothesis implies---realistically---that individual orders for the value-weighted market index have large dollar size. This implies that the overall value of the market index is heavily dependent on value-weighted market index orders.  In the current market design, the demand for indexes like the CME' S\\&P 500 E-mini futures contract or actively traded ETFs like SPDR influence the prices of individual assets via index arbitrage trading. In our design, the index arbitrage is not necessary because the indexes are defined as the baskets of stocks themselves. Thus, in our design, when a trader buys the value-weighted market index, they do not obtain shares in an ETF-like asset but instead obtain different numbers of shares in $N=500$ different assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders for Individual Stocks\n",
    "\n",
    "Assume the total number of assets is $N = 500$, the total number of orders is $M = 100000$, and the fraction of total orders for individual assets is $frac_MA = 0.50$. Then the total number of orders for all individual assets is the nonstochastic quantity $MA := M * frac_MA = 100000 * 0.50 = 50000$. \n",
    "\n",
    "The expected number of orders for each asset is obtained by assuming that the expected number of orders for an asset has a lognormal distribution with (log)variance $std\\_num\\_orders\\_asset = 1.7$. For each asset, an expected number of orders is generating by first drawing from this lognormal distribution for each stock, summing the 500 random lognormally distributed quantities, then dividing each draw from the lognormal by their sum to obtain for each asset the fraction of total orders expected for that asset. The mean of the lognormal distribution does not matter because the results add up to one after dividing by their sum. \n",
    "\n",
    "Next, for each of the $MA = 50000$ individual asset orders, a random variable is drawn from a multinomial distribution whose probability weights are the expected fraction of orders for each asset. The integer drawn from the multinomial distribution determines the asset to which the order applies. \n",
    "\n",
    "Since 1.7 is a large standard deviation, it is likely there are some assets with thousands of orders and some assets with no orders at all.  This is intentional. Our market clearing algorithm should be able to find market clearing prices and quantities for each asset, even when there are no individual asset orders for some assets.  Of course, every asset will be part of orders for a value-weighted or equally-weighted market portfolio. The prices of illiquid assets are therefore likely to be heavily influenced by orders for indexes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class and function definitions related to simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions Class\n",
    "\n",
    "The Assumptions class defines default values for constants used to simulate an OrderBook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Base</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>500</td>\n",
       "      <td>Number of assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>100000</td>\n",
       "      <td>Number of orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exch_epsilon</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>Slope of exchange's demand schedule (shares traded per dollar price change at \\$100/share)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exch_phpl_frac</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Exchange $p_H - p_L$ as fraction of $p_0$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stab_max_qv</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>Stabilizing order max q as multiple of v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stab_ph_frac</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>Fraction of $p_0$ where buying starts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stab_pl_frac</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>Fraction of $p_0$ where buying stops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fracMA</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>Fraction of orders for individual assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subfracMX</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>Fraction of orders for indexes among orders for portfolios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_size_indexes</td>\n",
       "      <td>5</td>\n",
       "      <td>Number of size indexes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num_industry_indexes</td>\n",
       "      <td>10</td>\n",
       "      <td>Number of industry indexes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>market_index_share</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>Probability an index order is a market index order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>size_index_subshare</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>Probability a size or industry index order is a size index order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ew_mkt_index_subshare</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>Probability a mkt index order is an EW mkt index order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ew_size_index_subsubshare</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>Probability a size index order is an EW size index order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ew_industry_index_subsubshare</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>Probability an industry index order is an EW industry index order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>std_num_orders_asset</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>Standard deviation of expected number of orders across assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>std_order_size</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>Standard deviation of order size given asset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dv_single_asset_orders</td>\n",
       "      <td>1.00e+07</td>\n",
       "      <td>Expect total dollar volume of orders for individual assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>std_limit_price</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Standard deviation of upper limit price as fraction of initial price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>limit_bias</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>Mean deviation of upper limit price as fraction of initial price standard deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>avg_ph_minus_pl_bp</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mean difference between upper and lower limit prices (basis points)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>std_ph_minus_pl</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Standard deviation of difference between upper and lower limit prices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>index_prices</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Mean index price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mean_asset_price</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>Mean asset price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>std_asset_price</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>St.dev of mean asset prices across assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>invariance_exponent</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>Invariance exponent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fraction_buy_orders_asset</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>Fraction buy orders for indexes and assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bs_M</td>\n",
       "      <td>0</td>\n",
       "      <td>Number of orders for sparse portfolios of registered assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bs_Rmin</td>\n",
       "      <td>1</td>\n",
       "      <td>Minimum number of registered assets in sparse order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bs_Rmax</td>\n",
       "      <td>5</td>\n",
       "      <td>Maximum number of registered assets in sparse order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bs_Wscale</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Scaling factor for size of sparse orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Bs_std_ph_dollars</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Std dev of ph minus value based on p0 for sparse order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bd_M</td>\n",
       "      <td>0</td>\n",
       "      <td>Number of orders for dense portfolios of registered assets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bd_Rmin</td>\n",
       "      <td>20</td>\n",
       "      <td>Minimum number of registered assets in dense order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bd_Rmax</td>\n",
       "      <td>50</td>\n",
       "      <td>Maximum number of registered assets in dense order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bd_Wscale</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Scaling factor for size of dense orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bd_std_ph_dollars</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Std dev of ph minus value based on p0 for dense order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ew_mkt_index_share</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>Probability an index order is for the equally-weighted market index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>vw_mkt_index_share</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>Probability an index order is for the value-weighted market index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ew_size_index_share</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>Probability an index order is for an equally-weighted size index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>vw_size_index_share</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>Probability an index order is for a value-weighted size index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ew_industry_index_share</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>Probability an index order is for an equally-weighted industry index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>vw_industry_index_share</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>Probability an index order is for a value-weighted industry index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Parameter     Base                                                                                 Description\n",
       "0                               N      500                                                                            Number of assets\n",
       "1                               M   100000                                                                            Number of orders\n",
       "2                    exch_epsilon   0.0100  Slope of exchange's demand schedule (shares traded per dollar price change at \\$100/share)\n",
       "3                  exch_phpl_frac 100.0000                                                   Exchange $p_H - p_L$ as fraction of $p_0$\n",
       "4                     stab_max_qv 0.00e+00                                                    Stabilizing order max q as multiple of v\n",
       "5                    stab_ph_frac   0.7000                                                       Fraction of $p_0$ where buying starts\n",
       "6                    stab_pl_frac   0.2000                                                        Fraction of $p_0$ where buying stops\n",
       "7                          fracMA   0.5000                                                    Fraction of orders for individual assets\n",
       "8                       subfracMX   0.5000                                  Fraction of orders for indexes among orders for portfolios\n",
       "9                num_size_indexes        5                                                                      Number of size indexes\n",
       "10           num_industry_indexes       10                                                                  Number of industry indexes\n",
       "11             market_index_share   0.8000                                          Probability an index order is a market index order\n",
       "12            size_index_subshare   0.5000                            Probability a size or industry index order is a size index order\n",
       "13          ew_mkt_index_subshare   0.0625                                      Probability a mkt index order is an EW mkt index order\n",
       "14      ew_size_index_subsubshare   0.2500                                    Probability a size index order is an EW size index order\n",
       "15  ew_industry_index_subsubshare   0.2500                           Probability an industry index order is an EW industry index order\n",
       "16           std_num_orders_asset   1.7000                               Standard deviation of expected number of orders across assets\n",
       "17                 std_order_size   1.5000                                                Standard deviation of order size given asset\n",
       "18         dv_single_asset_orders 1.00e+07                                  Expect total dollar volume of orders for individual assets\n",
       "19                std_limit_price   0.1000                        Standard deviation of upper limit price as fraction of initial price\n",
       "20                     limit_bias   0.3000         Mean deviation of upper limit price as fraction of initial price standard deviation\n",
       "21             avg_ph_minus_pl_bp   1.0000                         Mean difference between upper and lower limit prices (basis points)\n",
       "22                std_ph_minus_pl   2.0000                       Standard deviation of difference between upper and lower limit prices\n",
       "23                   index_prices 100.0000                                                                            Mean index price\n",
       "24               mean_asset_price 100.0000                                                                            Mean asset price\n",
       "25                std_asset_price 0.00e+00                                                   St.dev of mean asset prices across assets\n",
       "26            invariance_exponent   0.3333                                                                         Invariance exponent\n",
       "27      fraction_buy_orders_asset   0.5000                                                  Fraction buy orders for indexes and assets\n",
       "28                           Bs_M        0                                 Number of orders for sparse portfolios of registered assets\n",
       "29                        Bs_Rmin        1                                         Minimum number of registered assets in sparse order\n",
       "30                        Bs_Rmax        5                                         Maximum number of registered assets in sparse order\n",
       "31                      Bs_Wscale   1.0000                                                    Scaling factor for size of sparse orders\n",
       "32              Bs_std_ph_dollars   1.0000                                      Std dev of ph minus value based on p0 for sparse order\n",
       "33                           Bd_M        0                                  Number of orders for dense portfolios of registered assets\n",
       "34                        Bd_Rmin       20                                          Minimum number of registered assets in dense order\n",
       "35                        Bd_Rmax       50                                          Maximum number of registered assets in dense order\n",
       "36                      Bd_Wscale   1.0000                                                     Scaling factor for size of dense orders\n",
       "37              Bd_std_ph_dollars   1.0000                                       Std dev of ph minus value based on p0 for dense order\n",
       "38             ew_mkt_index_share   0.0500                         Probability an index order is for the equally-weighted market index\n",
       "39             vw_mkt_index_share   0.7500                           Probability an index order is for the value-weighted market index\n",
       "40            ew_size_index_share   0.0250                            Probability an index order is for an equally-weighted size index\n",
       "41            vw_size_index_share   0.0750                               Probability an index order is for a value-weighted size index\n",
       "42        ew_industry_index_share   0.0250                        Probability an index order is for an equally-weighted industry index\n",
       "43        vw_industry_index_share   0.0750                           Probability an index order is for a value-weighted industry index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclasses.dataclass(frozen=False)\n",
    "class Assumptions():\n",
    "    \"\"\"\n",
    "    This class defines constants used to generate order books based on asset characteristics.\n",
    "    It is simply a convenient way to put numerous related constants into one namespace.\n",
    "    Descriptions of parameters are strings withe names preceded by an underscore.\n",
    "    This makes it possible to construct tables describing parameters.\n",
    "    \"\"\"\n",
    "        \n",
    "    #self.DTYPE = np.float32\n",
    "    dtype = np.float64\n",
    "\n",
    "    N : int = 500 # number of assets\n",
    "    _N = \"Number of assets\"\n",
    "    M : int = 100000 # number of orders\n",
    "    _M = \"Number of orders\"\n",
    "\n",
    "    exch_liq_model : str = 'mina' # 'pete' = invariance, 'mina' = constant, 'eric' = proportional    \n",
    "    x_exch_liq_model = \"$\\epsilon$ model 'mina', 'pete', 'eric'\"\n",
    "    exch_epsilon : dtype = 1.00e-2\n",
    "    #_exch_epsilon = \"$\\epsilon$, exchange shares traded per dollar $\\Delta p$ at $p=100$ dollars\"    \n",
    "    _exch_epsilon = \"Slope of exchange's demand schedule (shares traded per dollar price change at \\$100/share)\"    \n",
    "    exch_phpl_frac : dtype = 100.00\n",
    "    _exch_phpl_frac = \"Exchange $p_H - p_L$ as fraction of $p_0$\"    \n",
    "\n",
    "    stab_max_qv : dtype = 0.00\n",
    "    _stab_max_qv = \"Stabilizing order max q as multiple of v\"\n",
    "    stab_ph_frac : dtype = 0.70\n",
    "    _stab_ph_frac =  \"Fraction of $p_0$ where buying starts\"\n",
    "    stab_pl_frac : dtype = 0.20\n",
    "    _stab_pl_frac =  \"Fraction of $p_0$ where buying stops\"\n",
    "        \n",
    "    fracMA : dtype = 0.50\n",
    "    _fracMA = \"Fraction of orders for individual assets\"\n",
    "    #fracBs : dtype = 0.10\n",
    "    #_fracBs = \"Fraction of orders for sparse portfolios of registered assets\"\n",
    "    #fracBd : dtype = 0.00\n",
    "    #_fracBd = \"Fraction of orders for dense portfolios of registered assets\"\n",
    "    subfracMX : dtype = 0.50\n",
    "    _subfracMX = \"Fraction of orders for indexes among orders for portfolios\"    \n",
    "\n",
    "    num_size_indexes : int = 5\n",
    "    _num_size_indexes = \"Number of size indexes\"\n",
    "    num_industry_indexes : int = 10\n",
    "    _num_industry_indexes  = \"Number of industry indexes\"\n",
    "\n",
    "    # Decomposition of total index trading by type of index:\n",
    "    # Invariance uses this to define the number and size of orders.\n",
    "    # Put a lot of trade into a single vw market index! Should have more orders than largest stock.\n",
    "    \n",
    "    market_index_share : dtype = 0.80\n",
    "    _market_index_share = \"Probability an index order is a market index order\"    \n",
    "    size_index_subshare : dtype = 0.50\n",
    "    _size_index_subshare = \"Probability a size or industry index order is a size index order\"    \n",
    "    ew_mkt_index_subshare : dtype = 0.0625\n",
    "    _ew_mkt_index_subshare = \"Probability a mkt index order is an EW mkt index order\"    \n",
    "    ew_size_index_subsubshare : dtype = 0.25\n",
    "    _ew_size_index_subsubshare = \"Probability a size index order is an EW size index order\"    \n",
    "    ew_industry_index_subsubshare : dtype = 0.25    \n",
    "    _ew_industry_index_subsubshare = \"Probability an industry index order is an EW industry index order\"    \n",
    "\n",
    "    ew_size_index_alpha : dtype = 0.00\n",
    "    x_ew_size_index_alpha = \"decay rate of dv share of ew mkt indexes\"\n",
    "    \n",
    "    # Invariance suggests std_num_orders_asset = 2.5*2/3? \n",
    "    # Large value of self.std_num_orders_assets creates a few liquid assets and many illiquid assets.\n",
    "    std_num_orders_asset : dtype = 1.7 \n",
    "    _std_num_orders_asset = \"Standard deviation of expected number of orders across assets\"    \n",
    "\n",
    "    std_order_size : dtype = 1.5  #log-standard-deviation of dollar size of asset order\n",
    "    _std_order_size = \"Standard deviation of order size given asset\"\n",
    "\n",
    "    dv_single_asset_orders : dtype = 1.00e+7\n",
    "    _dv_single_asset_orders = \"Expect total dollar volume of orders for individual assets\"\n",
    "        \n",
    "    # Limit price on order is random variable distributed around initial price, \n",
    "    # 0.10 means + or - 10 percent of price\n",
    "    std_limit_price : dtype = 0.10\n",
    "    _std_limit_price = \"Standard deviation of upper limit price as fraction of initial price\"\n",
    "\n",
    "    limit_bias : dtype = 0.30 # Buy order mean price reduced and sell order mean price increase by factor proportional to this value\n",
    "    #_limit_bias = \"Buy limits higher than sell limits\"\n",
    "    _limit_bias = \"Mean deviation of upper limit price as fraction of initial price standard deviation\"\n",
    "\n",
    "    # Specify avg of pH - pL as fraction of asset price in basis points. \n",
    "    # For asset with p=$100.00, avg_ph_minus_pl = 1.00 means ph - pl=$0.01 = one basis point\n",
    "    avg_ph_minus_pl_bp : dtype = 1.00 \n",
    "    #_avg_ph_minus_pl_bp = \"Avg. of $p_H - p_L$ in basis points\"    \n",
    "    _avg_ph_minus_pl_bp = \"Mean difference between upper and lower limit prices (basis points)\"    \n",
    "    std_ph_minus_pl : dtype = 2.00  # log standard deviation applied to lognormal.\n",
    "    #_std_ph_minus_pl = \"St.dev. of $p_H - p_L$\"\n",
    "    _std_ph_minus_pl = \"Standard deviation of difference between upper and lower limit prices\"\n",
    "    # Seed random number generator:\n",
    "    #nseed : int = 1234\n",
    "    #rng = np.random.default_rng(nseed)\n",
    "        \n",
    "    #vw_size_index_share : dtype = 0.08\n",
    "    #ew_size_index_share : dtype = 0.02\n",
    "    #vw_industry_index_share : dtype = 0.08\n",
    "    #ew_industry_index_share : dtype = 0.02\n",
    "\n",
    "    #@property # see below\n",
    "    #self.vw_mkt_index_share = (1.00 - self.ew_mkt_index_share \n",
    "    #                       - self.vw_size_index_share - self.ew_size_index_share\n",
    "    #                       - self.vw_industry_index_share - self.ew_industry_index_share)\n",
    "\n",
    "    index_prices : dtype = 100.00\n",
    "    _index_prices = \"Mean index price\"\n",
    "\n",
    "    mean_asset_price : dtype = 100.00 # Should not matter much, can be scaled to one dollar\n",
    "    _mean_asset_price = \"Mean asset price\"    \n",
    "    std_asset_price : dtype = 0.00  # *** Should not matter much, can be almost zero\n",
    "    _std_asset_price = \"St.dev of mean asset prices across assets\"\n",
    "\n",
    "    # invariance_exponent determines how dollar order size varies with asset dollar volume\n",
    "    # If invariance_exponent = 1/3 and dollar volume increases by factor of 8, \n",
    "    # dollar size of orders increases by factor of 2 and number of orders by factor of 4    \n",
    "    invariance_exponent : dtype = 1.00 / 3.00\n",
    "    _invariance_exponent = \"Invariance exponent\"\n",
    "    # invariance_c = 2000.00 dollars is value from Kyle-Obizhaeva paper. \n",
    "    # Only effect of invariance_c here is to scale dollar volume and order size.\n",
    "    # But different invariance_c changes simulation convergence tolerances since they involve dollar units.\n",
    "    #invariance_c_factor : dtype = 1.00 # Constant with determines mean order size\n",
    "    #_invariance_c_factor =\"Invariance constant\"    \n",
    "    # TODO: Change invariance_m to property with exact calculation.  \n",
    "    # Does not affect substance of results, but does have modest effect on scaling.\n",
    "    #invariance_m : dtype = 0.60  # rescales INVARINCE_C, leave at 0.40\n",
    "    #x_invariance_m = \"Invariance moment ratio\"    # prefix 'x' drops from table\n",
    "\n",
    "    # Can change fraction to less than 0.50 (say 0.30?) to simulate a flash crash:\n",
    "    fraction_buy_orders_asset : dtype = 0.50\n",
    "    _fraction_buy_orders_asset = \"Fraction buy orders for indexes and assets\"    \n",
    "    # fraction_buy_orders_index : dtype = 0.50 # not used since index orders are treated like asset orders\n",
    "    \n",
    "    Bs_M : int = 0\n",
    "    _Bs_M = \"Number of orders for sparse portfolios of registered assets\"\n",
    "    Bs_Rmin : int = 1\n",
    "    _Bs_Rmin = \"Minimum number of registered assets in sparse order\"\n",
    "    Bs_Rmax : int = 5\n",
    "    _Bs_Rmax = \"Maximum number of registered assets in sparse order\"\n",
    "    Bs_Wscale : dtype = 1.00\n",
    "    _Bs_Wscale = \"Scaling factor for size of sparse orders\"\n",
    "    Bs_std_ph_dollars : dtype = 1.00\n",
    "    _Bs_std_ph_dollars = \"Std dev of ph minus value based on p0 for sparse order\"\n",
    "    \n",
    "    Bd_M : int = 0\n",
    "    _Bd_M = \"Number of orders for dense portfolios of registered assets\"\n",
    "    Bd_Rmin : int = 20\n",
    "    _Bd_Rmin = \"Minimum number of registered assets in dense order\"\n",
    "    Bd_Rmax : int = 50\n",
    "    _Bd_Rmax = \"Maximum number of registered assets in dense order\"\n",
    "    Bd_Wscale : dtype = 1.00\n",
    "    _Bd_Wscale = \"Scaling factor for size of dense orders\"\n",
    "    Bd_std_ph_dollars : dtype = 1.00\n",
    "    _Bd_std_ph_dollars = \"Std dev of ph minus value based on p0 for dense order\"\n",
    "    \n",
    "    #self.tie_breaker_weight = 0.00001\n",
    "    \n",
    "    fracMX : dtype = dataclasses.field(init=False)\n",
    "    fracM2 : dtype = dataclasses.field(init=False)\n",
    "    #fracM : dtype = dataclasses.field(init=False)\n",
    "    MX : int = dataclasses.field(init=False)\n",
    "    M2 : int = dataclasses.field(init=False)\n",
    "    MA : int = dataclasses.field(init=False)\n",
    "    M0 : int = dataclasses.field(init=False) # number of order by the exchange (one buy order and one sell order for each asset)\n",
    "    M0s : int = dataclasses.field(init=False) # number of order by the exchange (one buy order and one sell order for each asset)\n",
    "    M1 : int = dataclasses.field(init=False)  # number of single portfolio order assets and indexes, excludes exchange\n",
    "    Mall : int = dataclasses.field(init=False)  # total number of orders\n",
    "    NX : int = dataclasses.field(init=False)\n",
    "    NR : int = dataclasses.field(init=False)\n",
    "    ew_mkt_index_share : dtype = dataclasses.field(init=False)\n",
    "    vw_mkt_index_share : dtype = dataclasses.field(init=False)\n",
    "    industry_index_subshare : dtype = dataclasses.field(init=False)\n",
    "    ew_size_index_share : dtype = dataclasses.field(init=False)\n",
    "    vw_size_index_share :  dtype = dataclasses.field(init=False)\n",
    "    ew_industry_index_share :  dtype = dataclasses.field(init=False)\n",
    "    vw_industry_index_share :  dtype = dataclasses.field(init=False)\n",
    "    #invariance_c : dtype = dataclasses.field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        R = self.dtype\n",
    "\n",
    "        # TODO: Need to adjust code to handle various zero values:\n",
    "        assert 0.00 <= self.subfracMX and self.subfracMX <= 1.00\n",
    "        # assert self.MX > 0  # It may be okay if c.MX == 0!\n",
    "        assert 0.00 <= self.fracMA and self.fracMA <= 1.00\n",
    "        assert self.num_size_indexes > 0\n",
    "        assert self.num_industry_indexes > 0\n",
    "        assert self.num_size_indexes <= self.N\n",
    "        assert self.num_industry_indexes <= self.N\n",
    "\n",
    "        assert 0.00 < self.market_index_share and self.market_index_share < 1.00\n",
    "        assert 0.00 < self.size_index_subshare and self.size_index_subshare < 1.00\n",
    "        assert 0.00 < self.ew_mkt_index_subshare and self.ew_mkt_index_subshare < 1.00\n",
    "        assert 0.00 < self.ew_size_index_subsubshare and self.ew_size_index_subsubshare < 1.00\n",
    "        assert 0.00 < self.ew_industry_index_subsubshare and self.ew_industry_index_subsubshare < 1.00\n",
    "        \n",
    "        self.fracMX : dtype = (1.00 - self.fracMA) * self.subfracMX\n",
    "        self.fracM2 : R = (1.00 - self.fracMA) * (1.00 - self.subfracMX)\n",
    "        #self.fracM : int = int(self.fracMX * self.M)\n",
    "        self.MX : int = int(self.fracMX * self.M)\n",
    "        self.M2 : int = int(self.fracM2 * self.M)\n",
    "        self.MA : int = int(self.M - self.MX - self.M2)\n",
    "        # number of order by the exchange (one buy order and one sell order for each asset):\n",
    "        self.M0 : int = 2 * self.N if self.exch_epsilon != 0.00 else 0\n",
    "        # number of stabilizing orders (one buy order and one sell order for each asset)        \n",
    "        self.M0s : int = 2 * self.N  if self.stab_max_qv != 0.00 else 0\n",
    "        # number of single portfolio order assets and indexes, excludes exchange\n",
    "        self.M1 : int = self.MA + self.MX  \n",
    "        # total number of orders        \n",
    "        self.Mall : int = self.M0 + self.M0s + self.M1 + self.M2\n",
    "        self.NX : int = 2 * (1 + self.num_size_indexes + self.num_industry_indexes)\n",
    "        self.NR : int = self.N + self.NX\n",
    "\n",
    "        self.vw_mkt_index_share : R = self.market_index_share * (1.00 - self.ew_mkt_index_subshare)\n",
    "        self._vw_mkt_index_share = \"Probability an index order is for the value-weighted market index\"\n",
    "        self.ew_mkt_index_share : R = self.market_index_share * self.ew_mkt_index_subshare\n",
    "        self._ew_mkt_index_share = \"Probability an index order is for the equally-weighted market index\"\n",
    "        self.industry_index_subshare : R = 1.00 - self.size_index_subshare\n",
    "        self.vw_size_index_share : R = ((1.00 - self.market_index_share) * self.size_index_subshare\n",
    "                                        * (1.00 - self.ew_size_index_subsubshare))\n",
    "        self._vw_size_index_share = \"Probability an index order is for a value-weighted size index\"\n",
    "        self.ew_size_index_share : R = ((1.00 - self.market_index_share) * self.size_index_subshare \n",
    "                                        * self.ew_size_index_subsubshare)\n",
    "        self._ew_size_index_share = \"Probability an index order is for an equally-weighted size index\"\n",
    "        self.vw_industry_index_share : R = ((1.00 - self.market_index_share) * self.industry_index_subshare \n",
    "                                            * (1.00 - self.ew_industry_index_subsubshare))\n",
    "        self._vw_industry_index_share = \"Probability an index order is for a value-weighted industry index\"\n",
    "        self.ew_industry_index_share : R = ((1.00 - self.market_index_share) * self.industry_index_subshare \n",
    "                                            * self.ew_industry_index_subsubshare)\n",
    "        self._ew_industry_index_share = \"Probability an index order is for an equally-weighted industry index\"\n",
    "        #self.invariance_c : R = 1500.00 * self.invariance_c_factor / (self.M + 1)\n",
    "        \n",
    "        temp = (self.vw_mkt_index_share + self.ew_mkt_index_share \n",
    "                + self.ew_size_index_share + self.vw_size_index_share\n",
    "                + self.ew_industry_index_share + self.vw_industry_index_share)\n",
    "        # print(f\"{self.vw_mkt_index_share=}, {self.ew_mkt_index_share=}\")\n",
    "        # print(f\"{self.ew_size_index_share=}, {self.vw_size_index_share=}\")\n",
    "        # print(f\"{self.ew_industry_index_share=}, {self.vw_industry_index_share=}\")\n",
    "\n",
    "        assert np.isclose(temp, 1.00), \"PKError: res = \" + str(temp) + \". Shares should add up to one!\"\n",
    "        \n",
    "    def make_documentation_table(self):\n",
    "        d = dataclasses.asdict(self)\n",
    "        vns = []\n",
    "        docstrings = []\n",
    "        values = []\n",
    "        for k in d:\n",
    "            try:\n",
    "                v = getattr(self, k)\n",
    "                cv = getattr(self, \"_\" + k)\n",
    "                vns.append(k)\n",
    "                docstrings.append(cv)\n",
    "                values.append(v)\n",
    "            except:\n",
    "                pass\n",
    "        df = pd.DataFrame({'Parameter' : vns, 'Base' : values, 'Description' : docstrings}, dtype=object)\n",
    "        return df\n",
    "\n",
    "    \n",
    "def test_assumptions_display():    \n",
    "    c = Assumptions()\n",
    "\n",
    "    pd.options.display.float_format = format_pd\n",
    "    pd.set_option('display.max_colwidth', 100)    \n",
    "    #print(c.make_documentation_table())\n",
    "    display(c.make_documentation_table())\n",
    "\n",
    "test_assumptions_display()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below converts the Assumptions() into a dictionary and displays the results.\n",
    "\n",
    "Note that properties are not in the dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 99,\n",
       " 'M': 100000,\n",
       " 'exch_liq_model': 'mina',\n",
       " 'exch_epsilon': 0.01,\n",
       " 'exch_phpl_frac': 100.0,\n",
       " 'stab_max_qv': 0.0,\n",
       " 'stab_ph_frac': 0.7,\n",
       " 'stab_pl_frac': 0.2,\n",
       " 'fracMA': 0.5,\n",
       " 'subfracMX': 0.5,\n",
       " 'num_size_indexes': 15,\n",
       " 'num_industry_indexes': 3,\n",
       " 'market_index_share': 0.8,\n",
       " 'size_index_subshare': 0.5,\n",
       " 'ew_mkt_index_subshare': 0.0625,\n",
       " 'ew_size_index_subsubshare': 0.25,\n",
       " 'ew_industry_index_subsubshare': 0.25,\n",
       " 'ew_size_index_alpha': 0.0,\n",
       " 'std_num_orders_asset': 1.7,\n",
       " 'std_order_size': 1.5,\n",
       " 'dv_single_asset_orders': 10000000.0,\n",
       " 'std_limit_price': 0.1,\n",
       " 'limit_bias': 0.3,\n",
       " 'avg_ph_minus_pl_bp': 1.0,\n",
       " 'std_ph_minus_pl': 2.0,\n",
       " 'index_prices': 100.0,\n",
       " 'mean_asset_price': 100.0,\n",
       " 'std_asset_price': 0.0,\n",
       " 'invariance_exponent': 0.3333333333333333,\n",
       " 'fraction_buy_orders_asset': 0.5,\n",
       " 'Bs_M': 0,\n",
       " 'Bs_Rmin': 1,\n",
       " 'Bs_Rmax': 5,\n",
       " 'Bs_Wscale': 1.0,\n",
       " 'Bs_std_ph_dollars': 1.0,\n",
       " 'Bd_M': 0,\n",
       " 'Bd_Rmin': 20,\n",
       " 'Bd_Rmax': 50,\n",
       " 'Bd_Wscale': 1.0,\n",
       " 'Bd_std_ph_dollars': 1.0,\n",
       " 'fracMX': 0.25,\n",
       " 'fracM2': 0.25,\n",
       " 'MX': 25000,\n",
       " 'M2': 25000,\n",
       " 'MA': 50000,\n",
       " 'M0': 198,\n",
       " 'M0s': 0,\n",
       " 'M1': 75000,\n",
       " 'Mall': 100198,\n",
       " 'NX': 38,\n",
       " 'NR': 137,\n",
       " 'ew_mkt_index_share': 0.05,\n",
       " 'vw_mkt_index_share': 0.75,\n",
       " 'industry_index_subshare': 0.5,\n",
       " 'ew_size_index_share': 0.024999999999999994,\n",
       " 'vw_size_index_share': 0.07499999999999998,\n",
       " 'ew_industry_index_share': 0.024999999999999994,\n",
       " 'vw_industry_index_share': 0.07499999999999998}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_display_Assumptions():\n",
    "    c = Assumptions(**{'N' : 99, 'num_size_indexes' : 15, 'num_industry_indexes' : 3})\n",
    "    display(dataclasses.asdict(c))\n",
    "\n",
    "test_display_Assumptions()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OrderBook class\n",
    "\n",
    "The order book class handles the manner in which Assumptions are used to generate a book of orders.\n",
    "\n",
    "There are several different kinds of orders:\n",
    "\n",
    "1. Orders for individual assets, generated randomly.\n",
    "2. Orders for portfolios, generated randomly.\n",
    "3. Orders for \"pairs trades\", which buy one asset or portfolio and sell another asset or portfolio in equal dollar amounts based on initial prices.\n",
    "4. Modest \"market making\" orders placed by the exchange; such orders buy if the price is below the initial price and sell if it is aove the initial price, up to some limit defined as a large percentage price change.\n",
    "5. \"Stabilizing\" orders which buy if prices fall a significant amount and sell if prices rise a significant amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assumptions(N=12, M=300, exch_liq_model='mina', exch_epsilon=0.0, exch_phpl_frac=100.0, stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, fracMA=0.5, subfracMX=0.5, num_size_indexes=2, num_industry_indexes=4, market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, std_num_orders_asset=1.7, std_order_size=1.5, dv_single_asset_orders=10000000.0, std_limit_price=0.1, limit_bias=0.3, avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0, index_prices=100.0, mean_asset_price=100.0, std_asset_price=0.0, invariance_exponent=0.3333333333333333, fraction_buy_orders_asset=0.5, Bs_M=100, Bs_Rmin=1, Bs_Rmax=5, Bs_Wscale=1.0, Bs_std_ph_dollars=1.0, Bd_M=100, Bd_Rmin=20, Bd_Rmax=50, Bd_Wscale=1.0, Bd_std_ph_dollars=1.0, fracMX=0.25, fracM2=0.25, MX=75, M2=75, MA=150, M0=0, M0s=0, M1=225, Mall=300, NX=14, NR=26, ew_mkt_index_share=0.05, vw_mkt_index_share=0.75, industry_index_subshare=0.5, ew_size_index_share=0.024999999999999994, vw_size_index_share=0.07499999999999998, ew_industry_index_share=0.024999999999999994, vw_industry_index_share=0.07499999999999998) \n",
      "\n",
      "bk.RX_mat.T, <class 'numpy.ndarray'>, float64, shape= (14, 12) = 168, nnz= 168 , fracnz= 1.0, nans= 0, L1= 2.776423793555758, \n",
      "\n",
      "bk.RX_mat.T:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.99161694e-01, 3.12899599e-01, 4.13916642e-02, 2.03915958e-02,\n",
       "        6.52505888e-03, 5.64012930e-03, 5.53999738e-03, 3.51416544e-03,\n",
       "        1.81859663e-03, 1.59405946e-03, 9.78210468e-04, 5.45229632e-04],\n",
       "       [8.33333333e-02, 8.33333333e-02, 8.33333333e-02, 8.33333333e-02,\n",
       "        8.33333333e-02, 8.33333333e-02, 8.33333333e-02, 8.33333333e-02,\n",
       "        8.33333333e-02, 8.33333333e-02, 8.33333333e-02, 8.33333333e-02],\n",
       "       [6.07663058e-01, 3.17339257e-01, 4.19789608e-02, 2.06809273e-02,\n",
       "        6.61764139e-03, 5.72015576e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.95989622e-01, 2.51186589e-01,\n",
       "        1.29990204e-01, 1.13940668e-01, 6.99208262e-02, 3.89720899e-02],\n",
       "       [1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.66666667e-01, 1.66666667e-01,\n",
       "        1.66666667e-01, 1.66666667e-01, 1.66666667e-01, 1.66666667e-01],\n",
       "       [9.86265709e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.07407431e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.99354834e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 9.77402608e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.76180382e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.97935402e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.63948544e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.15633733e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.04177224e-02, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.33978300e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.43722823e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.22988768e-02],\n",
       "       [3.33333333e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.33333333e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.33333333e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 3.33333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.33333333e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33333333e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_index_stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dv_share</th>\n",
       "      <th>gamma</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>dv</th>\n",
       "      <th>asset_start</th>\n",
       "      <th>asset_stop</th>\n",
       "      <th>asset_stride</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vw_market</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.750</td>\n",
       "      <td>37.219</td>\n",
       "      <td>37.219</td>\n",
       "      <td>62970.588</td>\n",
       "      <td>629.706</td>\n",
       "      <td>2343699.308</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>23436.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ew_market</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>6.119</td>\n",
       "      <td>6.119</td>\n",
       "      <td>25533.322</td>\n",
       "      <td>255.333</td>\n",
       "      <td>156246.621</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1562.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vw_size_00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.075</td>\n",
       "      <td>8.019</td>\n",
       "      <td>8.019</td>\n",
       "      <td>29228.358</td>\n",
       "      <td>292.284</td>\n",
       "      <td>234369.931</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2343.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vw_size_01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ew_size_00</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2.942</td>\n",
       "      <td>2.942</td>\n",
       "      <td>17703.817</td>\n",
       "      <td>177.038</td>\n",
       "      <td>52082.207</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>520.822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker  n      p0  sigma  dv_share  gamma  num_orders  avg_order_dollars  avg_order_shares          dv  asset_start  asset_stop  asset_stride         v\n",
       "0   vw_market  0 100.000  0.020     0.750 37.219      37.219          62970.588           629.706 2343699.308            0          12             1 23436.993\n",
       "1   ew_market  1 100.000  0.020     0.050  6.119       6.119          25533.322           255.333  156246.621            0          12             1  1562.466\n",
       "2  vw_size_00  2 100.000  0.020     0.075  8.019       8.019          29228.358           292.284  234369.931            0           6             1  2343.699\n",
       "3  vw_size_01  3 100.000  0.020     0.000  0.000       0.000              0.000             0.000       0.000            6          12             1     0.000\n",
       "4  ew_size_00  4 100.000  0.020     0.017  2.942       2.942          17703.817           177.038   52082.207            0           6             1   520.822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dv_share</th>\n",
       "      <th>gamma</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>dv</th>\n",
       "      <th>asset_start</th>\n",
       "      <th>asset_stop</th>\n",
       "      <th>asset_stride</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vw_ind_03</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.182</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>58592.483</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>585.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ew_ind_00</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ew_ind_01</td>\n",
       "      <td>11</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ew_ind_02</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ew_ind_03</td>\n",
       "      <td>13</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker   n      p0  sigma  dv_share  gamma  num_orders  avg_order_dollars  avg_order_shares        dv  asset_start  asset_stop  asset_stride       v\n",
       "9   vw_ind_03   9 100.000  0.020     0.019  3.182       3.182          18412.712           184.127 58592.483            3          12             4 585.925\n",
       "10  ew_ind_00  10 100.000  0.020     0.006  1.530       1.530          12766.661           127.667 19530.828            0          12             4 195.308\n",
       "11  ew_ind_01  11 100.000  0.020     0.006  1.530       1.530          12766.661           127.667 19530.828            1          12             4 195.308\n",
       "12  ew_ind_02  12 100.000  0.020     0.006  1.530       1.530          12766.661           127.667 19530.828            2          12             4 195.308\n",
       "13  ew_ind_03  13 100.000  0.020     0.006  1.530       1.530          12766.661           127.667 19530.828            3          12             4 195.308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_asset_stats:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>sigma</th>\n",
       "      <th>p0</th>\n",
       "      <th>gamma</th>\n",
       "      <th>dv_share</th>\n",
       "      <th>dv</th>\n",
       "      <th>mc_over_sigma_const</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>v</th>\n",
       "      <th>ticker</th>\n",
       "      <th>asset_start</th>\n",
       "      <th>asset_stop</th>\n",
       "      <th>asset_stride</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69.587</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>69.587</td>\n",
       "      <td>0.599</td>\n",
       "      <td>5991616.940</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>59916.169</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45.127</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>45.127</td>\n",
       "      <td>0.313</td>\n",
       "      <td>3128995.987</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>31289.960</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.716</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>11.716</td>\n",
       "      <td>0.041</td>\n",
       "      <td>413916.642</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>35329.819</td>\n",
       "      <td>353.298</td>\n",
       "      <td>4139.166</td>\n",
       "      <td>asset_0002</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.308</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>7.308</td>\n",
       "      <td>0.020</td>\n",
       "      <td>203915.958</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>27903.211</td>\n",
       "      <td>279.032</td>\n",
       "      <td>2039.160</td>\n",
       "      <td>asset_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.419</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>3.419</td>\n",
       "      <td>0.007</td>\n",
       "      <td>65250.589</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>19085.283</td>\n",
       "      <td>190.853</td>\n",
       "      <td>652.506</td>\n",
       "      <td>asset_0004</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n  num_orders  sigma      p0  gamma  dv_share          dv  mc_over_sigma_const  avg_order_dollars  avg_order_shares         v      ticker  asset_start  asset_stop  asset_stride\n",
       "ndx                                                                                                                                                                                  \n",
       "0    0      69.587  0.020 100.000 69.587     0.599 5991616.940            10321.806          86103.036           861.030 59916.169  asset_0000            0           1             1\n",
       "1    1      45.127  0.020 100.000 45.127     0.313 3128995.987            10321.806          69338.129           693.381 31289.960  asset_0001            1           2             1\n",
       "2    2      11.716  0.020 100.000 11.716     0.041  413916.642            10321.806          35329.819           353.298  4139.166  asset_0002            2           3             1\n",
       "3    3       7.308  0.020 100.000  7.308     0.020  203915.958            10321.806          27903.211           279.032  2039.160  asset_0003            3           4             1\n",
       "4    4       3.419  0.020 100.000  3.419     0.007   65250.589            10321.806          19085.283           190.853   652.506  asset_0004            4           5             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>sigma</th>\n",
       "      <th>p0</th>\n",
       "      <th>gamma</th>\n",
       "      <th>dv_share</th>\n",
       "      <th>dv</th>\n",
       "      <th>mc_over_sigma_const</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>v</th>\n",
       "      <th>ticker</th>\n",
       "      <th>asset_start</th>\n",
       "      <th>asset_stop</th>\n",
       "      <th>asset_stride</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.004</td>\n",
       "      <td>35141.654</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>15527.845</td>\n",
       "      <td>155.278</td>\n",
       "      <td>351.417</td>\n",
       "      <td>asset_0007</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.459</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.459</td>\n",
       "      <td>0.002</td>\n",
       "      <td>18185.966</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>12466.635</td>\n",
       "      <td>124.666</td>\n",
       "      <td>181.860</td>\n",
       "      <td>asset_0008</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.336</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.336</td>\n",
       "      <td>0.002</td>\n",
       "      <td>15940.595</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>11930.866</td>\n",
       "      <td>119.309</td>\n",
       "      <td>159.406</td>\n",
       "      <td>asset_0009</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.001</td>\n",
       "      <td>9782.105</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>10138.675</td>\n",
       "      <td>101.387</td>\n",
       "      <td>97.821</td>\n",
       "      <td>asset_0010</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.020</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5452.296</td>\n",
       "      <td>10321.806</td>\n",
       "      <td>8343.795</td>\n",
       "      <td>83.438</td>\n",
       "      <td>54.523</td>\n",
       "      <td>asset_0011</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n  num_orders  sigma      p0  gamma  dv_share        dv  mc_over_sigma_const  avg_order_dollars  avg_order_shares       v      ticker  asset_start  asset_stop  asset_stride\n",
       "ndx                                                                                                                                                                               \n",
       "7     7       2.263  0.020 100.000  2.263     0.004 35141.654            10321.806          15527.845           155.278 351.417  asset_0007            7           8             1\n",
       "8     8       1.459  0.020 100.000  1.459     0.002 18185.966            10321.806          12466.635           124.666 181.860  asset_0008            8           9             1\n",
       "9     9       1.336  0.020 100.000  1.336     0.002 15940.595            10321.806          11930.866           119.309 159.406  asset_0009            9          10             1\n",
       "10   10       0.965  0.020 100.000  0.965     0.001  9782.105            10321.806          10138.675           101.387  97.821  asset_0010           10          11             1\n",
       "11   11       0.653  0.020 100.000  0.653     0.001  5452.296            10321.806           8343.795            83.438  54.523  asset_0011           11          12             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_exchange:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>w</th>\n",
       "      <th>ph</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, w, ph, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>w</th>\n",
       "      <th>ph</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, w, ph, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>w</th>\n",
       "      <th>ph</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, w, ph, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_stabilizing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>ph</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, ph, w, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>ph</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, ph, w, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dv</th>\n",
       "      <th>v</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>n</th>\n",
       "      <th>ph</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>pl</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dv, v, p0, sigma, n, ph, w, q, ph_minus_pl_dollars, pl, order_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_single_asset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>n</th>\n",
       "      <th>ticker</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>p0</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>w</th>\n",
       "      <th>rv_limit_price</th>\n",
       "      <th>ph</th>\n",
       "      <th>pl</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1237.850</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.029</td>\n",
       "      <td>99.904</td>\n",
       "      <td>99.904</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>583.355</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>-91.925</td>\n",
       "      <td>-91.926</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>842.823</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.033</td>\n",
       "      <td>-106.324</td>\n",
       "      <td>-106.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>66.566</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.878</td>\n",
       "      <td>84.785</td>\n",
       "      <td>84.785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>105.163</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-99.878</td>\n",
       "      <td>-99.879</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  n      ticker  avg_order_dollars  avg_order_shares      p0        q  ph_minus_pl_bp      w  rv_limit_price       ph       pl  ph_minus_pl_dollars  order_type\n",
       "0  0  0  asset_0000          86103.036           861.030 100.000 1237.850           0.007  1.000           1.029   99.904   99.904                0.000           1\n",
       "1  1  0  asset_0000          86103.036           861.030 100.000  583.355           0.122 -1.000           0.889  -91.925  -91.926                0.001           1\n",
       "2  2  0  asset_0000          86103.036           861.030 100.000  842.823           0.028 -1.000           1.033 -106.324 -106.324                0.000           1\n",
       "3  3  0  asset_0000          86103.036           861.030 100.000   66.566           0.010  1.000           0.878   84.785   84.785                0.000           1\n",
       "4  4  0  asset_0000          86103.036           861.030 100.000  105.163           0.110 -1.000           0.969  -99.878  -99.879                0.001           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>n</th>\n",
       "      <th>ticker</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>p0</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>w</th>\n",
       "      <th>rv_limit_price</th>\n",
       "      <th>ph</th>\n",
       "      <th>pl</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>21</td>\n",
       "      <td>vw_ind_03</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>100.000</td>\n",
       "      <td>30.768</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.926</td>\n",
       "      <td>-95.612</td>\n",
       "      <td>-95.612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>22</td>\n",
       "      <td>ew_ind_00</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>100.000</td>\n",
       "      <td>709.540</td>\n",
       "      <td>0.142</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>92.972</td>\n",
       "      <td>92.970</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>23</td>\n",
       "      <td>ew_ind_01</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>100.000</td>\n",
       "      <td>37.176</td>\n",
       "      <td>4.578</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.029</td>\n",
       "      <td>99.917</td>\n",
       "      <td>99.871</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>24</td>\n",
       "      <td>ew_ind_02</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>100.000</td>\n",
       "      <td>213.705</td>\n",
       "      <td>4.863</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-88.018</td>\n",
       "      <td>-88.060</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>24</td>\n",
       "      <td>ew_ind_02</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>100.000</td>\n",
       "      <td>247.312</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.067</td>\n",
       "      <td>-109.750</td>\n",
       "      <td>-109.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i   n     ticker  avg_order_dollars  avg_order_shares      p0       q  ph_minus_pl_bp      w  rv_limit_price       ph       pl  ph_minus_pl_dollars  order_type\n",
       "220  220  21  vw_ind_03          18412.712           184.127 100.000  30.768           0.032 -1.000           0.926  -95.612  -95.612                0.000           1\n",
       "221  221  22  ew_ind_00          12766.661           127.667 100.000 709.540           0.142  1.000           0.960   92.972   92.970                0.001           1\n",
       "222  222  23  ew_ind_01          12766.661           127.667 100.000  37.176           4.578  1.000           1.029   99.917   99.871                0.047           1\n",
       "223  223  24  ew_ind_02          12766.661           127.667 100.000 213.705           4.863 -1.000           0.850  -88.018  -88.060                0.041           1\n",
       "224  224  24  ew_ind_02          12766.661           127.667 100.000 247.312           0.026 -1.000           1.067 -109.750 -109.750                0.000           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_pairs_trade:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>n_buy</th>\n",
       "      <th>n_sell</th>\n",
       "      <th>n_x</th>\n",
       "      <th>avg_order_dollars_buy</th>\n",
       "      <th>avg_order_shares_buy</th>\n",
       "      <th>p_buy</th>\n",
       "      <th>ticker_buy</th>\n",
       "      <th>n_y</th>\n",
       "      <th>avg_order_dollars_sell</th>\n",
       "      <th>avg_order_shares_sell</th>\n",
       "      <th>p_sell</th>\n",
       "      <th>ticker_sell</th>\n",
       "      <th>rv_order_dollars_buy</th>\n",
       "      <th>rv_order_dollars_sell</th>\n",
       "      <th>order_dollars_buy</th>\n",
       "      <th>order_dollars_sell</th>\n",
       "      <th>order_dollars</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>w_buy</th>\n",
       "      <th>w_sell</th>\n",
       "      <th>rv_limit_price</th>\n",
       "      <th>ph</th>\n",
       "      <th>pl</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>1</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.299</td>\n",
       "      <td>56553.837</td>\n",
       "      <td>20725.391</td>\n",
       "      <td>20725.391</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>207.254</td>\n",
       "      <td>-207.254</td>\n",
       "      <td>0.967</td>\n",
       "      <td>-688.615</td>\n",
       "      <td>-688.699</td>\n",
       "      <td>0.084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>1</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>2.337</td>\n",
       "      <td>0.134</td>\n",
       "      <td>201227.139</td>\n",
       "      <td>9277.271</td>\n",
       "      <td>9277.271</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>92.773</td>\n",
       "      <td>-92.773</td>\n",
       "      <td>0.931</td>\n",
       "      <td>-635.785</td>\n",
       "      <td>-635.903</td>\n",
       "      <td>0.118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>1</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.421</td>\n",
       "      <td>45783.501</td>\n",
       "      <td>29214.923</td>\n",
       "      <td>29214.923</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.586</td>\n",
       "      <td>292.149</td>\n",
       "      <td>-292.149</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1936.378</td>\n",
       "      <td>1934.666</td>\n",
       "      <td>1.712</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>1</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.019</td>\n",
       "      <td>10092.872</td>\n",
       "      <td>1284.823</td>\n",
       "      <td>1284.823</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>12.848</td>\n",
       "      <td>-12.848</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-35.325</td>\n",
       "      <td>-35.326</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>1</td>\n",
       "      <td>69338.129</td>\n",
       "      <td>693.381</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0001</td>\n",
       "      <td>0.021</td>\n",
       "      <td>4.577</td>\n",
       "      <td>1812.635</td>\n",
       "      <td>317334.577</td>\n",
       "      <td>1812.635</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>18.126</td>\n",
       "      <td>-18.126</td>\n",
       "      <td>0.920</td>\n",
       "      <td>-145.265</td>\n",
       "      <td>-145.275</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  n_buy  n_sell  n_x  avg_order_dollars_buy  avg_order_shares_buy   p_buy  ticker_buy  n_y  avg_order_dollars_sell  avg_order_shares_sell  p_sell ticker_sell  rv_order_dollars_buy  \\\n",
       "0  0      0       1    0              86103.036               861.030 100.000  asset_0000    1               69338.129                693.381 100.000  asset_0001                 0.657   \n",
       "1  1      0       1    0              86103.036               861.030 100.000  asset_0000    1               69338.129                693.381 100.000  asset_0001                 2.337   \n",
       "2  2      0       1    0              86103.036               861.030 100.000  asset_0000    1               69338.129                693.381 100.000  asset_0001                 0.532   \n",
       "3  3      0       1    0              86103.036               861.030 100.000  asset_0000    1               69338.129                693.381 100.000  asset_0001                 0.117   \n",
       "4  4      0       1    0              86103.036               861.030 100.000  asset_0000    1               69338.129                693.381 100.000  asset_0001                 0.021   \n",
       "\n",
       "   rv_order_dollars_sell  order_dollars_buy  order_dollars_sell  order_dollars     q  ph_minus_pl_bp   w_buy   w_sell  rv_limit_price       ph       pl  ph_minus_pl_dollars  order_type  \n",
       "0                  0.299          56553.837           20725.391      20725.391 1.000           0.040 207.254 -207.254           0.967 -688.615 -688.699                0.084           2  \n",
       "1                  0.134         201227.139            9277.271       9277.271 1.000           0.127  92.773  -92.773           0.931 -635.785 -635.903                0.118           2  \n",
       "2                  0.421          45783.501           29214.923      29214.923 1.000           0.586 292.149 -292.149           1.066 1936.378 1934.666                1.712           2  \n",
       "3                  0.019          10092.872            1284.823       1284.823 1.000           0.006  12.848  -12.848           0.973  -35.325  -35.326                0.001           2  \n",
       "4                  4.577           1812.635          317334.577       1812.635 1.000           0.055  18.126  -18.126           0.920 -145.265 -145.275                0.010           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>n_buy</th>\n",
       "      <th>n_sell</th>\n",
       "      <th>n_x</th>\n",
       "      <th>avg_order_dollars_buy</th>\n",
       "      <th>avg_order_shares_buy</th>\n",
       "      <th>p_buy</th>\n",
       "      <th>ticker_buy</th>\n",
       "      <th>n_y</th>\n",
       "      <th>avg_order_dollars_sell</th>\n",
       "      <th>avg_order_shares_sell</th>\n",
       "      <th>p_sell</th>\n",
       "      <th>ticker_sell</th>\n",
       "      <th>rv_order_dollars_buy</th>\n",
       "      <th>rv_order_dollars_sell</th>\n",
       "      <th>order_dollars_buy</th>\n",
       "      <th>order_dollars_sell</th>\n",
       "      <th>order_dollars</th>\n",
       "      <th>q</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>w_buy</th>\n",
       "      <th>w_sell</th>\n",
       "      <th>rv_limit_price</th>\n",
       "      <th>ph</th>\n",
       "      <th>pl</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>14051.529</td>\n",
       "      <td>140.515</td>\n",
       "      <td>100.000</td>\n",
       "      <td>ew_size_01</td>\n",
       "      <td>3</td>\n",
       "      <td>27903.211</td>\n",
       "      <td>279.032</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0003</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.669</td>\n",
       "      <td>2316.712</td>\n",
       "      <td>18675.643</td>\n",
       "      <td>2316.712</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>23.167</td>\n",
       "      <td>-23.167</td>\n",
       "      <td>0.959</td>\n",
       "      <td>-95.186</td>\n",
       "      <td>-95.226</td>\n",
       "      <td>0.039</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>100.000</td>\n",
       "      <td>vw_ind_02</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.255</td>\n",
       "      <td>1309.879</td>\n",
       "      <td>21965.705</td>\n",
       "      <td>1309.879</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.688</td>\n",
       "      <td>13.099</td>\n",
       "      <td>-13.099</td>\n",
       "      <td>0.870</td>\n",
       "      <td>-170.024</td>\n",
       "      <td>-170.114</td>\n",
       "      <td>0.090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>100.000</td>\n",
       "      <td>vw_ind_02</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.647</td>\n",
       "      <td>1770.841</td>\n",
       "      <td>314025.046</td>\n",
       "      <td>1770.841</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>17.708</td>\n",
       "      <td>-17.708</td>\n",
       "      <td>1.036</td>\n",
       "      <td>63.884</td>\n",
       "      <td>63.879</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>100.000</td>\n",
       "      <td>vw_ind_02</td>\n",
       "      <td>12</td>\n",
       "      <td>62970.588</td>\n",
       "      <td>629.706</td>\n",
       "      <td>100.000</td>\n",
       "      <td>vw_market</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5614.975</td>\n",
       "      <td>62845.973</td>\n",
       "      <td>5614.975</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>56.150</td>\n",
       "      <td>-56.150</td>\n",
       "      <td>0.885</td>\n",
       "      <td>-647.925</td>\n",
       "      <td>-647.977</td>\n",
       "      <td>0.051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>100.000</td>\n",
       "      <td>ew_ind_03</td>\n",
       "      <td>0</td>\n",
       "      <td>86103.036</td>\n",
       "      <td>861.030</td>\n",
       "      <td>100.000</td>\n",
       "      <td>asset_0000</td>\n",
       "      <td>3.415</td>\n",
       "      <td>0.501</td>\n",
       "      <td>43597.449</td>\n",
       "      <td>43137.150</td>\n",
       "      <td>43137.150</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.199</td>\n",
       "      <td>431.371</td>\n",
       "      <td>-431.371</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1999.618</td>\n",
       "      <td>1994.446</td>\n",
       "      <td>5.171</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     i  n_buy  n_sell  n_x  avg_order_dollars_buy  avg_order_shares_buy   p_buy  ticker_buy  n_y  avg_order_dollars_sell  avg_order_shares_sell  p_sell ticker_sell  rv_order_dollars_buy  \\\n",
       "70  70     17       3   17              14051.529               140.515 100.000  ew_size_01    3               27903.211                279.032 100.000  asset_0003                 0.165   \n",
       "71  71     20       0   20              18412.712               184.127 100.000   vw_ind_02    0               86103.036                861.030 100.000  asset_0000                 0.071   \n",
       "72  72     20       0   20              18412.712               184.127 100.000   vw_ind_02    0               86103.036                861.030 100.000  asset_0000                 0.096   \n",
       "73  73     20      12   20              18412.712               184.127 100.000   vw_ind_02   12               62970.588                629.706 100.000   vw_market                 0.305   \n",
       "74  74     25       0   25              12766.661               127.667 100.000   ew_ind_03    0               86103.036                861.030 100.000  asset_0000                 3.415   \n",
       "\n",
       "    rv_order_dollars_sell  order_dollars_buy  order_dollars_sell  order_dollars     q  ph_minus_pl_bp   w_buy   w_sell  rv_limit_price       ph       pl  ph_minus_pl_dollars  order_type  \n",
       "70                  0.669           2316.712           18675.643       2316.712 1.000           0.170  23.167  -23.167           0.959  -95.186  -95.226                0.039           2  \n",
       "71                  0.255           1309.879           21965.705       1309.879 1.000           0.688  13.099  -13.099           0.870 -170.024 -170.114                0.090           2  \n",
       "72                  3.647           1770.841          314025.046       1770.841 1.000           0.031  17.708  -17.708           1.036   63.884   63.879                0.005           2  \n",
       "73                  0.998           5614.975           62845.973       5614.975 1.000           0.091  56.150  -56.150           0.885 -647.925 -647.977                0.051           2  \n",
       "74                  0.501          43597.449           43137.150      43137.150 1.000           1.199 431.371 -431.371           1.046 1999.618 1994.446                5.171           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_sparse:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>nnz_order</th>\n",
       "      <th>q</th>\n",
       "      <th>dollars_per_order</th>\n",
       "      <th>ph</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.312</td>\n",
       "      <td>-3.150</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.106</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>0.090</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.143</td>\n",
       "      <td>-3.571</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  nnz_order     q  dollars_per_order     ph  ph_minus_pl_bp  ph_minus_pl_dollars     0     1     2     3     4     5      6      7     8     9    10    11    12    13    14     15    16    17  \\\n",
       "0  0          2 1.000             -2.312 -3.150         100.000                0.010 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 0.000 0.000   \n",
       "1  1          3 1.000             -0.049 -0.744         100.000                0.010 0.000 0.000 0.000 0.000 0.000 0.000 -0.004  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 0.000 0.004   \n",
       "2  2          3 1.000             -1.106 -0.808         100.000                0.010 0.000 0.000 0.000 0.000 0.000 0.000  0.000 -0.008 0.000 0.000 0.000 0.000 0.000 0.002 0.000  0.000 0.000 0.000   \n",
       "3  3          2 1.000             -0.600  0.090         100.000                0.010 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 0.000 0.000   \n",
       "4  4          2 1.000             -2.143 -3.571         100.000                0.010 0.000 0.000 0.000 0.000 0.000 0.000  0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.021 0.000 0.000   \n",
       "\n",
       "      18     19     20    21     22    23    24     25  order_type  \n",
       "0  0.000  0.000 -0.008 0.000  0.000 0.000 0.000 -0.015         999  \n",
       "1  0.000  0.000  0.000 0.000  0.000 0.000 0.000  0.000         999  \n",
       "2  0.000 -0.005  0.000 0.000  0.000 0.000 0.000  0.000         999  \n",
       "3 -0.004  0.000  0.000 0.000 -0.002 0.000 0.000  0.000         999  \n",
       "4  0.000  0.000  0.000 0.000  0.000 0.000 0.000  0.000         999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>nnz_order</th>\n",
       "      <th>q</th>\n",
       "      <th>dollars_per_order</th>\n",
       "      <th>ph</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.040</td>\n",
       "      <td>3.545</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-1.399</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.211</td>\n",
       "      <td>-1.795</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     i  nnz_order     q  dollars_per_order     ph  ph_minus_pl_bp  ph_minus_pl_dollars      0      1     2     3     4     5     6     7     8      9     10    11    12    13    14    15    16  \\\n",
       "95  95          4 1.000              2.040  3.545         100.000                0.010  0.012  0.000 0.000 0.000 0.010 0.000 0.000 0.012 0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "96  96          1 1.000             -0.841 -1.399         100.000                0.010  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000 -0.008 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "97  97          1 1.000             -0.024 -0.411         100.000                0.010  0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "98  98          1 1.000             -0.211 -1.795         100.000                0.010  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.002  0.000 0.000 0.000 0.000 0.000 0.000 0.000   \n",
       "99  99          4 1.000              0.834 -0.119         100.000                0.010 -0.004  0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000  0.000  0.000 0.000 0.000 0.000 0.000 0.000 0.011   \n",
       "\n",
       "      17    18    19    20     21    22    23    24     25  order_type  \n",
       "95 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000 -0.013         999  \n",
       "96 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000  0.000         999  \n",
       "97 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000  0.000         999  \n",
       "98 0.000 0.000 0.000 0.000  0.000 0.000 0.000 0.000  0.000         999  \n",
       "99 0.000 0.000 0.000 0.000 -0.004 0.005 0.000 0.000  0.000         999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_dense:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>nnz_order</th>\n",
       "      <th>q</th>\n",
       "      <th>dollars_per_order</th>\n",
       "      <th>ph</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.850</td>\n",
       "      <td>-1.337</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-6.311</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-5.916</td>\n",
       "      <td>-5.712</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-7.864</td>\n",
       "      <td>-7.713</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.468</td>\n",
       "      <td>-1.445</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  nnz_order     q  dollars_per_order     ph  ph_minus_pl_bp  ph_minus_pl_dollars      0      1      2      3      4      5      6      7      8      9     10     11     12    13     14     15  \\\n",
       "0  0         42 1.000             -1.850 -1.337         100.000                0.010 -0.008 -0.002  0.003 -0.003 -0.008  0.029 -0.002  0.000  0.003  0.016 -0.010  0.000 -0.032 0.000 -0.004 -0.015   \n",
       "1  1         25 1.000             -6.311 -7.043         100.000                0.010  0.000 -0.022  0.009  0.010 -0.007  0.000 -0.007  0.002 -0.011 -0.008  0.003  0.000 -0.005 0.003  0.000 -0.007   \n",
       "2  2         22 1.000             -5.916 -5.712         100.000                0.010  0.001 -0.012  0.000  0.000  0.004 -0.009  0.000 -0.011  0.006 -0.005 -0.014  0.000  0.000 0.000 -0.001 -0.008   \n",
       "3  3         38 1.000             -7.864 -7.713         100.000                0.010 -0.003  0.004  0.000  0.017  0.000  0.002  0.000  0.012 -0.008  0.005 -0.001 -0.014 -0.016 0.019 -0.019  0.000   \n",
       "4  4         35 1.000             -1.468 -1.445         100.000                0.010 -0.012 -0.008 -0.002  0.001  0.000  0.000 -0.004  0.024  0.000 -0.006  0.026  0.000 -0.023 0.000  0.004 -0.020   \n",
       "\n",
       "      16     17     18     19     20     21     22     23     24     25  order_type  \n",
       "0  0.006  0.000  0.005  0.000 -0.000 -0.005  0.004  0.000  0.005 -0.003         999  \n",
       "1  0.000  0.000 -0.016  0.006 -0.001  0.000  0.000  0.006 -0.006 -0.012         999  \n",
       "2 -0.011  0.000  0.000  0.000  0.007 -0.024  0.000  0.009  0.000  0.010         999  \n",
       "3  0.001 -0.017 -0.011 -0.022 -0.011 -0.003 -0.008 -0.015  0.000  0.006         999  \n",
       "4  0.000  0.000  0.000 -0.000 -0.000  0.014 -0.018  0.000  0.009  0.001         999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>nnz_order</th>\n",
       "      <th>q</th>\n",
       "      <th>dollars_per_order</th>\n",
       "      <th>ph</th>\n",
       "      <th>ph_minus_pl_bp</th>\n",
       "      <th>ph_minus_pl_dollars</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>order_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.980</td>\n",
       "      <td>1.640</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.548</td>\n",
       "      <td>2.769</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-4.432</td>\n",
       "      <td>-4.279</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.387</td>\n",
       "      <td>-3.053</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>45</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.683</td>\n",
       "      <td>7.602</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     i  nnz_order     q  dollars_per_order     ph  ph_minus_pl_bp  ph_minus_pl_dollars     0      1      2      3     4      5      6      7      8      9     10     11     12     13     14     15  \\\n",
       "95  95         36 1.000              1.980  1.640         100.000                0.010 0.000  0.000  0.011 -0.023 0.012 -0.032  0.002  0.000  0.006 -0.026  0.009  0.008 -0.004  0.011  0.008  0.011   \n",
       "96  96         24 1.000              2.548  2.769         100.000                0.010 0.000  0.000 -0.003  0.000 0.013 -0.002  0.004  0.007 -0.003  0.000  0.000 -0.012  0.019  0.020 -0.009  0.000   \n",
       "97  97         22 1.000             -4.432 -4.279         100.000                0.010 0.010  0.005  0.000  0.006 0.000 -0.007 -0.002 -0.011  0.000  0.000  0.001  0.000  0.000  0.004  0.000  0.003   \n",
       "98  98         22 1.000             -2.387 -3.053         100.000                0.010 0.000 -0.007 -0.009  0.000 0.000  0.000  0.007 -0.012  0.000 -0.000  0.000  0.000 -0.013 -0.001  0.016 -0.006   \n",
       "99  99         45 1.000              7.683  7.602         100.000                0.010 0.003  0.020  0.000  0.013 0.010  0.000  0.007  0.040  0.010  0.012 -0.013  0.000 -0.001  0.000 -0.005 -0.013   \n",
       "\n",
       "       16     17     18     19     20    21     22     23     24     25  order_type  \n",
       "95  0.013  0.000  0.000  0.000  0.001 0.005  0.006  0.000 -0.009  0.012         999  \n",
       "96 -0.006 -0.006  0.000  0.000  0.000 0.001 -0.009  0.000  0.012  0.000         999  \n",
       "97  0.000 -0.028 -0.014 -0.009 -0.010 0.000  0.000  0.000  0.008  0.000         999  \n",
       "98  0.000 -0.011 -0.016  0.000  0.012 0.000  0.022 -0.020  0.013  0.000         999  \n",
       "99  0.005  0.029  0.006 -0.007  0.006 0.000 -0.017 -0.003 -0.024 -0.002         999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_index_stats all:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n</th>\n",
       "      <th>p0</th>\n",
       "      <th>sigma</th>\n",
       "      <th>dv_share</th>\n",
       "      <th>gamma</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>avg_order_dollars</th>\n",
       "      <th>avg_order_shares</th>\n",
       "      <th>dv</th>\n",
       "      <th>asset_start</th>\n",
       "      <th>asset_stop</th>\n",
       "      <th>asset_stride</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vw_market</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.750</td>\n",
       "      <td>37.219</td>\n",
       "      <td>37.219</td>\n",
       "      <td>62970.588</td>\n",
       "      <td>629.706</td>\n",
       "      <td>2343699.308</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>23436.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ew_market</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>6.119</td>\n",
       "      <td>6.119</td>\n",
       "      <td>25533.322</td>\n",
       "      <td>255.333</td>\n",
       "      <td>156246.621</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1562.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vw_size_00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.075</td>\n",
       "      <td>8.019</td>\n",
       "      <td>8.019</td>\n",
       "      <td>29228.358</td>\n",
       "      <td>292.284</td>\n",
       "      <td>234369.931</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2343.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vw_size_01</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ew_size_00</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2.942</td>\n",
       "      <td>2.942</td>\n",
       "      <td>17703.817</td>\n",
       "      <td>177.038</td>\n",
       "      <td>52082.207</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>520.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ew_size_01</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.853</td>\n",
       "      <td>1.853</td>\n",
       "      <td>14051.529</td>\n",
       "      <td>140.515</td>\n",
       "      <td>26041.103</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>260.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vw_ind_00</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.182</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>58592.483</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>585.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vw_ind_01</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.182</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>58592.483</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>585.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vw_ind_02</td>\n",
       "      <td>8</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.182</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>58592.483</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>585.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vw_ind_03</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.182</td>\n",
       "      <td>18412.712</td>\n",
       "      <td>184.127</td>\n",
       "      <td>58592.483</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>585.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ew_ind_00</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ew_ind_01</td>\n",
       "      <td>11</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ew_ind_02</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ew_ind_03</td>\n",
       "      <td>13</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.530</td>\n",
       "      <td>1.530</td>\n",
       "      <td>12766.661</td>\n",
       "      <td>127.667</td>\n",
       "      <td>19530.828</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>195.308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker   n      p0  sigma  dv_share  gamma  num_orders  avg_order_dollars  avg_order_shares          dv  asset_start  asset_stop  asset_stride         v\n",
       "0    vw_market   0 100.000  0.020     0.750 37.219      37.219          62970.588           629.706 2343699.308            0          12             1 23436.993\n",
       "1    ew_market   1 100.000  0.020     0.050  6.119       6.119          25533.322           255.333  156246.621            0          12             1  1562.466\n",
       "2   vw_size_00   2 100.000  0.020     0.075  8.019       8.019          29228.358           292.284  234369.931            0           6             1  2343.699\n",
       "3   vw_size_01   3 100.000  0.020     0.000  0.000       0.000              0.000             0.000       0.000            6          12             1     0.000\n",
       "4   ew_size_00   4 100.000  0.020     0.017  2.942       2.942          17703.817           177.038   52082.207            0           6             1   520.822\n",
       "5   ew_size_01   5 100.000  0.020     0.008  1.853       1.853          14051.529           140.515   26041.103            6          12             1   260.411\n",
       "6    vw_ind_00   6 100.000  0.020     0.019  3.182       3.182          18412.712           184.127   58592.483            0          12             4   585.925\n",
       "7    vw_ind_01   7 100.000  0.020     0.019  3.182       3.182          18412.712           184.127   58592.483            1          12             4   585.925\n",
       "8    vw_ind_02   8 100.000  0.020     0.019  3.182       3.182          18412.712           184.127   58592.483            2          12             4   585.925\n",
       "9    vw_ind_03   9 100.000  0.020     0.019  3.182       3.182          18412.712           184.127   58592.483            3          12             4   585.925\n",
       "10   ew_ind_00  10 100.000  0.020     0.006  1.530       1.530          12766.661           127.667   19530.828            0          12             4   195.308\n",
       "11   ew_ind_01  11 100.000  0.020     0.006  1.530       1.530          12766.661           127.667   19530.828            1          12             4   195.308\n",
       "12   ew_ind_02  12 100.000  0.020     0.006  1.530       1.530          12766.661           127.667   19530.828            2          12             4   195.308\n",
       "13   ew_ind_03  13 100.000  0.020     0.006  1.530       1.530          12766.661           127.667   19530.828            3          12             4   195.308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: df_exchange and other order books might have indexes inherited from merge.  Need to drop index?\n",
    "\n",
    "\n",
    "class OrderBook():\n",
    "    \"\"\"\n",
    "    Based on Assumptions c, this class creates asset statistics (df_asset_stats and df_index_stats).\n",
    "    Registered assets are either individual stocks with characteristics in df_asset_stats\n",
    "    or indexes (portfolios of individual stocks with positive weights) with characteristics in df_index_stats.\n",
    "    The two dataframes df_asset_stats and df_index_stats are concatented into df_stats.\n",
    "    An order is for either one registered asset (buy or sell) \n",
    "    or two registered assets (pairs trade to buy one and sell another).\n",
    "    The exchange is assumed to place its own orders, which are orders for single assets in df_exchange.\n",
    "    Other orders for single assets (both individual stock and indexes) are in df_single_asset. \n",
    "    Orders for pairs trades are in df_pairs_trade.\n",
    "    The dataframes df_exchange, df_single_asset, and df_pairs_trade contain one row for each order.\n",
    "    The orders are constructed by simulation using df_asset_stats and df_index_stats, using Assumption constants c.\n",
    "    Lognormal random variables are used for almost all simulated data.\n",
    "    \n",
    "    Given prices, the class can calculate execution quantities for each order, each registered asset, \n",
    "    and each underlying asset.\n",
    "    This class does not define an algorithm calculate to market clearing prices. \n",
    "    It is contemplated that market clearing prices are \n",
    "    calculated elsewhere (CVXOPT, Gurobi, etc.) by an algorithm which clears the market for underlying assets, \n",
    "    not registered assets or orders.\n",
    "    \"\"\"\n",
    "    def __init__(self, c=Assumptions(), nseed=123456):\n",
    "\n",
    "        self.c = c\n",
    "        self.dtype = c.dtype\n",
    "        self.nseed0 = nseed\n",
    "        self.rng = np.random.default_rng(nseed)\n",
    "        \n",
    "        self.df_asset_stats = self.make_asset_stats()\n",
    "        self.df_index_stats = self.make_index_stats()\n",
    "        \n",
    "        self.df_stats = pd.concat([self.df_asset_stats, self.df_index_stats])\n",
    "        self.df_stats['n'] = range(len(self.df_stats))\n",
    "        self.df_stats['ndx'] = self.df_stats['n'].copy()\n",
    "        self.df_stats = self.df_stats.set_index('ndx')\n",
    "        \n",
    "        # Define orders placed by the exchange itself:\n",
    "        self.df_exchange = self.make_order_book_exchange()\n",
    "        #assert len(self.df_exchange) == 2 * c.N, \"PKError: Exchange should have2 orders for each asset!\"\n",
    "        \n",
    "        # Define stabilizing orders:\n",
    "        self.df_stabilizing = self.make_order_book_stabilizing()\n",
    "        if c.stab_max_qv != 0.00:\n",
    "            assert len(self.df_stabilizing) == 2 * c.N, \"PKError: Should have 2 stabilizing orders for each asset!\"\n",
    "        else:    \n",
    "            assert len(self.df_stabilizing) == 0, \"PKError: Should have 0 stabilizing orders when c.stab_max_qv == 0.00!\"\n",
    "\n",
    "        # Define orders for single stocks and single indexes:\n",
    "        self.df_single_asset = self.make_order_book_single_asset()\n",
    "        \n",
    "        # Make order books for pairs trades of asset-asset, asset-index, index-index:\n",
    "        self.df_pairs_trade = self.make_order_book_pairs_trade()\n",
    "        \n",
    "        # Make order books for random sparse orders:\n",
    "        self.df_sparse = self.make_order_book_random_sparse()\n",
    "        \n",
    "        # Make order books for random dense orders:\n",
    "        self.df_dense = self.make_order_book_random_dense()\n",
    "\n",
    "        # Give names to dataframes of orders:\n",
    "        self.dfs_all = {'A0' : self.df_exchange, \n",
    "                             'A0s' : self.df_exchange,\n",
    "                             'B1' : self.df_single_asset, \n",
    "                             'B2' : self.df_pairs_trade,\n",
    "                             'Bs' : self.df_sparse, \n",
    "                             'Bd' : self.df_dense}\n",
    "        \n",
    "        # Pull data from order books to create numpy arrays for calculating market prices:\n",
    "        \n",
    "        self.q0 = self.df_exchange['q'].to_numpy()\n",
    "        self.ph0 = self.df_exchange['ph'].to_numpy()\n",
    "        self.pl0 = self.df_exchange['pl'].to_numpy()\n",
    "        self.ph_minus_pl0 = self.df_exchange['ph_minus_pl_dollars'].to_numpy()\n",
    "        self.n0 = self.df_exchange['n'].to_numpy()\n",
    "        self.w0 = self.df_exchange['w'].to_numpy()\n",
    "        self.order_type0 = self.df_exchange['order_type'].to_numpy()\n",
    "        \n",
    "        self.q0s = self.df_stabilizing['q'].to_numpy()\n",
    "        self.ph0s = self.df_stabilizing['ph'].to_numpy()\n",
    "        self.pl0s = self.df_stabilizing['pl'].to_numpy()\n",
    "        self.ph_minus_pl0s = self.df_stabilizing['ph_minus_pl_dollars'].to_numpy()\n",
    "        self.n0s = self.df_stabilizing['n'].to_numpy()\n",
    "        self.w0s = self.df_stabilizing['w'].to_numpy()\n",
    "        self.order_type0s = self.df_stabilizing['order_type'].to_numpy()\n",
    "\n",
    "        self.q1 = self.df_single_asset['q'].to_numpy()\n",
    "        self.ph1 = self.df_single_asset['ph'].to_numpy()\n",
    "        self.pl1 = self.df_single_asset['pl'].to_numpy()\n",
    "        self.ph_minus_pl1 = self.df_single_asset['ph_minus_pl_dollars'].to_numpy()\n",
    "        self.n1 = self.df_single_asset['n'].to_numpy()\n",
    "        self.w1 = self.df_single_asset['w'].to_numpy()\n",
    "        self.order_type1 = self.df_single_asset['order_type'].to_numpy()\n",
    "\n",
    "        self.q2 = self.df_pairs_trade['q'].to_numpy()\n",
    "        self.ph2 = self.df_pairs_trade['ph'].to_numpy()\n",
    "        self.pl2 = self.df_pairs_trade['pl'].to_numpy()\n",
    "        self.ph_minus_pl2 = self.df_pairs_trade['ph_minus_pl_dollars'].to_numpy()\n",
    "        self.n2b = self.df_pairs_trade['n_buy'].to_numpy()\n",
    "        self.n2s = self.df_pairs_trade['n_sell'].to_numpy()\n",
    "        self.w2b = self.df_pairs_trade['w_buy'].to_numpy()\n",
    "        self.w2s = self.df_pairs_trade['w_sell'].to_numpy()\n",
    "        self.order_type2 = self.df_pairs_trade['order_type'].to_numpy()\n",
    "\n",
    "        # Consistency checks\n",
    "        assert self.c.N == len(self.df_asset_stats), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.NX == len(self.df_index_stats), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.NR == len(self.df_stats), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.M0 == len(self.df_exchange), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.M0s == len(self.df_stabilizing), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.M1 == len(self.df_single_asset), \"PKERROR: failed consistency check\"\n",
    "        assert self.c.M2 == len(self.df_pairs_trade), \"PKERROR: failed consistency check\"\n",
    "        #print(self.c.M, self.c.M0, self.c.M1, self.c.M2)\n",
    "        #print(self.c)\n",
    "        assert self.c.Mall == (self.c.M0 + self.c.M0s + self.c.M1 + self.c.M2), \"PKERROR: failed consistency check\"\n",
    "        \n",
    "        self.q = np.concatenate([self.q0, self.q0s, self.q1, self.q2], axis=None)\n",
    "\n",
    "        #assert ((self.q.shape[0] == self.c.Mall) and\n",
    "        #        (self.q.ndim == 1)), \"PKerror: incorrect shape = \" + str(self.q.shape)\n",
    "\n",
    "        # Define variables needed as inputs for quadratic programming problem:\n",
    "        \n",
    "        self.order_type = np.concatenate([self.order_type0, self.order_type0s, self.order_type1, self.order_type2], axis=None)\n",
    "        \n",
    "        self.ph = np.concatenate([self.ph0, self.ph0s, self.ph1, self.ph2], axis=None)\n",
    "        self.pl = np.concatenate([self.pl0, self.pl0s, self.pl1, self.pl2], axis=None)\n",
    "        self.ph_minus_pl = np.concatenate([self.ph_minus_pl0, self.ph_minus_pl0s, \n",
    "                                           self.ph_minus_pl1, self.ph_minus_pl2], axis=None)\n",
    "\n",
    "\n",
    "        # Division by zero if self.q contains elements with zero values.\n",
    "        #self.Dvec = (self.ph - self.pl) / self.q\n",
    "        b_make_divide_by_zero_infinite = True\n",
    "        if b_make_divide_by_zero_infinite:\n",
    "            self.r_ph_minus_pl = np.empty_like(self.ph_minus_pl)\n",
    "            self.r_ph_minus_pl[:] = +np.inf\n",
    "            np.divide(1.00, self.ph_minus_pl, out=self.r_ph_minus_pl, where=(self.ph_minus_pl > 0.00))\n",
    "            self.Dvec = np.empty_like(self.q)\n",
    "            self.Dvec[:] = +np.inf\n",
    "            np.divide(self.ph_minus_pl, self.q, out=self.Dvec, where=(self.q > 0.00))\n",
    "        else:    \n",
    "            #self.r_ph_minus_pl = 1.00 / (self.ph - self.pl)\n",
    "            self.r_ph_minus_pl = 1.00 / (self.ph_minus_pl)\n",
    "            self.Dvec = (self.ph_minus_pl) / self.q\n",
    "            #self.Dvec = np.divide\n",
    "\n",
    "        self.Dinvvec = 1.00 / self.Dvec\n",
    "        self.Dsparse = scipy.sparse.dia_matrix((self.Dvec, [0]), shape=(self.Dvec.shape[0], self.Dvec.shape[0]))\n",
    "        self.Dinvsparse = scipy.sparse.dia_matrix((self.Dinvvec, [0]), shape=(self.Dvec.shape[0], self.Dvec.shape[0]))\n",
    "\n",
    "        self.zeros_n = np.zeros((self.c.N), dtype = c.dtype)\n",
    "        self.zeros_m = np.zeros((self.c.Mall), dtype = c.dtype)\n",
    "        self.zeros_2m = np.zeros((2 * self.c.Mall), dtype = c.dtype)\n",
    "\n",
    "        w0 = scipy.sparse.csr_matrix((self.w0, (self.n0, range(self.c.M0))),\n",
    "                                     shape=(self.c.NR, self.c.M0))\n",
    "        w0s = scipy.sparse.csr_matrix((self.w0s, (self.n0s, range(self.c.M0s))),\n",
    "                                     shape=(self.c.NR, self.c.M0s))\n",
    "        w1 = scipy.sparse.csr_matrix((self.w1, (self.n1, range(self.c.M1))),\n",
    "                                     shape=(self.c.NR, self.c.M1))\n",
    "        w2b = scipy.sparse.csr_matrix((self.w2b, (self.n2b, range(self.c.M2))),\n",
    "                                      shape=(self.c.NR, self.c.M2))\n",
    "        w2s = scipy.sparse.csr_matrix((self.w2s, (self.n2s, range(self.c.M2))),\n",
    "                                      shape=(self.c.NR, self.c.M2))\n",
    "\n",
    "        w2 = w2b + w2s\n",
    "        \n",
    "        self.Wsparse = scipy.sparse.csr_matrix(scipy.sparse.hstack([w0, w0s, w1, w2], dtype=c.dtype))\n",
    "        self.WTsparse = scipy.sparse.csr_matrix(self.Wsparse.transpose())\n",
    "        \n",
    "        self.Wsparse_coo = scipy.sparse.coo_matrix(self.Wsparse)\n",
    "        self.WTsparse_coo = scipy.sparse.coo_matrix(self.WTsparse)\n",
    "        \n",
    "        self.absWsparse = self.Wsparse.__abs__()\n",
    "        self.WWDinvvec = self.Wsparse.multiply(self.Wsparse).multiply(self.Dinvvec)\n",
    "        self.DinvWTsparse = self.Dinvsparse.dot(self.WTsparse)\n",
    "\n",
    "        # Definition of matrx R, which converts registered portfolios to assets:\n",
    "        # R_mat = [I_N, RX_mat], where RX_mat is N x RX matrix defining registered portfolio (index) weights.\n",
    "        # RX_mat can potentially be implemented as a sparse matrix, but here we make it dense:\n",
    "        # vw indexes have weights proportional to asset dollar volume dv for assets in the portfolio\n",
    "        # ew indexes have equal weights for assets in the portfolio\n",
    "        # Assets in the portfolios are defined by start, stop, stride.\n",
    "        # In more general application, users would define their own registered portfolios, which could be arbitrary.\n",
    "        \n",
    "        self.RX_mat = np.zeros((self.c.N, self.c.NX), dtype=self.dtype)\n",
    "        bool_vw = self.df_index_stats['ticker'].str[0:3].str.contains('vw_')\n",
    "        start = self.df_index_stats['asset_start'].to_numpy()\n",
    "        stop = self.df_index_stats['asset_stop'].to_numpy()\n",
    "        stride = self.df_index_stats['asset_stride'].to_numpy()\n",
    "        dv = self.df_asset_stats['dv'].to_numpy()\n",
    "\n",
    "        #with np.printoptions(precision=3):\n",
    "        #    printa(self.RX_mat, \"self.RX_mat\")\n",
    "        #    printa(dv, \"dv\")\n",
    "        #    print(dv)\n",
    "        #    r = 2\n",
    "        #    print(start[r], stop[r], stride[r])\n",
    "        #    print(dv[start[r]:stop[r]:stride[r]])\n",
    "\n",
    "        for r in range(self.c.NX):\n",
    "            if bool_vw[r] == True:\n",
    "                self.RX_mat[start[r]:stop[r]:stride[r], r] = dv[start[r]:stop[r]:stride[r]] \n",
    "            else:\n",
    "                self.RX_mat[start[r]:stop[r]:stride[r], r] = 1.00 \n",
    "        # Scale weights in each column to sum to one based on sums of dollar volumes or ones in each column:\n",
    "        self.RX_mat = self.RX_mat / self.RX_mat.sum(axis=0).reshape(1,-1)\n",
    "        \n",
    "        #printa(self.RX_mat.T, \"self.RX_mat.T\")\n",
    "        #print(self.RX_mat.T)\n",
    "        \n",
    "        # TODO: Adjust for prices not equal to one here:!!!!\n",
    "        p0assetinv = 1.00 / self.df_asset_stats['p0'].to_numpy().reshape(c.N, 1)\n",
    "        p0index = self.df_index_stats['p0'].to_numpy().reshape(1, c.NX)\n",
    "        self.RX_mat = p0assetinv * self.RX_mat * p0index  \n",
    "\n",
    "        assert self.RX_mat.min() >= 0.00, \"PKError: Every element of self.RX_mat should be nonnegative!\"\n",
    "        \n",
    "        #self.RXT_mat = self.RX_mat.T.copy()\n",
    "        self.RXT_mat = np.array(self.RX_mat.T.copy())\n",
    "\n",
    "        self.I_N = np.zeros((self.c.N, self.c.N), dtype=self.dtype)\n",
    "        for i in range(self.c.N):\n",
    "            self.I_N[i,i] = 1.00\n",
    "        self.R_mat = np.hstack([self.I_N, self.RX_mat])\n",
    "        \n",
    "        self.pbenchmark = self.df_asset_stats['p0'].to_numpy()\n",
    "        self.pa = self.pbenchmark\n",
    "        self.x = np.zeros_like(self.q)\n",
    "\n",
    "        self.net_dollar_demand_norm = 99999999999.9999\n",
    "        \n",
    "        qpinputs = {}\n",
    "        qpinputs['dtype'] = self.Dvec.dtype   # typically np.float64\n",
    "        qpinputs['m'] = self.Dvec.shape[0]   # number of orders, I in paper\n",
    "        qpinputs['n'] = self.pa.shape[0]   # number of assets, N in paper\n",
    "        qpinputs['k'] = self.RX_mat.shape[1]   # number of registered portfolios\n",
    "        dtype = qpinputs['dtype']\n",
    "        m = qpinputs['m']\n",
    "        n = qpinputs['n']\n",
    "        # Sigma = scipy.sparse.eye(n, dtype=dtype)\n",
    "        I_n = scipy.sparse.eye(n, dtype=dtype)\n",
    "        qpinputs['RX'] = np.ascontiguousarray(self.RX_mat)  # registered portfolio weights (shares / portfolio unit)\n",
    "        qpinputs['RXs'] = scipy.sparse.csr_matrix(qpinputs['RX'])  #  also registered portfolio weights (shares / portfolio unit)\n",
    "        Rmat = np.concatenate([I_n.toarray(), self.RX_mat], axis=1)\n",
    "        qpinputs['Rs'] = scipy.sparse.csr_matrix(Rmat) # registered portfolio weights (shares per portfolio unit, ones for individual assets)\n",
    "        qpinputs['Dsmat'] = scipy.sparse.diags(self.Dvec) # slope of order (dollars / portfolio unit^2) like lambda in Kyle-1985\n",
    "\n",
    "        qpinputs['Ws'] = self.Wsparse # subportfolio weight in order (asset units, +=buy, -=sell), order has one or two nonzero weights\n",
    "        qpinputs['Wst'] = self.WTsparse # subportfolio weight in order (asset units, +=buy, -=sell), order has one or two nonzero weights\n",
    "\n",
    "        qpinputs['Wcoo'] = self.Wsparse_coo # subportfolio weight in order (asset units, +=buy, -=sell), order has one or two nonzero weights\n",
    "        qpinputs['Wtcoo'] = self.WTsparse_coo # subportfolio weight in order (asset units, +=buy, -=sell), order has one or two nonzero weights\n",
    "\n",
    "        qpinputs['Gs'] = scipy.sparse.csr_matrix(scipy.sparse.vstack([scipy.sparse.diags(-np.ones((m,))),\n",
    "                                                                    scipy.sparse.diags( np.ones((m,)))]))\n",
    "\n",
    "        #qpinputs['c'] = -self.ph # negative of limit price (dollars / portfolio unit)\n",
    "        #qpinputs['b'] = np.zeros((n,), dtype=dtype) # quantity to clear market (shares)\n",
    "        #qpinputs['h'] = np.hstack([np.zeros_like(self.q), self.q]) # order quantity limits (portfolio units)\n",
    "        #qpinputs['p0'] = self.pbenchmark\n",
    "        #qpinputs['q'] = self.q\n",
    "\n",
    "        qpinputs['ph'] = self.ph # negative of limit price (dollars / portfolio unit)\n",
    "        qpinputs['mkt_clear'] = np.zeros((n,), dtype=dtype) # quantity to clear market (shares)\n",
    "        qpinputs['xzero'] = np.zeros_like(self.q)\n",
    "        qpinputs['q'] = self.q\n",
    "        qpinputs['p0'] = self.pbenchmark\n",
    "        \n",
    "        qpinputs['order_type'] = self.order_type\n",
    "        qpinputs['b_exch_order'] = (self.order_type == 0)\n",
    "        qpinputs['b_stab_order'] = (self.order_type == -1)\n",
    "        qpinputs['b_pair_order'] = (self.order_type == 2)\n",
    "        \n",
    "        qpinputs['b_q_constraint'] = np.hstack([~(self.q == self.q), self.q == self.q])\n",
    "        #qpinputs['b_q_constr_order_type'] = np.hstack([np.zeros_like(self.order_type), self.order_type])\n",
    "        qpinputs['constr_order_type'] = np.hstack([self.order_type, self.order_type])\n",
    "\n",
    "        qpinputs['b_exch_q_constraint'] = (qpinputs['b_q_constraint'] & (qpinputs['constr_order_type'] == 0))\n",
    "        qpinputs['b_stab_q_constraint'] = (qpinputs['b_q_constraint'] & (qpinputs['constr_order_type'] == -1))\n",
    "        \n",
    "        self.qpinputs = qpinputs # inputs to quadratic program\n",
    "        \n",
    "        # Do this when estimation options known: torch dtype and device not known yet!\n",
    "        #self.initialize_torch_dictionaries_(dtype, device)  \n",
    "    \n",
    "        \n",
    "    def update_demand(self, pa):\n",
    "        \"\"\"\n",
    "        self.update_demand(prices) calculates the excess demand vector self.net_dollar_demand \n",
    "        given a price vector.  It also calculates many other statistics.\n",
    "        FIXED? The style of this function is to \"hardwire\" what could otherwise be sparse matrix calculations.\n",
    "        This function can be used as a template for defining bespoke sparse operations for orders.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.pa = pa.copy()\n",
    "        \n",
    "        tempr = np.zeros(self.c.NR, dtype=self.dtype)\n",
    "        tempr[:self.c.N] += self.pa\n",
    "        tempr[self.c.N:] += self.RXT_mat @ self.pa\n",
    "        \n",
    "        self.pm = np.zeros(self.c.Mall, dtype=self.dtype)\n",
    "        self.pm[self.order_type == 0] = tempr[self.n0] * self.w0\n",
    "        self.pm[self.order_type == -1] = tempr[self.n0s] * self.w0s\n",
    "        self.pm[self.order_type == 1] = tempr[self.n1] * self.w1\n",
    "        self.pm[self.order_type == 2] =  tempr[self.n2b] * self.w2b\n",
    "        self.pm[self.order_type == 2] += tempr[self.n2s] * self.w2s\n",
    "        \n",
    "        #self.pm = np.zeros(self.c.Mall, dtype=self.dtype)\n",
    "        #self.pm[:self.c.M0] = tempr[self.n0] * self.w0\n",
    "        #self.pm[self.c.M0 : self.c.M0 + self.c.M1] = tempr[self.n1] * self.w1\n",
    "        #self.pm[self.c.M0 + self.c.M1 :] =  tempr[self.n2b] * self.w2b\n",
    "        #self.pm[self.c.M0 + self.c.M1 :] += tempr[self.n2s] * self.w2s\n",
    "\n",
    "        self.z = (self.ph - self.pm) * self.r_ph_minus_pl\n",
    "        #self.fvec, self.Fvec = F_and_fr_jit(self.z, eps=0.0000001, factor=1.00)\n",
    "        self.Fvec = np.maximum(np.minimum(self.z, 1.00), 0.00)\n",
    "        self.x = self.q * self.Fvec\n",
    "        \n",
    "        tempr[:] = (  np.bincount(self.n0, self.w0 * self.x[self.order_type == 0], minlength=self.c.NR)\n",
    "                        + np.bincount(self.n0s, self.w0s * self.x[self.order_type == -1], minlength=self.c.NR)\n",
    "                        + np.bincount(self.n1, self.w1 * self.x[self.order_type == 1], minlength=self.c.NR)\n",
    "                        + np.bincount(self.n2b, self.w2b * self.x[self.order_type == 2], minlength=self.c.NR)\n",
    "                        + np.bincount(self.n2s, self.w2s * self.x[self.order_type == 2], minlength=self.c.NR))\n",
    "\n",
    "        self.net_demand = np.zeros(self.c.N, dtype=self.dtype)\n",
    "\n",
    "        self.net_demand[:] = tempr[:self.c.N] + self.RX_mat @ tempr[self.c.N:]\n",
    "        \n",
    "        #tempr[:] = (  np.bincount(self.n0, self.w0 * self.x[:self.c.M0], minlength=self.c.NR)\n",
    "        #                + np.bincount(self.n1, self.w1 * self.x[self.c.M0 : self.c.M0 + self.c.M1], minlength=self.c.NR)\n",
    "        #                + np.bincount(self.n2b, self.w2b * self.x[self.c.M0 + self.c.M1 :], minlength=self.c.NR)\n",
    "        #                + np.bincount(self.n2s, self.w2s * self.x[self.c.M0 + self.c.M1 :], minlength=self.c.NR))\n",
    "\n",
    "        #self.net_demand = np.zeros(self.c.N, dtype=self.dtype)\n",
    "\n",
    "        #self.net_demand[:] = tempr[:self.c.N] + self.RX_mat @ tempr[self.c.N:]\n",
    "\n",
    "        self.net_dollar_demand = self.pbenchmark * self.net_demand\n",
    "        self.net_dollar_demand_norm = np.linalg.norm(self.net_dollar_demand, 2)\n",
    "        \n",
    "        return self.net_dollar_demand_norm\n",
    "\n",
    "    def calculate_volume_stats(self):\n",
    "        \"\"\"\n",
    "        This function calculates statistics based on trading volume.  \n",
    "        It is assumed that update_demand(...) has already been called.\n",
    "        The important statistic self.uncleared_share gives the fraction of total dollar volume which\n",
    "        did not clear. The message msg summarized volume statistics.\n",
    "        The uncleared volume share is printed dollars per million (i.e., multiplied by 10**6), so\n",
    "        unclpM = 1.00 means one dollar per 1,000,000 dollars of volume did not clear.\n",
    "        \"\"\"\n",
    "        #c = self.c\n",
    "        \n",
    "        self.dollar_volume = (self.pbenchmark * (self.R_mat @ self.absWsparse.dot(self.x))).sum()\n",
    "        self.exchange_dollar_volume = (self.pbenchmark * (self.R_mat @ \n",
    "                     self.absWsparse[:, self.order_type == 0].dot(self.x[self.order_type == 0]))).sum()\n",
    "        self.stabilizing_dollar_volume = (self.pbenchmark * (self.R_mat @ \n",
    "                     self.absWsparse[:, self.order_type == -1].dot(self.x[self.order_type == -1]))).sum()\n",
    "        self.single_asset_dollar_volume =  (self.pbenchmark * (self.R_mat @ \n",
    "                      self.absWsparse[:, self.order_type == 1].dot(self.x[self.order_type == 1]))).sum()\n",
    "        self.pairs_trade_dollar_volume =  (self.pbenchmark * (self.R_mat @ \n",
    "                        self.absWsparse[:, self.order_type == 2].dot(self.x[self.order_type == 2]))).sum()\n",
    "        self.net_dollar_volume_vec = self.pbenchmark * np.abs(self.R_mat @ self.Wsparse.dot(self.x))\n",
    "        self.uncleared_dollar_volume = self.net_dollar_volume_vec.sum()\n",
    "\n",
    "        if self.dollar_volume != 0.00:\n",
    "            self.uncleared_share = self.uncleared_dollar_volume / self.dollar_volume\n",
    "            self.exchange_share = self.exchange_dollar_volume / self.dollar_volume\n",
    "            self.stabilizing_share = self.stabilizing_dollar_volume / self.dollar_volume\n",
    "            self.single_asset_share = self.single_asset_dollar_volume / self.dollar_volume\n",
    "            self.pairs_trade_share = self.pairs_trade_dollar_volume / self.dollar_volume\n",
    "        else:    \n",
    "            self.uncleared_share = 0.00\n",
    "            self.exchange_share = 0.00\n",
    "            self.stabilizing_share = 0.00\n",
    "            self.single_asset_share = 1.00\n",
    "            self.pairs_trade_share = 0.00\n",
    "\n",
    "        msg = \"unclpM=\" + f\"{(self.uncleared_share * 1.00e6):.1e}\"\n",
    "        msg += \", exchpM=\" + f\"{(self.exchange_share * 1.00e6):.1e}\"\n",
    "        msg += \", stabpM=\" + f\"{(self.stabilizing_share * 1.00e6):.1e}\"\n",
    "        msg += \", pairspM=\" + f\"{(self.pairs_trade_share * 1.00e6):.1e}\"\n",
    "        msg += \", dv10^6=\" + f\"{(self.dollar_volume * 1.0e-6):.4e}\"\n",
    "        #msg += \"norm=\" + f\"{self.net_dollar_demand_norm:.1e}\"\n",
    "        \n",
    "        d = {}\n",
    "        d['norm'] = self.net_dollar_demand_norm\n",
    "        d['unclpM'] = self.uncleared_share * 1.00e6\n",
    "        d['exchpM'] = self.exchange_share * 1.00e6\n",
    "        d['stabpM'] = self.stabilizing_share * 1.00e6\n",
    "        d['pairpM'] = self.pairs_trade_share * 1.00e6\n",
    "        d['dvM'] = self.dollar_volume * 10e-6\n",
    "        d['dollar_volume'] = self.dollar_volume\n",
    "        d['exchange_dollar_volume'] = self.exchange_dollar_volume\n",
    "        d['single_asset_dollar_volume'] = self.single_asset_dollar_volume\n",
    "        d['pairs_trade_dollar_volume'] = self.pairs_trade_dollar_volume\n",
    "        d['uncleared_dollar_volume'] = self.uncleared_dollar_volume\n",
    "        d['uncleared_share'] = self.uncleared_share\n",
    "        d['exchange_share'] = self.exchange_share\n",
    "        d['stabilizing_share'] = self.stabilizing_share\n",
    "        d['single_asset_share'] = self.single_asset_share\n",
    "        d['pairs_trade_share'] = self.pairs_trade_share\n",
    "        d['net_dollar_volume_vec'] = self.net_dollar_volume_vec\n",
    "        \n",
    "        return msg, d\n",
    "\n",
    "    def make_asset_stats(self):\n",
    "        \"\"\"\n",
    "        Create a dataframe containing one row for each asset and columns of simulated asset statistics.\n",
    "        The asset statistics are used to define the size and number of orders.\n",
    "        Assets with high dollar volume have many orders of larger average size.\n",
    "        We can eventually replace this with statistics estimated from CRSP or TAQ data.\n",
    "        Here, asset \"ticker\" is a string name, which can be replaced by a real ticker symbol.\n",
    "        \"\"\"\n",
    "\n",
    "        # Abbreviations to make typing easier and notation cleaner:\n",
    "        c = self.c\n",
    "        R = self.dtype\n",
    "\n",
    "        df = pd.DataFrame({'n' : range(c.N)})\n",
    "\n",
    "        # num_orders has lognormal distribution with mean c.MA / c.N\n",
    "        df['num_orders'] = (self.rng.lognormal(mean = -0.50 * c.std_num_orders_asset ** 2, sigma = c.std_num_orders_asset, \n",
    "                                   size=c.N) * R(c.MA) / R(c.N))\n",
    "        \n",
    "        # Eliminate statistical error by scaling num_orders up or down to generate the correct total number of orders.\n",
    "        df['num_orders'] = (df['num_orders'] / df['num_orders'].sum()) * R(c.MA)\n",
    "        \n",
    "        assert np.isclose(df['num_orders'].sum(), R(c.MA)), f\"PKError: {df['num_orders'].sum()=} should equal {c.MA=}\"\n",
    "        \n",
    "        # Placeholder for daily asset volatility of 2% per day\n",
    "        df['sigma'] = 0.02\n",
    "        \n",
    "        df['p0'] = self.rng.lognormal(mean=np.log(c.mean_asset_price) - 0.50 * c.std_asset_price ** 2,\n",
    "                                          sigma=c.std_asset_price, size=c.N )\n",
    "        \n",
    "        # num_orders is equivalent to gamma in invariance theory:\n",
    "        df['gamma'] = df['num_orders']\n",
    "\n",
    "        # dv means \"dollar volume\"\n",
    "        # df['dv_share'] = df['dv'] / df['dv'].sum()\n",
    "        # df['dv'] = df['avg_order_dollars'] * df['num_orders'] \n",
    "        df['dv_share'] = df['gamma'] ** (1.00 / (2.00 * c.invariance_exponent))\n",
    "        df['dv_share'] = df['dv_share'] / df['dv_share'].sum()\n",
    "        df['dv'] = df['dv_share'] * c.dv_single_asset_orders \n",
    "        \n",
    "        df['mc_over_sigma_const'] = df['dv'] / df['gamma']**(1.00 / (2 * c.invariance_exponent))\n",
    "        \n",
    "        assert (df['mc_over_sigma_const'].std() < 1.00e-6), f\"PKError: {df['mc_over_sigma_const'].std()=}, should equal 0.00\"\n",
    "        self.mc_over_sigma_const = df['mc_over_sigma_const'].median()\n",
    "\n",
    "        # invariance formula for L from gamma = sigma**2 * L**2 / m**2\n",
    "        # df['L'] = np.sqrt(df['num_orders']) * c.invariance_m / df['sigma']\n",
    "\n",
    "        # invariance formula for average bet size = C * L\n",
    "        #df['avg_order_dollars'] = c.invariance_c * df['L']\n",
    "        #df['avg_order_dollars'] = np.sqrt(df['gamma'])\n",
    "        df['avg_order_dollars'] = df['dv'] / df['gamma']\n",
    "\n",
    "        df['avg_order_shares'] = df['avg_order_dollars'] / df['p0']\n",
    "        \n",
    "        \n",
    "        # self.dv_assets = Total expected dollar volume across all assets. \n",
    "        # But here it is dollar volume of orders, not executions, so there is a discrepancy.\n",
    "        # Actual volume will be less than dv_assets since not all orders are executed.\n",
    "        #self.dv_assets = df['dv'].sum()\n",
    "        \n",
    "        #df['dv'] = self.rng.lognormal(mean=np.log(c.dollar_volume_assets / c.N) - 0.50 * c.std_asset_dollar_volume ** 2,\n",
    "        #                                   sigma=c.std_asset_dollar_volume, size=c.N)\n",
    "\n",
    "        df['v'] = df['dv'] / df['p0']  # expected daily share volume\n",
    "\n",
    "        # Sort assets and change index so that asset 0 has highest volume and asset N has lowest:\n",
    "        df = df.sort_values(['num_orders', 'dv', 'p0'], ascending=False)\n",
    "        df['n'] = range(c.N)\n",
    "        df['ndx'] = df['n']\n",
    "        df = df.set_index(['ndx'])\n",
    "        \n",
    "        df['ticker'] = ['asset_' + str(n).zfill(4) for n in range(c.N)]\n",
    "        \n",
    "        # asset_start and asset_stop are for compatibility with make_index_stats, play no role\n",
    "        df['asset_start'] = df['n']\n",
    "        df['asset_stop'] = df['n'] + 1\n",
    "        df['asset_stride'] = 1\n",
    "\n",
    "        return df\n",
    "\n",
    "    def make_index_stats(self):\n",
    "        \"\"\"\n",
    "        Create a dataframe containing one row for each index and columns of defined index statistics.\n",
    "        We can eventually replace this with ETF statistics estimated from CRSP or TAQ data.\n",
    "        Here, index \"names\" are integer indices with descriptive strings.\n",
    "        \"\"\"\n",
    "\n",
    "        c = self.c\n",
    "        R = self.dtype\n",
    "\n",
    "        # Create easily understood names for value weighted market index, equally weighted market index,\n",
    "        # value-weighted quantile indexes, and equally weighted quantile indexes.\n",
    "        # These names will eventually describe user-defined registered portfolios.\n",
    "        # In production, ETFs will be included in assets described by c.N and c.MA, not here.\n",
    "        # This is because registered portfolios clear by clearing underlying assets,\n",
    "        # but ETFs clear by clearing the ETF symbol itself.\n",
    "\n",
    "        # Users will likely register the ETF-mimicking create-and-redeem baskets as portfolios,\n",
    "        # then arbitrage the ETF against the registered basket.\n",
    "        # TODO: We might designate some assets as ETFs, then add registered ETF portfolio-mimicking baskets\n",
    "        # A separate category of ETF arbitrage orders would keep the ETF price close to the price of the basket.\n",
    "        # This might have the effect of worsening the condition number for estimation, destabilizing the CG method!\n",
    "\n",
    "        tickers = ['vw_market', 'ew_market']\n",
    "        for n in range(c.num_size_indexes):\n",
    "            tickers.append('vw_size_' + str(n).zfill(2))\n",
    "        for n in range(c.num_size_indexes):\n",
    "            tickers.append('ew_size_' + str(n).zfill(2))\n",
    "        for n in range(c.num_industry_indexes):\n",
    "            tickers.append('vw_ind_' + str(n).zfill(2))\n",
    "        for n in range(c.num_industry_indexes):\n",
    "            tickers.append('ew_ind_' + str(n).zfill(2))\n",
    "\n",
    "        df = pd.DataFrame({'ticker' : tickers}) \n",
    "        df['n'] = range(len(df))\n",
    "\n",
    "        df['p0'] = c.index_prices\n",
    "        #df['p0'] = 100.00\n",
    "        df['sigma'] = 0.02\n",
    "        \n",
    "        # Calculate dollar volume shares dv_share for each index asset, using Assumptions in c:\n",
    "        dv_share = [c.vw_mkt_index_share, c.ew_mkt_index_share]\n",
    "\n",
    "        # For vw quantile index dollar volumes, use geometrically declining weights which sum to one:\n",
    "        # For vw quantile indexes, use sum from n=0 to N of alpha^n = 1 - alpha^N / (1 - alpha) = 1 to make \n",
    "        # weights alpha**n / alpha_factor sum to one:\n",
    "        # alpha = 0.50\n",
    "        # alpha_factor = (1 - alpha**(c.num_size_indexes)) / (1 - alpha)\n",
    "        # dv_share += list([c.vw_size_index_share * alpha**n \n",
    "        #                     / alpha_factor for n in range(c.num_size_indexes)])\n",
    "\n",
    "        # ew_size_index_alpha = 1.00  # alpha should be between zero and one, inclusive.\n",
    "        wts = np.array([c.ew_size_index_alpha**n for n in range(c.num_size_indexes)])\n",
    "        wts = c.vw_size_index_share * wts / wts.sum()\n",
    "        dv_share = dv_share + wts.tolist()\n",
    "        \n",
    "        # For ew index dollar volumes, use arithmetically or polynomial declining weights which sum to one:\n",
    "        # Here, weights are proportional to N, N-1, ..., 1, which sums to N * (N+1) / 2.\n",
    "        dv_share += list([(c.ew_size_index_share * R(c.num_size_indexes - n) \n",
    "                / R(c.num_size_indexes * (c.num_size_indexes + 1) / 2)) \n",
    "                               for n in range(c.num_size_indexes)])\n",
    "\n",
    "        # Make gamma_share for each industry index the same, for both vw and ew:\n",
    "        dv_share += [c.vw_industry_index_share \n",
    "                           / R(c.num_industry_indexes)] * c.num_industry_indexes\n",
    "        dv_share += [c.ew_industry_index_share \n",
    "               / R(c.num_industry_indexes)] * c.num_industry_indexes\n",
    "        df['dv_share'] = dv_share\n",
    "        df['gamma'] = ( (df['dv_share'] * df['sigma']).pow(2.00 * c.invariance_exponent) * R(c.MX) \n",
    "                       / (df['dv_share'] * df['sigma']).pow(2.00 * c.invariance_exponent).sum() )\n",
    "        \n",
    "        # dv_share should sum to one, and gamma should sum to MX:\n",
    "        #print(f\"{df['dv_share'].sum()=} should be one\")\n",
    "        #print(f\"{df['gamma'].sum()=} should be same as {c.MX=}\")\n",
    "        assert np.isclose(df['dv_share'].sum(), 1.00), f\"PKError: {df['dv_share'].sum()=} should be 1.00\"\n",
    "        assert np.isclose(df['gamma'].sum(), R(c.MX)), f\"PKError: {df['gamma'].sum()=} should be {c.MX=}.\"\n",
    "\n",
    "        # gamma is the same thing as number of orders:\n",
    "        df['num_orders'] = df['gamma']\n",
    "        \n",
    "        # invariance formula for L from gamma = sigma**2 * L**2 / m**2\n",
    "        # df['L'] = np.sqrt(df['num_orders']) * c.invariance_m / df['sigma']\n",
    "\n",
    "        # invariance formula for average bet size = C * L\n",
    "        # df['avg_order_dollars'] = c.invariance_c * df['L']\n",
    "        # CHECK NEXT LINE: EXPONENT IS 1/2 WHEN INVARIANCE EXPONENT IS 1/3. IS THIS THE CORRECT FORMULA?\n",
    "        df['avg_order_dollars'] = self.mc_over_sigma_const * (df['gamma'] \n",
    "                                        ** (c.invariance_exponent / (1.00 - c.invariance_exponent)))\n",
    "        df['avg_order_shares'] = df['avg_order_dollars'] / df['p0']\n",
    "\n",
    "        # dv means \"dollar volume\"\n",
    "        df['dv'] = df['avg_order_dollars'] * df['num_orders'] \n",
    "        \n",
    "        # Portfolios include assets with indices in range(asset_start, asset_stop, 1):\n",
    "        # vw_market and ew_market include everything\n",
    "        # Example: If c.num_size_indexes = 5 and c.N = 50, then\n",
    "        # asset_start = [0, 0, 0, 10, 20, 30, 40, 0, 10, 20, 30, 40]\n",
    "        # asset_stop = [50, 50, 10, 20, 30, 40, 50, 10, 20, 30, 40, 50]\n",
    "        asset_start = [0, 0]\n",
    "        asset_stop = [c.N, c.N]\n",
    "        # vw and ew quantile portfolios include quantile ranges:\n",
    "        asset_start += list([np.floor(R(c.N * n) / R(c.num_size_indexes)) \n",
    "                           for n in range(c.num_size_indexes)]) * 2\n",
    "        asset_stop += list([np.floor(R(c.N * (n + 1.000000001)) / R(c.num_size_indexes)) \n",
    "                                for n in range(c.num_size_indexes)]) * 2\n",
    "        # Stocks for industry portfolios are picked mod num_industry_indexes:\n",
    "        asset_start += [n for n in range(c.num_industry_indexes)] * 2\n",
    "        asset_stop += [c.N] * (2 * c.num_industry_indexes)\n",
    "        asset_stride = [1] * (2 + 2 * c.num_size_indexes)\n",
    "        asset_stride += [c.num_industry_indexes] * (2 * c.num_industry_indexes)\n",
    "        # TODO: Add asset_oformat_pdet for industry indexes?\n",
    "        df['asset_start'] = asset_start\n",
    "        df['asset_stop'] = asset_stop\n",
    "        df['asset_stride'] = asset_stride\n",
    "        df[['asset_start', 'asset_stop']] = df[['asset_start', 'asset_stop']].astype(np.int64)\n",
    "\n",
    "        # Normalize all index portfolios to have value of $100.00 --- Now done above\n",
    "        # df['p0'] = c.index_prices\n",
    "        \n",
    "        df['v'] = df['dv'] / df['p0']  # expected daily share volume\n",
    "        \n",
    "        # Placeholder for daily asset volatility of 2% per day. Does not have any effect.\n",
    "        df['sigma'] = 0.02\n",
    "\n",
    "        return df\n",
    "\n",
    "    def make_order_book_exchange(self, ptarget=None):\n",
    "        \"\"\"\n",
    "        The exchange places one buy order and one sell order for each asset to stabilize prices.\n",
    "        \"\"\"\n",
    "\n",
    "        df_asset_stats = self.df_asset_stats\n",
    "        c = self.c\n",
    "        # R = self.dtype\n",
    "\n",
    "        # Exchange places one buy and one sell order for each asset,\n",
    "        # so dfbuy and dfsell each have one row for each asset:\n",
    "\n",
    "        # Exchange does not force asset prices to be positive.\n",
    "        # Exchange trades exch_epsilon share of expected daily volume if price moves one sigma:\n",
    "        # Exchange buys if price below ptarget, sells if price above ptarget\n",
    "        # Set ph and pl to be far away from initial price:\n",
    "        # max_num_sigma = 1.00e2\n",
    "        # exch_max_qvtion = max_num_sigma * c.exch_epsilon\n",
    "\n",
    "        vns = ['dv', 'v', 'p0', 'sigma', 'n']\n",
    "\n",
    "        dfbuy = df_asset_stats[vns].copy()  # one row for each asset\n",
    "        dfsell = df_asset_stats[vns].copy()\n",
    "\n",
    "        # For different target, add argument ptarget to function and use here instead of p0. DONE!\n",
    "        #if ptarget == None:\n",
    "        #    dfbuy['ptarget'] = dfbuy['p0']\n",
    "        #    dfsell['ptarget'] = dfsell['p0']\n",
    "        #else:\n",
    "        #    dfbuy['ptarget'] = ptarget\n",
    "        #    dfsell['ptarget'] = ptarget\n",
    "            \n",
    "        #volume_adjustment_factor = c.exch_max_qv * (1.00 - 0.90 * c.fracMA) /  (c.fracMA + 0.01)    \n",
    "        #volume_adjustment_factor = c.exch_max_qv\n",
    "\n",
    "        assert c.exch_liq_model == 'mina', (\"PKError: Require c.exch_liq_model == 'mina', not \" + c.exch_liq_model)\n",
    "        assert c.exch_epsilon >= 0.00,  (\"PKError: Require c.exch_epsilon >= 0, not \" + c.exch_epsilon)\n",
    "        \n",
    "        dfbuy['w'] = 1.00\n",
    "        dfbuy['ph'] = dfbuy['p0']\n",
    "        dfbuy['q'] = c.exch_phpl_frac * c.exch_epsilon * 100.00 / dfbuy['p0']\n",
    "        dfbuy['ph_minus_pl_dollars'] = c.exch_phpl_frac * dfbuy['p0']\n",
    "        if c.exch_epsilon == 0.00:\n",
    "            dfbuy['ph_minus_pl_dollars'] = 1.00e-16  # Value does not matter. Orders gets dropped anyway!\n",
    "        dfbuy['pl'] = dfbuy['ph'] - dfbuy['ph_minus_pl_dollars']  # Mina\n",
    "\n",
    "        dfsell['w'] = -1.00\n",
    "        dfsell['ph'] = -dfsell['p0']\n",
    "        dfsell['q'] = c.exch_phpl_frac * c.exch_epsilon * 100.00 / dfsell['p0']\n",
    "        dfsell['ph_minus_pl_dollars'] = c.exch_phpl_frac * dfsell['p0']\n",
    "        if c.exch_epsilon == 0.00:\n",
    "            dfsell['ph_minus_pl_dollars'] = 1.00e-16  # Value does not matter. Orders gets dropped anyway!\n",
    "        dfsell['pl'] = dfsell['ph'] - dfsell['ph_minus_pl_dollars']\n",
    "\n",
    "        # dfsell['ph_minus_pl_dollars'] = dfsell['q'] * 10000.00 / c.exch_epsilon\n",
    "        # dfsell['pl'] = -dfsell['p0'] * (1.00 + dfsell['sigma'] * max_num_sigma)\n",
    "        # #dfsell['q'] = exch_max_qvtion * dfsell['v']\n",
    "        # dfsell['q'] = ((dfsell['ph'] - dfsell['pl']) * c.invariance_c * dfsell['L']**2 \n",
    "        #               * c.exch_epsilon / dfsell['p0']**2)\n",
    "        \n",
    "        #dfsell['q'] = ((dfsell['ph'] - dfsell['pl']) * c.exch_epsilon / dfbuy['p0']**2)\n",
    "        #dfsell['q'] = ((dfsell['ph'] - dfsell['pl']) * c.exch_epsilon / 10000.00)\n",
    "        \n",
    "        df = pd.concat([dfbuy, dfsell])\n",
    "        \n",
    "        df['order_type'] = 0\n",
    "\n",
    "        assert len(df) == 2 * c.N, \"PKError: Exchange should have 2 orders for each asset!\"\n",
    "        \n",
    "        # Drop orders of zero size.  This may change the length of df\n",
    "        df = df[df['q'] != 0.00]\n",
    "\n",
    "        assert len(df) == self.c.M0, \"PKERROR: failed consistency check\"\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "    def make_order_book_stabilizing(self, ptarget=None):\n",
    "        \"\"\"\n",
    "        The exchange places one buy order and one sell order for each asset to stabilize prices.\n",
    "        \"\"\"\n",
    "\n",
    "        df_asset_stats = self.df_asset_stats\n",
    "        c = self.c\n",
    "        # R = self.dtype\n",
    "\n",
    "        # One buy and one sell order for each asset,\n",
    "        # so dfbuy and dfsell each have one row for each asset:\n",
    "\n",
    "        vns = ['dv', 'v', 'p0', 'sigma', 'n']\n",
    "\n",
    "        dfbuy = df_asset_stats[vns].copy()  # one row for each asset\n",
    "        dfsell = df_asset_stats[vns].copy()\n",
    "        \n",
    "        # For different target, add argument ptarget to function and use here instead of p0. DONE!\n",
    "        #dfbuy['ph'] = dfbuy['p0'] * (1.00 - c.stab_dp_frac)\n",
    "        dfbuy['ph'] = dfbuy['p0'] * c.stab_ph_frac\n",
    "        dfbuy['w'] = 1.00\n",
    "        dfbuy['q'] = dfbuy['v'] * c.stab_max_qv\n",
    "        #dfbuy['ph_minus_pl_dollars'] = dfbuy['p0']  * c.stab_phpl_frac\n",
    "        dfbuy['ph_minus_pl_dollars'] = dfbuy['p0']  * (c.stab_ph_frac - c.stab_pl_frac)\n",
    "        #dfbuy['pl'] = dfbuy['ph'] - dfbuy['ph_minus_pl_dollars'] \n",
    "        dfbuy['pl'] = dfbuy['p0'] * c.stab_pl_frac \n",
    "        \n",
    "        #dfsell['ph'] = -dfsell['p0'] * (1.00 + c.stab_dp_frac)\n",
    "        dfsell['ph'] = -dfsell['p0'] * (2.00 - c.stab_ph_frac)\n",
    "        dfsell['w'] = -1.00\n",
    "        dfsell['q'] = dfsell['v'] * c.stab_max_qv\n",
    "        dfsell['ph_minus_pl_dollars'] = dfsell['p0']  * (c.stab_ph_frac - c.stab_pl_frac)\n",
    "        #dfsell['pl'] = dfsell['ph'] - dfsell['ph_minus_pl_dollars'] \n",
    "        dfsell['pl'] = -dfsell['p0'] * (2.00 - c.stab_pl_frac) \n",
    "        \n",
    "        df = pd.concat([dfbuy, dfsell])\n",
    "        \n",
    "        df['order_type'] = -1\n",
    "\n",
    "        assert len(df) == 2 * c.N, \"PKError: Should have 2 stabilizing orders for each asset!\"\n",
    "        \n",
    "        # Drop orders of zero size.  This may change the length of df\n",
    "        df = df[df['q'] != 0.00]\n",
    "\n",
    "        assert len(df) == self.c.M0s, \"PKERROR: failed consistency check\"\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def make_order_book_single_asset(self):\n",
    "\n",
    "        c = self.c\n",
    "        # R = self.dtype\n",
    "\n",
    "        df_stats = self.df_stats\n",
    "        \n",
    "        # Combine statistics for individual assets and registered indexes into one dataset.\n",
    "        # This makes it possible to define to define orders for single assets and single indexes simultaneously\n",
    "        # df_stats = pd.concat([df_asset_stats, df_index_stats])\n",
    "\n",
    "        df_stats['frac_orders'] = df_stats['gamma'] / df_stats['gamma'].sum()\n",
    "        df_stats['cum_frac_orders'] = df_stats['frac_orders'].cumsum()\n",
    "\n",
    "        # Generate empty order book as dataframe with orders indexed i:\n",
    "        \n",
    "        df = pd.DataFrame({'i' : range(c.M1)})\n",
    "        \n",
    "        # Randomly pick asset n corresponding to each order based on order share:\n",
    "        df['n'] = np.digitize(self.rng.uniform(low=0.00, high=1.00, size=c.M1),\n",
    "                              df_stats['cum_frac_orders'], right=False)\n",
    "\n",
    "        # Sort orders so that orders for same asset are together, \n",
    "        # most active individual asset n=0 at top, indexes at bottom:\n",
    "        df = df.sort_values(['n'], ascending=True)\n",
    "\n",
    "        # Change index of assets so orders for asset 0 come first:\n",
    "        df['i'] = range(c.M1)\n",
    "        df['idx'] = df['i']\n",
    "        df = df.set_index(['idx'])\n",
    "\n",
    "        # Retrieve order size and asset price from df_asset_stats: \n",
    "        df = df.merge(right=df_stats[['n', 'ticker', 'avg_order_dollars', 'avg_order_shares', 'p0']],\n",
    "                                  how='left', on=['n'] )\n",
    "\n",
    "        # Make actual order_shares random by multiplying by lognormal random variable with mean equal one:\n",
    "        df['q'] = self.rng.lognormal(mean = -0.50 * c.std_order_size**2,\n",
    "                                                sigma = c.std_order_size, size=c.M1) * df['avg_order_shares']\n",
    "\n",
    "        df['ph_minus_pl_bp'] = self.rng.lognormal(mean = -0.50 * c.std_ph_minus_pl**2,\n",
    "                                    sigma = c.std_ph_minus_pl, size=c.M1) * c.avg_ph_minus_pl_bp\n",
    "\n",
    "        # Define buy and sell orders by letting portfolio weight w be +1 or -1 drawn from binomial distribution:\n",
    "        df['w'] = self.rng.binomial(n=1, p=c.fraction_buy_orders_asset, size=c.M1) * 2.00 - 1.00\n",
    "        df['w'] = df['w'].astype(self.dtype)\n",
    "\n",
    "        # ph and pl are negative for sell orders and pl < ph, so need to multiply by w (twice):\n",
    "        df['rv_limit_price'] = self.rng.lognormal(mean = -0.50 * c.std_limit_price**2, \n",
    "                                               sigma = c.std_limit_price, size=c.M1)\n",
    "        # Multiply by 0.0001 to convert basis points to dollars\n",
    "        \n",
    "        limit_price_bias = c.limit_bias * c.std_limit_price\n",
    "        \n",
    "        df['ph'] = ( df['w'] * df['p0'] * (df['rv_limit_price'] - np.sign(df['w']) * limit_price_bias)\n",
    "                          * (1.00 + np.sign(df['w']) * df['ph_minus_pl_bp'] * 0.0001 * 0.50) )\n",
    "        df['pl'] = ( df['w'] * df['p0'] * (df['rv_limit_price'] - np.sign(df['w']) * limit_price_bias)\n",
    "                          * (1.00 - np.sign(df['w']) * df['ph_minus_pl_bp'] * 0.0001 * 0.50) )\n",
    "        \n",
    "        df['ph_minus_pl_dollars'] = (df['w'] * df['p0'] * df['rv_limit_price']\n",
    "                          * np.sign(df['w']) * df['ph_minus_pl_bp'] * 0.0001)\n",
    "        \n",
    "        df['order_type'] = 1\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def make_order_book_pairs_trade(self):\n",
    "\n",
    "        c = self.c\n",
    "        df_stats = self.df_stats\n",
    "        # R = self.dtype\n",
    "\n",
    "        df = pd.DataFrame({'i' : range(c.M2)})\n",
    "\n",
    "        # Pick stock to buy randomly, proportional to 'frac_orders', using 'cum_frac_orders':\n",
    "        df['n_buy'] = np.digitize(self.rng.uniform(low=0.00, high=1.00, size=c.M2),\n",
    "                              df_stats['cum_frac_orders'], right=False)\n",
    "\n",
    "        # Pick stock to sell randomly, making sure different stock is chosen to sell:\n",
    "        df['n_sell'] = df['n_buy']\n",
    "        assert c.N > 1, f\"PKError: Must have at least two assets! {c.N=}\"\n",
    "        while (df['n_sell'] == df['n_buy']).sum() > 0:\n",
    "            df.loc[df['n_sell'] == df['n_buy'], ['n_sell']] = np.digitize(self.rng.uniform(\n",
    "                                low=0.00, high=1.00, size=((df['n_sell'] == df['n_buy']).sum(), 1)),\n",
    "                              df_stats['cum_frac_orders'], right=False)\n",
    "\n",
    "        df = df.sort_values(['n_buy', 'n_sell'], ascending=True)\n",
    "\n",
    "        # Change index of assets so buy side of pairs trade orders sorted the same way as in df_stats:\n",
    "        df['i'] = range(c.M2)\n",
    "        df['idx'] = df['i']\n",
    "        df = df.set_index(['idx'])\n",
    "\n",
    "        # Merge asset charcteristics of buy half of pairs trade from orders for single stocks:\n",
    "        df = df.merge(right=df_stats[['n', 'avg_order_dollars', 'avg_order_shares', 'p0', 'ticker']],\n",
    "                                  how='left', left_on=['n_buy'], right_on=['n'] )\n",
    "\n",
    "        # Rename single stock characteristics to indicate buy half of pairs trade order:\n",
    "        df = df.rename(columns={'avg_order_dollars' : 'avg_order_dollars_buy',\n",
    "                               'avg_order_shares' : 'avg_order_shares_buy',\n",
    "                               'p0' : 'p_buy',\n",
    "                               'ticker' : 'ticker_buy'})\n",
    "\n",
    "        # Merge asset charcteristics of sell half of pairs trade from orders for single stocks:\n",
    "        df = df.merge(right=df_stats[['n', 'avg_order_dollars', 'avg_order_shares', 'p0', 'ticker']],\n",
    "                                  how='left', left_on=['n_sell'], right_on=['n'] )\n",
    "\n",
    "        # Rename single stock characteristics to indicate sell half of pairs trade order:\n",
    "        df = df.rename(columns={'avg_order_dollars' : 'avg_order_dollars_sell',\n",
    "                               'avg_order_shares' : 'avg_order_shares_sell',\n",
    "                               'p0' : 'p_sell',\n",
    "                               'ticker' : 'ticker_sell'})\n",
    "\n",
    "        # del df[['n_x', 'n_y']]\n",
    "\n",
    "        # Define lognormal random size of long and short sides of pairs trade.\n",
    "        # First generate lognormal with mean of one and variance of order size variance.\n",
    "        # Then generate a random order for each asset with average size of single-stock order.\n",
    "        # Finally, make dollar size of each leg of pairs trade order equal to dollar size of smaller leg.\n",
    "        # Prefix 'rv_' means 'random variable':\n",
    "        df['rv_order_dollars_buy'] = self.rng.lognormal(mean = -0.50 * c.std_order_size**2, \n",
    "                                                     sigma = c.std_order_size, size=c.M2)\n",
    "        df['rv_order_dollars_sell'] = self.rng.lognormal(mean = -0.50 * c.std_order_size**2, \n",
    "                                                      sigma = c.std_order_size, size=c.M2)\n",
    "        df['order_dollars_buy'] = df['rv_order_dollars_buy'] * df['avg_order_dollars_buy']\n",
    "        df['order_dollars_sell'] = df['rv_order_dollars_sell'] * df['avg_order_dollars_sell']\n",
    "        df['order_dollars'] = df[['order_dollars_buy', 'order_dollars_sell']].min(axis=1)\n",
    "        \n",
    "        df['q'] = 1.00\n",
    "\n",
    "        df['ph_minus_pl_bp'] = self.rng.lognormal(mean = -0.50 * c.std_ph_minus_pl**2, \n",
    "                            sigma=c.std_ph_minus_pl, size=c.M2) * c.avg_ph_minus_pl_bp\n",
    "\n",
    "        # Define pairs trade portfolio weights as shares with equal dollar value, \n",
    "        # opposite signs, different share amounts:\n",
    "        df['w_buy'] = df['order_dollars'] / df['p_buy']\n",
    "        df['w_sell'] = -df['order_dollars'] / df['p_sell']\n",
    "\n",
    "        # Since buy an sell legs have same absolute size and opposite sign, center ph and pl around rv_limit_price,\n",
    "        # with random value proportional to dollar size of legs:\n",
    "        df['rv_limit_price'] = self.rng.lognormal(mean = -0.50 * c.std_limit_price**2, \n",
    "                                               sigma = c.std_limit_price, size=c.M2)\n",
    "        df['ph'] = df['order_dollars'] *  (0.50 * 0.0001 * df['ph_minus_pl_bp'] + df['rv_limit_price'] - 1.00)\n",
    "        df['pl'] = df['order_dollars'] * (-0.50 * 0.0001 * df['ph_minus_pl_bp'] + df['rv_limit_price'] - 1.00)\n",
    "        \n",
    "        df['ph_minus_pl_dollars'] = df['order_dollars'] *  0.0001 * df['ph_minus_pl_bp']\n",
    "        \n",
    "        df['order_type'] = 2\n",
    "\n",
    "        return df\n",
    "\n",
    "    def make_order_book_random_sparse(self):\n",
    "\n",
    "        c = self.c\n",
    "        df = pd.DataFrame({'i' : range(c.Bs_M)})\n",
    "\n",
    "        m = c.Bs_M  #number of orders\n",
    "        k = c.N + c.NX  #number of assets\n",
    "\n",
    "        rmin = c.Bs_Rmin  # minimum nonzero weights per order\n",
    "        rmax = c.Bs_Rmax  # maximum nonzero weights per order\n",
    "        \n",
    "        assert 0 < c.Bs_Rmin and c.Bs_Rmin < c.Bs_Rmax\n",
    "\n",
    "        \n",
    "        df['nnz_order'] = self.rng.integers(low=rmin, high=rmax, size=m)  # number of nonzero asset weights for each order\n",
    "\n",
    "        nnz = df['nnz_order'].sum()  # total number of asset weights summed across all orders\n",
    "\n",
    "        # Inputs into coo matrix:\n",
    "        rows = np.repeat(range(m), df['nnz_order'])   #indices of orders\n",
    "        cols = self.rng.integers(low=0, high=k, size=nnz)  #indices of registered portfolios\n",
    "        wts_dollars = self.rng.standard_normal(nnz) * c.Bs_Wscale\n",
    "        if c.Bs_M > 0:\n",
    "            dollars_per_order = np.bincount(rows, weights=wts_dollars)\n",
    "        else:\n",
    "            dollars_per_order = np.nan # Should not matter since no orders.\n",
    "        \n",
    "        # Convert weights from dollars to shares\n",
    "        #_n = df_stats['n'].to_numpy()\n",
    "        _p0 = self.df_stats['p0'].to_numpy()\n",
    "        _p = _p0[cols]  # price of registered portfolio based on p0\n",
    "        wts_shares = wts_dollars / _p\n",
    "\n",
    "        w = scipy.sparse.coo_matrix((wts_shares, (rows, cols)), shape=(m, k))\n",
    "        w.sum_duplicates()\n",
    "\n",
    "        df['q'] = 1.00\n",
    "        df['dollars_per_order'] = dollars_per_order\n",
    "        df['ph'] = dollars_per_order + c.Bs_std_ph_dollars * c.Bs_Wscale * self.rng.standard_normal(m)\n",
    "        df['ph_minus_pl_bp'] = 100.00\n",
    "        df['ph_minus_pl_dollars'] = df['ph_minus_pl_bp'] * 0.0001 \n",
    "\n",
    "        w_index = pd.RangeIndex(k)\n",
    "        df[w_index] = pd.DataFrame.sparse.from_spmatrix(w)\n",
    "        \n",
    "        df['order_type'] = 999  # not used yet!\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def make_order_book_random_dense(self):\n",
    "\n",
    "        c = self.c\n",
    "        df = pd.DataFrame({'i' : range(c.Bd_M)})\n",
    "\n",
    "        m = c.Bd_M  #number of orders\n",
    "        k = c.N + c.NX  #number of assets\n",
    "\n",
    "        rmin = c.Bd_Rmin  # minimum nonzero weights per order\n",
    "        rmax = c.Bd_Rmax  # maximum nonzero weights per order\n",
    "        \n",
    "        assert 0 < c.Bd_Rmin and c.Bd_Rmin < c.Bd_Rmax\n",
    "\n",
    "        # Strategy: First construct a sparse coo matrix, then convert to dense.  May help testing.\n",
    "        \n",
    "        df['nnz_order'] = self.rng.integers(low=rmin, high=rmax, size=m)  # number of nonzero asset weights for each order\n",
    "\n",
    "        nnz = df['nnz_order'].sum()  # total number of asset weights summed across all orders\n",
    "\n",
    "        # Inputs into coo matrix:\n",
    "        rows = np.repeat(range(m), df['nnz_order'])   #indices of orders\n",
    "        cols = self.rng.integers(low=0, high=k, size=nnz)  #indices of registered portfolios\n",
    "        wts_dollars = self.rng.standard_normal(nnz) * c.Bd_Wscale\n",
    "        \n",
    "        #print(\"xyz:\", rows.shape, rows.dtype, wts_dollars.shape, wts_dollars.dtype)\n",
    "\n",
    "        if m > 0:\n",
    "            dollars_per_order = np.bincount(rows, weights=wts_dollars)\n",
    "        else:\n",
    "            # Value of dollars_per_order should not matter since there are no orders, but bincount fails.\n",
    "            dollars_per_order = np.nan\n",
    "        \n",
    "        # Convert weights from dollars to shares\n",
    "        #_n = df_stats['n'].to_numpy()\n",
    "        _p0 = self.df_stats['p0'].to_numpy()\n",
    "        _p = _p0[cols]  # price of registered portfolio based on p0\n",
    "        wts_shares = wts_dollars / _p\n",
    "\n",
    "        wstcoo = scipy.sparse.coo_matrix((wts_shares, (rows, cols)), shape=(m, k))\n",
    "        wstcoo.sum_duplicates()\n",
    "        wt = wstcoo.todense()\n",
    "        w = wt.transpose().copy()\n",
    "\n",
    "        df['q'] = 1.00\n",
    "        df['dollars_per_order'] = dollars_per_order\n",
    "        df['ph'] = dollars_per_order + c.Bd_std_ph_dollars * c.Bd_Wscale * self.rng.standard_normal(m)\n",
    "        df['ph_minus_pl_bp'] = 100.00\n",
    "        df['ph_minus_pl_dollars'] = df['ph_minus_pl_bp'] * 0.0001 \n",
    "        \n",
    "        df_temp = pd.DataFrame(wt, columns=pd.RangeIndex(k)).copy()\n",
    "        df = pd.concat([df, df_temp], axis=1)\n",
    "\n",
    "        #w_index = pd.RangeIndex(k)\n",
    "        #df[w_index] = pd.DataFrame.sparse.from_spmatrix(w)\n",
    "        #df[w_index] = pd.DataFrame(w)\n",
    "        \n",
    "        df['order_type'] = 999  # not used yet!\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "def f_test_order_book(bk=None):\n",
    "    if bk == None:\n",
    "        c = Assumptions(N=12, M=300, num_size_indexes=2, num_industry_indexes=4,\n",
    "                avg_ph_minus_pl_bp=1.00, exch_epsilon=0.00, stab_max_qv = 0.00,\n",
    "                mean_asset_price = 1.00e+2, std_asset_price = 0.00, index_prices=1.00e+2,\n",
    "                       Bs_M = 100, Bd_M = 100)    \n",
    "\n",
    "        bk = OrderBook(c, nseed=123456)\n",
    "    \n",
    "    print(\"\\n\", bk.c, \"\\n\")\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    printa(bk.RX_mat.T, 'bk.RX_mat.T')\n",
    "    print(\"\\nbk.RX_mat.T:\")\n",
    "    display(bk.RX_mat.T)\n",
    "    print(\"\\ndf_index_stats:\")\n",
    "    display(bk.df_index_stats.head())\n",
    "    display(bk.df_index_stats.tail())\n",
    "    print(\"\\ndf_asset_stats:\")\n",
    "    display(bk.df_asset_stats.head())\n",
    "    display(bk.df_asset_stats.tail())\n",
    "    print(\"\\ndf_exchange:\")\n",
    "    display(bk.df_exchange)\n",
    "    display(bk.df_exchange.head())\n",
    "    display(bk.df_exchange.tail())\n",
    "    print(\"\\ndf_stabilizing:\")\n",
    "    display(bk.df_stabilizing)\n",
    "    display(bk.df_stabilizing.head())\n",
    "    display(bk.df_stabilizing.tail())\n",
    "    print(\"\\ndf_single_asset:\")\n",
    "    display(bk.df_single_asset.head())\n",
    "    display(bk.df_single_asset.tail())\n",
    "    print(\"\\ndf_pairs_trade:\")\n",
    "    display(bk.df_pairs_trade.head())\n",
    "    display(bk.df_pairs_trade.tail())\n",
    "    print(\"\\ndf_sparse:\")\n",
    "    display(bk.df_sparse.head())\n",
    "    display(bk.df_sparse.tail())\n",
    "    print(\"\\ndf_dense:\")\n",
    "    display(bk.df_dense.head())\n",
    "    display(bk.df_dense.tail())\n",
    "    print(\"\\ndf_index_stats all:\")\n",
    "    display(bk.df_index_stats)\n",
    "    #display(bk.df_exchange)\n",
    "\n",
    "f_test_order_book()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Program Algorithm\n",
    "\n",
    "The next cell is a quadratic programming algorithm to solve the model for market-clearing prices and quantities. The algorithm is implemented in numpy and scipy using an interior point method which follows the methodology in the *cvxopt* documentation but does not actually use the *cvxopt* package.  It should take a similar number of iterations as the cvxopt algorithm.\n",
    "\n",
    "The algorithm is specialized to our problem, where the matrix $D$ ($Q$ in the algorithm) is diagonal positive definite. It can therefore be efficiently represented as a diagonal sparse matrix.  The algorithm uses registered portfolios to speed up execution. Each order trades one or two registered portfolios. Registered portfolio can be either single assets or indexes. Orders are specified by matrix $W$. The matrix $R$ is the portfolio weights defining registered portfolios. If formed explicitly, the matrix $R$ concatenates an identity matrix defining trivial weights for individual assets with another matrix $RX$ defining asset weights for indexes. Instead of forming the matrix $A = R @ W$ to first convert registered portfolio to asset weights, it is more efficient not to calculate $A$ explicitly but instead to multiply by $R$ and $W$ separately because both $R$ and $W$ are very sparse.  Moreover, it is not efficient to form the matrix $R$ explicitly because its embedded identity matrix is handles more efficiently by a linear operator which avoids explicitly multiplying by a diagonal matrix of ones.\n",
    "\n",
    "The algorithm uses the *scipy.sparse.LinearOperator* class to wrap matrices which do not have to expressed explicitly.\n",
    "I spent some time optimizing this algorithm for speed.\n",
    "On my Lenovo P1 laptop with 6 physical cores, it solves problem with 100 assets and 5000 x 3 orders in less than 0.30 sec. The cvxopt algorithm (with my choice of Cholesky method of solving the KKT equations) takes about 0.67 + 0.22 sec, two or three times as long. I think David M.'s workstation should be twice as fast or more.\n",
    "\n",
    "The algorithm is very short.  It should be easy to change or play with.  I have added some extra tweaking parameters, but they do not seem to make much difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Programming Problem Notation\n",
    "\n",
    "The quadratic programming problem in this notebook is\n",
    "$$\n",
    "\\min \\tfrac{1}{2} x'P x + c'x \\qquad \\text{subject to} \\qquad A x = b, \\qquad G x \\ge h.\n",
    "$$\n",
    "The quadratic programming problem in the paper is\n",
    "$$\n",
    "\\min \\tfrac{1}{2} x'D x - p_H'x \\qquad \\text{subject to} \\qquad W x = 0_n, \\qquad 0_m \\le x \\le q.\n",
    "$$\n",
    "The notation in this notebook uses the notation in Vandenberge (2010), \"The CVXOPT linear and quadratic cone program solvers\", a note describing the details of the *cvxopt* package.  We do not use the *cvxopt* package itself here but instead use our own direct implementation of the algorithms described in the note. Our implemention uses  *scipy* and *numpy* arrays. The *cvxopt* package uses a different package for matrix algebra; the different package has its own different implementation language. Using the same mathematical notation as Vandenberge's note makes comparing our implementation with the note easier. (One deviation from Vandengerge's notation is that we use $n$ for number of assets and $m$ for number of orders and $2m$ for number of constraints, while Vandenberge uses $n$ for number of orders and $p$ for number of assets.)\n",
    "\n",
    "As quadratic programming problems go, ours is very simple. Vandenbergs considers different kinds of constraints which map into different kinds of cone programming problems.  We have a problem with very simple Euclidean cone constraints.  \n",
    "\n",
    "Our problem is furthermore simlified since $P$ is diagonal and positive definite, $H$ stacks two identity matrices of opposite signs on top of each other to defined simple inequality constraints, and there is substantial sparsity in $A$ since portfolios representing orders for a single asset are defined as unit vectors and the only multiple-portfolio orders allowed are pairs trades.  We want to exploit the simplicity and sparsity of our problem in our algorithm.\n",
    "\n",
    "Compared with notation in the paper: \n",
    "\n",
    "$x$ is an $m \\times 1$ vector of portfolio units which maps to the same notation as $x$ in the paper. \n",
    "\n",
    "$P$ is an $m \\times m$ diagonal positive definited matrix which maps to $D$ in the paper.\n",
    "\n",
    "$c$ is and $m \\times 1$ vector which maps to $-p_H$ in the paper.\n",
    "\n",
    "$G' = [I_m, -I_m]$ is a $2m \\times m$ matrix which helps define the constraints $0_m \\le x \\le q$ as one $2m$ vector of less-than inequalities.  The sparse matrix $G$ is implemented in this notebook as a linear operator $fG$ which does not have to do any multiplication by 1 or 0.\n",
    "\n",
    "$h' = [0_m, q]$ is a $2m \\times 1$ vector which stacks an $m$-vector of zeros onto $q$ to help define $0_m \\le x \\le q$ in the paper as $G x le h$ here.\n",
    "\n",
    "$A = R W_s$ is an $n \\times m$ matrix which maps to $W$ in the paper. The matrix $R = [I_n, R_x]$ is an $n \\times (n+k)$ matrix of registered portfolio weights and $W_s$ is an $(n+k) \\times m$ sparse matrix of number of units of portfolios which are traded by an order. The $n+k$ registered portfolio weights consistent of $n$ single asset portfolios defined by unit vectors in $I_n$ plus $k$ sets of portfolio weights defined by the $n \\times k$ matrix R_x. Orders are allowed to trade either one portfolio (single asset or single index) or two portfolio (pairs trade). Thus, in the matrix $W_s$, each column of $W_s$ has either one nonzero element (which implies trading one asset or index) or two non-zero elements (defining a pairs trade, which in the simulations have one positive weight and one negative weight).  Note that $W_s$ in this notebook is different from $W$ in the paper. The subscript $s$ in $W_s$ means \"sparse\", not the dimension of the matrix.  The subscript $x$ in $R_x$ refers to indexes, not the dimension of $R_x$ which is $n \\times k$, meaning one set of $n$ asset weights for each of $k$ portfolios.  In principle, the python representation of $R_x$ could be either a *numpy* dense matrix or a *scipy* sparse matrix.  We use the *scipy* sparse implementation becaus it is slightly faster due to the fact that most indexes have a substantial number of assets and therefore many nonzero weights.\n",
    "\n",
    "$b$ maps to $0_n$, which implies markets clear when net excess demand is $b=0_n$, 0 for each asset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KKT Equations\n",
    "\n",
    "The Lagrangian for our problem is\n",
    "$$\n",
    "L = \\tfrac{1}{2} x'P x + c'x + y'(A x - b) + z'(G x - h).\n",
    "$$\n",
    "The solution to the maximization problem can be defined by KKT equations:\n",
    "$$\n",
    "P x + A'y + G'z + c = 0_m, \\qquad A x - b = 0_n, \\qquad s + G x - h = 0_{2m}, \\qquad  s \\ge 0_{2m}, \\qquad z \\ge 0_{2m}.\n",
    "$$\n",
    "Here, the first equation defines first-order conditions, the second eqution defines equality constraints for market clearing, the third equation defines inequality constriants to prevent overfilling and underfilling orders, and the inequalities define complementary slackness conditions. The variables $z$ and $y$ are multipliers for order quantities and asset prices; $s$ is a slack variable measuring the distance of $x$ from the constraint (two constraints for each order). Using slack variables $s$ allows the complementary slackness conditions $z \\ge 0_{2m}, z \\cdot (G x - h) = 0_{2m}$ to be written as $z \\ge 0_{2m}$, $s \\ge 0_{2m}$, $z \\cdot s = 0_{2m}$.  Here, the dot operator means scalar multiplication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior Point Method\n",
    "\n",
    "The interior point method can be derived by replacing the inequality constraints with log barrier penalty functions of the form $\\mu 1_{2m} ' \\log(G x - h)$, where $\\mu >0$ is a scalar weight on the penalty function which puts the same weight on each constraint. The solution to the original problem is obtained in the limit as $\\mu \\rightarrow 0$.  When transformed into KKT equations, the equalities remain the same but the inequalities are replaced by\n",
    "$$\n",
    "s \\cdot z = \\mu, \\qquad s \\ge 0_{2m}, \\qquad z \\ge 0_{2m},\n",
    "$$\n",
    "To find a solution, the interior point method iterate by improving guesses until a good enough solution is found.\n",
    "\n",
    "Let $x$, $y$, $z$, $s$ be a guess for a solution. At each iteration improvements $dx$, $dy$, $dz$, and $ds$ ar found such that $x + dx$, $y + dy$, $z + dz$, $s + ds$ are a better approximation to a solution to\n",
    "$$\n",
    "P (x + dx) + A'(y + dy) + G'(z + dz) + c = 0_m, \\qquad A (x+ dx) - b = 0_n, \\qquad s + ds + G (x + dx) - h = 0_{2m}, \\qquad (s + ds) \\cdot (z + dz) = \\mu,\n",
    "$$\n",
    "which satisfies the constraints $s \\ge 0_{2m}$, $z \\ge 0_{2m}$.  The value of $\\mu$ is gradually reduce toward 0. The iterations stop when the solution is good enough and $\\mu$ is close enough to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "\n",
    "Define the initial errors\n",
    "$$\n",
    "r_x = P x + A'y + G'z + c, \\qquad r_y = A x - b, \\qquad r_z = s + G x - h.\n",
    "$$\n",
    "Now choose $\\,dx\\,$, $\\,dy\\,$, $\\,dz\\,$, $\\,ds\\,$ to improve the solution to\n",
    "$$\n",
    "P \\,dx\\, + A'\\,dy\\, + G'\\,dz\\, = -r_x, \\qquad A \\,dx\\, = -r_y, \\qquad \\,ds\\, + G \\,dx\\, = -r_z, \\qquad (s + \\,ds\\,) \\cdot (z + \\,dz\\,) = \\mu, \\qquad s \\ge 0_{2m}, \\qquad z \\ge 0_{2m}.\n",
    "$$\n",
    "As a function of unknowns $\\,dx\\,$, $\\,dy\\,$, $\\,dz\\,$, $\\,ds\\,$, this system is nonlinear only because the product $\\,ds\\, \\cdot \\,dz\\,$ appears in the fourth equation.\n",
    "\n",
    "The nice theory of interior point methods divides the solution into two phases.  During the first phase, the value of $\\mu$ is held constant until a close-enough solution with market clearing prices is found.  During the second phase, the value of $\\mu$ is reduced and the system is re-solved.  Theoretical results on interior points methods show that if $\\mu$ is not reduce too fast, Newton's method can be used efficiently to solve the system for different values of $\\mu$ when a previous solution with near-market-clearing prices is used as a starting point.\n",
    "\n",
    "The practical algorithm combines both of these steps into one step by trying to reduce $\\mu$ to zero at each step.\n",
    "\n",
    "The solution methodolgy using Newton's method works as follows: The linearized system is identical to the nonlinear system, except for two differences: (1) the $\\,ds\\, \\cdot \\,dz\\,$ term is omitted in the fourth equation to make the system linear, and (2) $\\mu$ has been changed to 0 in the fourth equation. These two changes give us the linear system\n",
    "$$\n",
    "P \\,dx\\, + A'\\,dy\\, + G'\\,dz\\, = -r_x, \\qquad A \\,dx\\, = -r_y, \\qquad \\,ds\\, + G \\,dx\\, = -r_z, \\qquad s \\cdot \\,dz\\, + z \\cdot \\,ds\\,  = -s \\cdot z.\n",
    "$$\n",
    "To enforce the inequality constraints $s + \\,ds\\, \\ge 0_{2m}$, $ z + \\,dz\\, \\ge 0_{2m}$ after solving the linear system, the solution  $\\,dx\\,$, $\\,dy\\,$, $\\,dz\\,$, $\\,ds\\,$ is scaled down with multiplication by a factor $\\alpha$ so that the inequality constraints $s + \\alpha \\cdot \\,ds\\, > 0_{2m}$, $z + \\alpha \\cdot \\,dz\\, > 0_{2m}$ hold by some small but comfortable margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homemade function for sparse matrix multiplication of coo matrices\n",
    "\n",
    "Pytorch does not implement sparse matrix multiplication for csr matrices on the cpu when using Windows, but it does implement sparse matrix multiplication for csr matrices on the gpu.\n",
    "\n",
    "Pytorch does implement sparse matrix multiplication for coo matrices on both cpu and gpu, but the implementation is very slow, especially on cpu.\n",
    "\n",
    "The following homemade sparse matrix multiplication function implements sparse matrix multiplication for coo matrices on both cuda and cpu.  It is faster than the corresponding functions for coo matrices in Pytorch (not sure why Pytorch is so inefficient).  It is slower than the function for csr matrices on gpu.\n",
    "\n",
    "Therefore, it should be more efficient to use the homemade function for coo matrices for cpu calculations and the Pytorch function for csr matrics for gpu calculations.\n",
    "\n",
    "Since gpu calculations are, in our experience, always faster than cpu calculations, there is no reason to use the cpu except for making comparisons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Occasionally, when torch.jit.ignore is turned off in the following function,\n",
    "# nan answers are obtained from test_model(), usually on about the third pass after optimization under jit using cpu,\n",
    "# typically after changes to functions have been made.\n",
    "# Maybe torch.jit.script has bugs using cpu on Windows???\n",
    "# Note that although the function argument coomat is a sparse_coo_tensor, the function does not use\n",
    "# any coo functions except indices() and values()\n",
    "\n",
    "#@torch.jit.script\n",
    "#@torch.jit.ignore\n",
    "def f_sparse_coo_mv(coomat, y):\n",
    "    \"\"\"\n",
    "    Usage: res = f_sparse_mv()\n",
    "    \n",
    "    coomat = torch.sparse_coo_tensor with two-dimensional shape (nr, nc) (i.e., a matrix)\n",
    "    y = torch.tensor with shape (nc,) (i.e., a vector)\n",
    "    res = torch.tensor with shape (nr,)\n",
    "    \n",
    "    This function is more efficient than corresponding Pytorch function for sparse coo matrices.\n",
    "    It is less efficient than corresponding Pytorch function for sparse csr matrices.\n",
    "    Pytorch does not define matrix multiplication for sparse csr matrices on cpu on Windows.\n",
    "    Therefore, use this function as an alternative for cpu but prefer sparse csr function on cuda\n",
    "    \"\"\"\n",
    "    \n",
    "    rowindex = coomat._indices()[0]\n",
    "    colindex = coomat._indices()[1]\n",
    "    data = coomat._values()\n",
    "    #assert(coomat.indices().ndim == 2)\n",
    "    #assert(y.size()[0] == coomat.size()[1])\n",
    "    nr = coomat.size()[0]\n",
    "    yy = data * torch.index_select(y, 0, colindex)\n",
    "    res = torch.zeros((nr,), dtype=coomat.dtype, device=coomat.device)\n",
    "    res.index_add_(0, rowindex, yy)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "#@torch.jit.ignore\n",
    "def f_sparse_mv_for_cpu_and_cuda(csrmat, coomat, vec, bLinux = 0):\n",
    "    \"\"\"\n",
    "    Usage: res = f_sparse_mv_for_cpu_and_cuda(csrmat, coomat, vec)\n",
    "\n",
    "    csrmat, coomat = torch.sparse_coo_tensor with two-dimensional shape (nr, nc) (i.e., a matrix)\n",
    "    vec = torch.tensor with shape (nc,) (i.e., a vector)\n",
    "    res = torch.tensor with shape (nr,)\n",
    "    \n",
    "    This function works around sparse mv not being defined for cpu.\n",
    "    For 'cuda', it uses pytorch mv (matrix-vector product) with csr matrix.\n",
    "    For 'cpu', it uses PK's algorithm f_sparse_mv with coo matrix.\n",
    "    Therefore the algorithm, needs both the csrmat and the coomat to cover both cases.\n",
    "    \n",
    "    NB: The PK version with coo matrix is faster than the pytorch version. \n",
    "    This suggests that pytorch did not put much effort into developing a good algorithm.\n",
    "    \n",
    "    TODO: This function addresses and issue with using the cpu for sparse matrix operations under Windows. \n",
    "    We could add an option to use the csr calculations on the cpu when using Linux.\n",
    "    This would speed up calculations by perhaps a factor of 3 or more.\n",
    "    \"\"\"\n",
    "    #bLinux = 0  # function argument with default value of 0 does not compile under torch.jit.ignore!\n",
    "\n",
    "    #TODO: Figure out unexpected crashes: The next two lines seem unnecessary, \n",
    "    # but they seem to eliminate crashes due to a potential torch.jit.script bug \n",
    "    # where perhaps the size or type of res is inferred incorrectly in different if-then branches.\n",
    "    # Algorithm sometimes fail when size of n changes and torch.jit.script recompiles the code\n",
    "    # But I could not reproduce this error in a simplistic setting, so interaction with something else is important.\n",
    "    # Error only occurs under torch.jit.script and only occurs on cpu, not cuda, and only after n changes.\n",
    "    nr = csrmat.size()[0]\n",
    "    #res = torch.empty((nr,), dtype=csrmat.dtype, device=csrmat.device)  # not necessary but might help optimizer?\n",
    "    if csrmat.device != torch.device('cpu') or bLinux == 1:\n",
    "        res = csrmat.mv(vec)\n",
    "    else:\n",
    "        res = f_sparse_coo_mv(coomat, vec)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate $AQA$ --- OLD\n",
    "\n",
    "Suppose $n$ is number of assets, $k$ is number of indexes, $m$ is number of orders.\n",
    "Need to calculate $AQA = R @ Ws @ Q @ Ws.T @ R.T$, where $R$ = [I_m WX] is a matrix of registered portfolio weights, $Ws$ is $(n+k) x m$ matrix of portflio weights with either 1 or 2 nonzero weights for each order, $Q$ is a diagonal matrix.\n",
    "\n",
    "For an efficient algorithm, need to express $Ws$ as two separate matrices, one with orders for single portfolios and the other with orders for pairs trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.ignore\n",
    "def Fw_init(Ws, Wst, M2 : int, dtype : str, device : str):\n",
    "    \n",
    "    Fw_dtype = dtype\n",
    "    Fw_device = device\n",
    "    \n",
    "    M = Wst.shape[0]\n",
    "    N = Wst.shape[1]\n",
    "    M1 = M - M2\n",
    "\n",
    "    Fw_N = N\n",
    "    Fw_M1 = M1\n",
    "\n",
    "    Fw_Wcoo = Ws.coalesce()\n",
    "    Fw_Wtcoo = Wst.coalesce()\n",
    "\n",
    "    Fw_Wcsr = Fw_Wcoo.to_sparse_csr()  #Does not jit!\n",
    "    Fw_Wtcsr = Fw_Wtcoo.to_sparse_csr()  \n",
    "\n",
    "    assert Fw_Wtcoo.shape == (M , N),  (\"PKError: Shape should be (\" \n",
    "                                + str(M) + \", \" + str(N) + \"), not \" + str(Wst.shape))\n",
    "\n",
    "    assert torch.all(Fw_Wtcoo.indices()[0, M1::2] == Fw_Wtcoo.indices()[0, M1+1::2])\n",
    "\n",
    "    Fw_rows = torch.empty((M1 + 4 * M2,), dtype=torch.int64, device=Fw_device)\n",
    "    Fw_cols = torch.empty((M1 + 4 * M2,), dtype=torch.int64, device=Fw_device) \n",
    "    Fw_data = torch.empty((M1 + 4 * M2,), dtype=Fw_dtype, device=Fw_device)\n",
    "\n",
    "    Fw_rows[:M1] = Fw_Wtcoo.indices()[1, :M1]\n",
    "    Fw_cols[:M1] = Fw_Wtcoo.indices()[1, :M1]\n",
    "    Fw_data[:M1] = Fw_Wtcoo.values()[:M1] * Fw_Wtcoo.values()[:M1]\n",
    "\n",
    "    Fw_rows[M1::4] = Fw_Wtcoo.indices()[1, M1::2]\n",
    "    Fw_cols[M1::4] = Fw_Wtcoo.indices()[1, M1::2]\n",
    "    Fw_data[M1::4] = Fw_Wtcoo.values()[M1::2] * Fw_Wtcoo.values()[M1::2]\n",
    "\n",
    "    Fw_rows[M1+1::4] = Fw_Wtcoo.indices()[1, M1+1::2]\n",
    "    Fw_cols[M1+1::4] = Fw_Wtcoo.indices()[1, M1+1::2]\n",
    "    Fw_data[M1+1::4] = Fw_Wtcoo.values()[M1+1::2] * Fw_Wtcoo.values()[M1+1::2]\n",
    "\n",
    "    Fw_rows[M1+2::4] = Fw_Wtcoo.indices()[1, M1::2]\n",
    "    Fw_cols[M1+2::4] = Fw_Wtcoo.indices()[1, M1+1::2]\n",
    "    Fw_data[M1+2::4] = Fw_Wtcoo.values()[M1::2] * Fw_Wtcoo.values()[M1+1::2]\n",
    "\n",
    "    Fw_rows[M1+3::4] = Fw_Wtcoo.indices()[1, M1+1::2]\n",
    "    Fw_cols[M1+3::4] = Fw_Wtcoo.indices()[1, M1::2]\n",
    "    Fw_data[M1+3::4] = Fw_Wtcoo.values()[M1::2] * Fw_Wtcoo.values()[M1+1::2]\n",
    "\n",
    "    Fw_data4 = Fw_data[M1:].reshape(-1, 4)\n",
    "\n",
    "    Fw_indices = torch.vstack([Fw_rows, Fw_cols])\n",
    "\n",
    "    #torch.cuda.synchronize()\n",
    "\n",
    "    #print(\"initialize Fw_init yyyy\")\n",
    "    #print('Wst.shape = ', Wst.shape)\n",
    "    #print('M2 = ', M2)\n",
    "    #print('N:', N)\n",
    "    #print('M:', M)\n",
    "    #print('Fw_N:', Fw_N)\n",
    "    #print('Fw_M1:', Fw_M1)\n",
    "    ##print('qwts:', qwts.shape)\n",
    "    #print('Fw_indices:', Fw_indices.shape)\n",
    "    #print('Fw_data:', Fw_data.shape)\n",
    "    #print('Fw_data:', Fw_data.shape)\n",
    "    #print('Fw_data4:', Fw_data4.shape)\n",
    "    \n",
    "    assert Fw_data4.shape[0] == M2, (\"PKError: Should be equal\" + str(Fw_data4.shape[0]) + str(M2))\n",
    "    \n",
    "    return Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N\n",
    "\n",
    "#def Fw_mv(self, vec):\n",
    "#    return Fw_Wcsr.mv(vec)\n",
    "\n",
    "#def Fw_rmv(self, vec):    \n",
    "#    return Fw_Wtcsr.mv(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def Fw_WQW(qwts, Fw_indices, Fw_data, Fw_data4, Fw_M1 : int, Fw_N : int):\n",
    "    \n",
    "    M1 = Fw_M1\n",
    "    \n",
    "    Fw_dtype = Fw_data.dtype\n",
    "    Fw_device = Fw_data.device\n",
    "\n",
    "    qwts = qwts.reshape(-1,)\n",
    "\n",
    "    resdata = torch.empty_like(Fw_data, dtype=Fw_dtype, device=Fw_device)\n",
    "    \n",
    "    resdata[:M1] = Fw_data[:M1] * qwts[:M1]\n",
    "\n",
    "    #print('resdata.shape = ', resdata.shape)\n",
    "    #print('resdata[M1:].shape = ', resdata[M1:].shape)\n",
    "    #print('Fw_data4.shape = ', Fw_data4.shape)\n",
    "    #print('qwts.shape = ', qwts.shape)\n",
    "    #print('qwts[M1:] = ', qwts[M1:].shape)\n",
    "    \n",
    "    resdata[M1:] = (Fw_data4 * qwts[M1:].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    res = torch.sparse_coo_tensor( Fw_indices, resdata, size=(Fw_N, Fw_N), \n",
    "                                  dtype=resdata.dtype, device=Fw_device ).to_dense()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fW as linear operator based on dictionary --- NEW\n",
    "\n",
    "Idea: Define W as a dictionary consisting of both basic inputs (components of registered portfolios, individual assets, pairs trades, plus extensions) and intermediate setup values.\n",
    "\n",
    "Creating W requires a setup function Winit() with appropriate inputs. Then define fW(W, x), fWt(Wt, y), and fWqW(W, q) as functions taking this dictionary as an argument.\n",
    "\n",
    "This should be more transparent and make code easier to maintain.  Furthermore, dictionary operations likely have very little overhead, so this approach should not sacrifice much efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_initialize_misc_(bk, options):\n",
    "    \n",
    "    dtype = options['dtype']\n",
    "    device = options['device']\n",
    "    b_solve_dollars = options['b_solve_dollars']\n",
    "\n",
    "    dtypeint = torch.int64\n",
    "    deviceint = 'cpu'\n",
    "    \n",
    "    p0 = torch.tensor(bk.pbenchmark, dtype=dtype, device=device)\n",
    "    #p0 = torch.tensor(bk.p0, dtype=dtype, device=device)\n",
    "    RX = torch.tensor(bk.RX_mat, dtype=dtype, device=device)\n",
    "    #RXt = torch.tensor(bk.RXT_mat, dtype=dtype, device=device)\n",
    "    RXt = RX.t().clone().detach()\n",
    "\n",
    "    n = torch.tensor(p0.size()[0], dtype=dtypeint, device=deviceint)\n",
    "    kx = torch.tensor(RX.size()[1], dtype=dtypeint, device=deviceint)\n",
    "    k = torch.tensor(n.item() + kx.item(), dtype=dtypeint, device=deviceint)\n",
    "    # m = number of all orders from all books, unknown until after B1, B2, etc., initialized\n",
    "    b_use_torch_dictionaries = torch.tensor(1, dtype=dtypeint, device=deviceint)\n",
    "\n",
    "    bk.bks : typing.Dict[str, typing.Dict[str, torch.Tensor]] = {}\n",
    "    bkmisc = {'n' : n, 'kx' : kx, 'k' : k, 'p0' : p0, 'RX' : RX, 'RXt' : RXt,\n",
    "             'b_use_torch_dictionaries' : b_use_torch_dictionaries }\n",
    "\n",
    "    # Calculations use the weighted index weights RXwt rather than origina weights.\n",
    "    # Here we scale prices and indexes. Order weights W1, etc., are scaled in e.g. fB1_initialize_().\n",
    "    if b_solve_dollars ==True:\n",
    "        # When b_solve dollars == True, the RXwt arrays are in dollars (one dollar per share) and prices are one dollar.\n",
    "        # The norm of one dollar of long-short epxposure is one.\n",
    "\n",
    "        bkmisc['p0wts'] = bkmisc['p0']\n",
    "        bkmisc['RXtwt'] = bkmisc['p0'].reshape(1, n) * bkmisc['RXt']\n",
    "        bkmisc['RXwt'] = bkmisc['RXtwt'].t().clone().detach()\n",
    "        #bkmisc['RXwt'] = bkmisc['p0'].reshape(n, 1) * bk.misc['RX']\n",
    "        \n",
    "        r = torch.tensor(range(n), dtype=dtypeint, device=device)\n",
    "        ii = torch.vstack([r, r])\n",
    "        bkmisc['p0wts_diagmat'] = torch.sparse_coo_tensor(ii, bkmisc['p0'], dtype=dtype, device=device)\n",
    "        \n",
    "        # Orders are scaled in fB1_initialize(), etc, so that the norm of weights W is the number of long-short dollars.\n",
    "        # Rescaled weights W by dividing by this norm, making one unit of each order one long-short dollar.\n",
    "        # This requires rescaling ph, ph-pl, q ) also.\n",
    "\n",
    "    else:\n",
    "        # When b_solve dollars == False, the weighted arrays are shares.\n",
    "        # The norm of one share is one; the norm of one unit of of index is the gross number of long-short shares per unit.\n",
    "\n",
    "        bkmisc['p0wts'] = torch.ones_like(bkmisc['p0'])\n",
    "        bkmisc['RXtwt'] = bkmisc['RXt']\n",
    "        bkmisc['RXwt'] = bkmisc['RX']\n",
    "        \n",
    "        # Old version leaves W unchanged so that the norm of one unit of order W is the number of long-short shares in W.\n",
    "        # The scaling or nonscaling happens in fB1_initialize(), etc.\n",
    "\n",
    "    bk.bks['misc'] = bkmisc\n",
    "    \n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_initialize_bks_from_dfs_(bk, options):\n",
    "    \"\"\"\n",
    "    Initializes dictionaries of orders A0, A0s, B1, B2, Bs, Bd \n",
    "    by adding to the dictionary indices B1['WW1i'] and values B1['WW1v'] \n",
    "    with squares of values in B1['Wcoo'']. This can be used to facilitate calculation of \n",
    "    fWW1(B1['W'], qwts) = B1['W'] @ z @ B1['W'].t(), where z is a diagonal matric.\n",
    "    \n",
    "    Usage: fB1_initialize(B1). Returns None, but changes B1.\n",
    "    \"\"\"\n",
    "\n",
    "    dtype = options['dtype']\n",
    "    dtypeint = torch.int64\n",
    "    device = options['device']\n",
    "    deviceint = 'cpu'\n",
    "    bkmisc = bk.bks['misc']\n",
    "    #RXt = bkmisc['RXt']\n",
    "    p0 = bkmisc['p0']\n",
    "    n = bkmisc['n'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "    mm = 0\n",
    "    current_sparcity = 1\n",
    "    for name in options['bk_sparsity']:\n",
    "    \n",
    "        df = bk.dfs_all[name]\n",
    "        # sparsity: # 1=single asset, 2=pairs trade, 9=sparse, 99=dense, must be sorted!\n",
    "        B = {'sparsity' : torch.tensor(options['bk_sparsity'][name], dtype=torch.int64, device='cpu')}\n",
    "        assert B['sparsity'] >= current_sparcity, \"Name should be sorted with sparsity ascending!\"\n",
    "        current_sparsity = B['sparsity']\n",
    "        B['is_sparse'] = torch.tensor(1, dtype=torch.int64, device='cpu')\n",
    "        B['ph'] = torch.tensor(df['ph'].to_numpy(), dtype=dtype, device=device) \n",
    "        B['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'].to_numpy(), dtype=dtype, device=device)            \n",
    "        B['q'] = torch.tensor(df['q'].to_numpy(), dtype=dtype, device=device)\n",
    "        \n",
    "        if B['sparsity'] == 1:  # one rp per order\n",
    "\n",
    "            m = df['n'].to_numpy().shape[0]\n",
    "            #r = torch.tensor(range(df['n'].to_numpy().shape[0]), dtype=torch.int64, device=device)\n",
    "            r = torch.ones((df['n'].to_numpy().shape[0],), dtype=torch.int64, device=device).cumsum(0) - 1\n",
    "            c = torch.tensor(df['n'].to_numpy(), dtype=torch.int64, device=device)\n",
    "            ii = torch.vstack([r, c])\n",
    "            v = torch.tensor(df['w'].to_numpy(), dtype=dtype, device=device)\n",
    "            Wtcoo = torch.sparse_coo_tensor(ii, v, (m,k))\n",
    "            B['Wtcoo'] = Wtcoo.coalesce()\n",
    "\n",
    "        elif B['sparsity'] == 2:  # pairs trades\n",
    "\n",
    "            # Assign indices for registered portfolios, over k\n",
    "            cb = torch.tensor(df['n_buy'].to_numpy(), dtype=dtype, device=device)\n",
    "            cs = torch.tensor(df['n_sell'].to_numpy(), dtype=dtype, device=device)\n",
    "            cbs = torch.hstack([cb, cs])\n",
    "            ndim = 2\n",
    "            m = cb.size()[0]  \n",
    "            # Assign order ids as a range over m:\n",
    "            #TODO: MIGHT CHANGE TO UNIQUE ORDER IDs FROM ORDER BOOK, BUT THIS WOULD MESS UP DENSE DIMENSIONS FOR ORDERS!\n",
    "            #rb = torch.tensor(range(m), dtype=torch.int64, device=device)\n",
    "            rb = torch.ones((m,), dtype=torch.int64, device=device).cumsum(0) - 1\n",
    "            rs = rb\n",
    "            rbs = torch.hstack([rb, rs])\n",
    "            ii = torch.vstack([rbs, cbs])\n",
    "            assert ii.size() == torch.Size([2, 2 * m])\n",
    "            # Assign portfolio weights\n",
    "            vb = torch.tensor(df['w_buy'].to_numpy(), dtype=dtype, device=device)\n",
    "            vs = torch.tensor(df['w_sell'].to_numpy(), dtype=dtype, device=device)\n",
    "            v = torch.hstack([vb, vs])\n",
    "            assert v.size() == torch.Size([2 * m])\n",
    "            Wtcoo = torch.sparse_coo_tensor(ii, v, (m, k))  # NOT COALESCED YET!\n",
    "            B['is_sparse'] = torch.tensor(1, dtype=torch.int64, device='cpu')\n",
    "            B['Wtcoo'] = Wtcoo.coalesce()  # rows over m, cols over k, nnz = 2 * m\n",
    "           \n",
    "        elif B['sparsity'] == 9:  # sparse orders, e.g., 9 ish rps per order\n",
    "\n",
    "            #BsWtcoo = bk.BsWtcoo # Get sparse weights from order book as numpy array converted to scipy coo\n",
    "            BsWtcoo_scipy = df[pd.RangeIndex(k)].sparse.to_coo()  \n",
    "            m = BsWtcoo_scipy.shape[0]  \n",
    "            assert k == BsWtcoo_scipy.shape[1]\n",
    "            rows = BsWtcoo_scipy.row\n",
    "            cols = BsWtcoo_scipy.col\n",
    "            rowscols = np.vstack([rows, cols])\n",
    "            values = BsWtcoo_scipy.data\n",
    "            B['is_sparse'] = torch.tensor(1, dtype=torch.int64, device='cpu')\n",
    "            # rows over m, cols over k, nnz = 2 * m\n",
    "            B['Wtcoo'] = torch.sparse_coo_tensor(rowscols, values, (m, k), dtype=dtype, device=device).coalesce()  \n",
    "            \n",
    "        elif B['sparsity'] == 99:    \n",
    "    \n",
    "            BdWt = bk.df_dense[range(k)].to_numpy()\n",
    "            m = BdWt.shape[0]  \n",
    "            assert k == BdWt.shape[1]\n",
    "            B['is_sparse'] = torch.tensor(0, dtype=torch.int64, device='cpu')\n",
    "            # rows over m, cols over k, nnz = 2 * m:\n",
    "            B['Wtdense'] = torch.tensor(BdWt, dtype=dtype, device=device)  \n",
    "            \n",
    "        B['m'] = torch.tensor(m, dtype=dtypeint, device=deviceint)\n",
    "        B['mm0'] = torch.tensor(mm, dtype=dtypeint, device=deviceint)\n",
    "        mm += m\n",
    "        B['mm1'] = torch.tensor(mm, dtype=dtypeint, device=deviceint)\n",
    "        \n",
    "        bk.bks[name] = B\n",
    "    \n",
    "    bkmisc['m'] = torch.tensor(mm, dtype=dtypeint, device=deviceint)  # Total number of orders in all order books.\n",
    "        \n",
    "    #bk.bks['misc']['rangem'] = torch.tensor(range(bk.bks['misc']['m']), dtype=torch.int32, device=device)\n",
    "    #bk.bks['misc']['rangem1'] = torch.tensor(range(bk.bks['misc']['m'] + 1), dtype=torch.int32, device=device)\n",
    "\n",
    "    bkmisc['rangem'] = torch.ones((bk.bks['misc']['m'],), dtype=torch.int32, device='cuda').cumsum(0) - 1\n",
    "    bkmisc['rangem1'] = torch.ones((bk.bks['misc']['m'] + 1,), dtype=torch.int32, device='cuda').cumsum(0) - 1\n",
    "    \n",
    "    #bkmisc['ijm'] = torch.vstack([bk.bks['misc']['rangem'], bk.bks['misc']['rangem']])\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ftest_WAqWBt: outputs\n",
      "sizes: torch.Size([13]) torch.Size([13]) torch.Size([13]) torch.Size([13]) torch.Size([20])\n",
      "\n",
      "f:colsa=array([1, 2, 0, 1, 3, 2, 3, 4], dtype=int64)\n",
      "rowsa=array([ 0,  0,  2,  6,  6,  9, 10, 12], dtype=int64)\n",
      "va=array([10., 20., 30., 40., 50., 60., 70., 80.])\n",
      "colsb=array([2, 0, 1, 1, 5, 7], dtype=int64)\n",
      "rowsb=array([ 0,  2,  6,  7,  8, 10], dtype=int64)\n",
      "vb=array([11., 22., 33., 44., 55., 66.])\n",
      "\n",
      "f:resc=array([ 0,  0,  2,  6,  6, 10], dtype=int64)\n",
      "resca=array([1, 2, 0, 1, 3, 3], dtype=int64)\n",
      "rescb=array([2, 2, 0, 1, 1, 7], dtype=int64)\n",
      "resv=array([ 110.,  220.,  660., 1320., 1650., 4620.])\n",
      "g: (3242494,) 1.9822871685028076\n",
      "g: (3242494,) 3.1253573894500732\n",
      "g: (3242494,) 0.0281221866607666\n",
      "g: (3242494,) 0.02964305877685547\n",
      "g: (3242494,) 0.050391197204589844\n"
     ]
    }
   ],
   "source": [
    "# Function to set up gram matrix calculation WqW:\n",
    "# Function takes inputs to coo matrix constructor as inputs.\n",
    "\n",
    "#@numba.njit # Not necessary since numba.jit.script(fWAqWBt_setup) called later\n",
    "def fBs_setup(rowsa, colsa, va, rowsb, colsb, vb):\n",
    "    \"\"\"\n",
    "    This function operates on numpy arrays so that numba.jit can be used on it!\n",
    "    \n",
    "    Function to precalulate values for W @ q @ Q using inputs of arbitrary coo matrix.\n",
    "    \n",
    "    Inputs are row indices rowsa, column indices colsa, values va of what will be sparse coo matrix WA;\n",
    "    row indices rowsb, column indices colsb, values vb of what will be sparse coo matrix WB.\n",
    "\n",
    "    Returns elements of sparse coo matrix needed to help calculate WAt @ q @ WB, where q is a diagonal matrix.\n",
    "    This setup has row indices r, column WA indices colsa, column WB indices colsb,\n",
    "    values with WA[r[n], colsa[n]] * WB[r[n], colsb[n]] .\n",
    "    For a column with ia matches in WA and ib matches in WB, the setup has ia * ib rows.\n",
    "\n",
    "    PYTORCH COO TENSORS ARE SORTED BY ROW WHEN COALESCED.  TO CALCULATE W * q * Wt,\n",
    "    THIS FUNCTION SHOULD BE CALLED ON THE COALESCED TRANSPOSE OF THE TORCH COO TENSOR:\n",
    "\n",
    "    Wt = W.t().coalesce()\n",
    "    rows = Wt.indices()[0].numpy()\n",
    "    cols = Wt.indices()[1].numpy()\n",
    "    values = Wt.values().numpy()\n",
    "    resr, resca, rescb, resv = fWAqWBt_setup(rows, cols, values, rows, cols, values)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert rowsa.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert va.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    assert rowsb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert vb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    # Calculate exact size of the array needed to hold the results:\n",
    "    bca = np.bincount(rowsa)\n",
    "    bcb = np.bincount(rowsb)\n",
    "    bcsize = min(bca.shape[0], bcb.shape[0])\n",
    "    nsize = (bca[0:bcsize] * bcb[0:bcsize]).sum()\n",
    "\n",
    "    resr = np.empty((nsize,), dtype=np.int64)\n",
    "    resca = np.empty((nsize,), dtype=np.int64)\n",
    "    rescb = np.empty((nsize,), dtype=np.int64)\n",
    "    resv = np.empty((nsize,), dtype=np.float64)\n",
    "\n",
    "    sizea = colsa.shape[0]\n",
    "    sizeb = colsb.shape[0]\n",
    "\n",
    "    ia = 0\n",
    "    ib = 0\n",
    "    n = 0\n",
    "\n",
    "    while ia < sizea and ib < sizeb:\n",
    "        if rowsa[ia] < rowsb[ib]:\n",
    "            ia += 1\n",
    "            if rowsa[ia-1] > rowsa[ia]:\n",
    "                print(\"rowa should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue    \n",
    "        if rowsb[ib] < rowsa[ia]:        \n",
    "            ib += 1\n",
    "            if rowsb[ib-1] > rowsb[ib]:\n",
    "                print(\"rowb should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue\n",
    "        r = rowsa[ia]\n",
    "        iia = ia\n",
    "        while iia < sizea and rowsa[iia] == r:\n",
    "            iib = ib\n",
    "            while iib < sizeb and rowsb[iib] == r:\n",
    "                resr[n] = r\n",
    "                resca[n] = colsa[iia]\n",
    "                rescb[n] = colsb[iib]\n",
    "                resv[n] = va[iia] * vb[iib]\n",
    "                #print(f\"{iia=}, {iib=}, {ia=}, {ib=}, {n=}, {resr[n]=}, {resca[n]=}, {rescb[n]=}, {resv[n]=}\")\n",
    "                n += 1\n",
    "                iib += 1\n",
    "            iia += 1\n",
    "        ia = iia\n",
    "        ib = iib\n",
    "\n",
    "    return resr, resca, rescb, resv\n",
    "\n",
    "\n",
    "def fWAqWBt(r, ca, cb, v, size, q):\n",
    "    \"\"\"\n",
    "    This function takes torch tensors, which require conversion from the numpy arrays\n",
    "    which are output from setup function fWAqWBt_setup using numba.jit.  \n",
    "    TODO: NEED TO FIX THIS DESIGN ISSUE!\n",
    "    \n",
    "    Calculates matrix W @ q @ W where r indexes orders, ca indexes assets, cb indexes assets traspose,\n",
    "    v is values of product of values indexed by ca and cb, \n",
    "    size is shape of output (assets * assets n * n or registered portfolios by registered portfolios k * k),\n",
    "    q is a diagonal matrix.\n",
    "    \n",
    "    This is a homemade altorithm using index_select, then sparse_coo_tensor(...).to_dense().\n",
    "    The sparse_coo_tensor(...).to_dense() step is the bottleneck in the program.\n",
    "    \n",
    "    GPU memory is likely to be another bottleneck \n",
    "    if there are many random orders for portfolios containing many assets or registered portfolios.\n",
    "    \"\"\"\n",
    "    \n",
    "    vals = v * torch.index_select(q, 0, r)\n",
    "    ii = torch.vstack([ca, cb])\n",
    "    \n",
    "    res = torch.sparse_coo_tensor( ii, vals, size=size, \n",
    "                                  dtype=vals.dtype, device=vals.device ).to_dense()\n",
    "    return res\n",
    "\n",
    "def ftest_WAqWBt():\n",
    "    \n",
    "    n = 5\n",
    "    m = 20\n",
    "    nnz = 10\n",
    "\n",
    "    dtype = torch.float64\n",
    "    device = 'cpu'\n",
    "\n",
    "    ri = torch.randint(0, n, [nnz], dtype=torch.int64, device=device)\n",
    "    ci = torch.randint(0, m, [nnz], dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([ri, ci])\n",
    "    v = torch.randn([nnz], dtype=dtype, device=device)\n",
    "    A1coo = torch.sparse_coo_tensor(ii, v, size=(n, m), dtype=dtype, device=device)\n",
    "    \n",
    "    A1coot = A1coo.t().coalesce()\n",
    "    rti = A1coot.indices()[0].clone().detach()\n",
    "    cti = A1coot.indices()[1].clone().detach()\n",
    "    vt = A1coot.values().clone().detach()\n",
    "    \n",
    "    q = torch.randn((m,), dtype=dtype, device=device)\n",
    "    \n",
    "    r, ca, cb, v = fBs_setup(rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy(), \n",
    "                                 rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy())\n",
    "    \n",
    "    r = torch.tensor(r, device=device, dtype=torch.int64)\n",
    "    ca = torch.tensor(ca, device=device, dtype=torch.int64)\n",
    "    cb = torch.tensor(cb, device=device, dtype=torch.int64)\n",
    "    v = torch.tensor(v, device=device, dtype=dtype)\n",
    "\n",
    "    print(\"\\nftest_WAqWBt: outputs\")\n",
    "    print(\"sizes:\", r.size(), ca.size(), cb.size(), v.size(), q.size())\n",
    "    \n",
    "    res = fWAqWBt(r, ca, cb, v, (n,n), q)\n",
    "\n",
    "    return res\n",
    "    \n",
    "ftest_WAqWBt()\n",
    "    \n",
    "    \n",
    "\n",
    "def ftest(fWAqWBt_setup):\n",
    "\n",
    "    rowsa = np.array([0, 0, 2, 6, 6, 9, 10, 12], dtype=np.int64)\n",
    "    colsa = np.array([1, 2, 0, 1, 3, 2,  3,  4], dtype=np.int64)\n",
    "    va = np.array([10.00, 20.00, 30.00, 40.00, 50.00, 60.00, 70.00, 80.00], dtype=np.float64)\n",
    "\n",
    "    rowsb = np.array([0, 2, 6, 7, 8, 10], dtype=np.int64)\n",
    "    colsb = np.array([2, 0, 1, 1, 5, 7], dtype=np.int64)\n",
    "    vb = np.array([11.00, 22.00, 33.00, 44.00, 55.00, 66.00], dtype=np.float64)\n",
    "\n",
    "    resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsb, colsb, vb)\n",
    "\n",
    "    print(f\"\\nf:{colsa=}\\n{rowsa=}\\n{va=}\\n{colsb=}\\n{rowsb=}\\n{vb=}\")\n",
    "    print(f\"\\nf:{resc=}\\n{resca=}\\n{rescb=}\\n{resv=}\")\n",
    "\n",
    "    n = 10\n",
    "    m = 20\n",
    "    nnz = 15\n",
    "\n",
    "    for i in range(1000):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        rowsa = rng.integers(0, m, size=nnz)\n",
    "        colsa = rng.integers(0, n, size=nnz)\n",
    "        va = rng.standard_normal((nnz,))\n",
    "\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    \n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "def gtest(fWAqWBt_setup):\n",
    "\n",
    "    n = 500\n",
    "    m = 20000\n",
    "    assets_per_order = 2\n",
    "\n",
    "    sizea = m * assets_per_order\n",
    "    sizeb = m * assets_per_order\n",
    "\n",
    "    rng = np.random.default_rng(12345)\n",
    "\n",
    "    rowsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    rowsa.sort()\n",
    "    colsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    va = rng.standard_normal(size=sizea)\n",
    "\n",
    "    rowsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    rowsb.sort()\n",
    "    colsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    vb = rng.standard_normal(size=sizeb)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(1):\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(\"g:\", resc.shape, dt)\n",
    "\n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "#resc, resca, rescb, resv = f()\n",
    "\n",
    "#fjtest = numba.njit(f)\n",
    "\n",
    "fBs_setup_jit = numba.njit(fBs_setup)\n",
    "\n",
    "ftest(fBs_setup)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "\n",
    "gtest(fBs_setup)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "\n",
    "\n",
    "#%timeit g(fBs_setup)\n",
    "#%timeit g(fBs_setup_jit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_initialize_bks_scaled_for_qp_(bk, options):\n",
    "\n",
    "    bkmisc = bk.bks['misc']\n",
    "    k = bkmisc['k'].item()\n",
    "    p0 = bkmisc['p0']\n",
    "    RXt = bkmisc['RXt']\n",
    "    dtype = options['dtype']\n",
    "    device = options['device']\n",
    "    \n",
    "    i0 = torch.empty((0,), dtype=torch.int64, device=device)\n",
    "    ij0 = torch.vstack([i0, i0])\n",
    "    i220 = torch.empty((0, 2, 2), dtype=torch.int64, device=device)\n",
    "    v0 = torch.empty((0,), dtype=dtype, device=device)\n",
    "    v220 = torch.empty((0,2, 2), dtype=dtype, device=device)\n",
    "    Wtcoo0 = torch.sparse_coo_tensor(ij0, v0, size=(0, k), device=device)\n",
    "    Wtdense0 = torch.empty(size=(0, k), dtype=dtype, device=device)\n",
    "\n",
    "    # Create indices for sparsity 1, 2, 9, 99\n",
    "    \n",
    "    m1 = 0\n",
    "    m2 = 0\n",
    "    ms = 0\n",
    "    md = 0\n",
    "\n",
    "    # Loop over books to create scaled variables:\n",
    "    \n",
    "    for name in options['bk_sparsity']: # name = 'A0', 'A0s', 'B1', 'B2', 'Bs', 'Bd'\n",
    "        \n",
    "        B = bk.bks[name]\n",
    "        sparsity = options['bk_sparsity'][name]  # Should be in {1,2,9,99}\n",
    "        assert sparsity in {1, 2, 9, 99}, \"Internal error. sparsity should be in {1,2,9,99}\"\n",
    "\n",
    "        if sparsity == 1:\n",
    "            m1 += B['m'].item()\n",
    "        if sparsity == 2:\n",
    "            m2 += B['m'].item()\n",
    "        if sparsity == 9:\n",
    "            ms += B['m'].item()\n",
    "        if sparsity == 99:\n",
    "            md += B['m'].item()\n",
    "        \n",
    "        if options['b_solve_dollars'] == True:\n",
    "\n",
    "            #print(\"B1---solve_dollars == True\")\n",
    "\n",
    "            # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "            if sparsity in {1, 2, 9}:\n",
    "                Wnorm = B['Wtcoo'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "            else:\n",
    "                assert sparsity == 99, \"Should be dense!\"\n",
    "                Wnorm = B['Wtdense'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "            Wnorminv = 1.00 / Wnorm\n",
    "            r = torch.tensor(range(B['m']), dtype=torch.int64, device=device)\n",
    "            indices = torch.vstack([r, r])\n",
    "            Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "            if options['bk_sparsity'][name] in {1, 2, 9}:\n",
    "                B['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, B['Wtcoo']).coalesce()\n",
    "            else:\n",
    "                B['Wtdense_scaled'] = torch.mm(Wnorminv_diagmat, B['Wtdense'])\n",
    "            B['ph_scaled'] = B['ph'] * Wnorminv\n",
    "            B['ph_minus_pl_scaled'] = B['ph_minus_pl'] * Wnorminv\n",
    "            B['q_scaled'] = B['q'] * Wnorm\n",
    "\n",
    "        else:\n",
    "            # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "\n",
    "            if sparsity in {1,2,9}:\n",
    "                B['Wtcoo_scaled'] = B['Wtcoo'].coalesce()\n",
    "            else:\n",
    "                B['Wtdense_scaled'] = B['Wtdense'] \n",
    "            B['ph_scaled'] = B['ph']\n",
    "            B['ph_minus_pl_scaled'] = B['ph_minus_pl']\n",
    "            B['q_scaled'] = B['q']\n",
    "\n",
    "        # Create special arrays for calculation of W q Wt    \n",
    "\n",
    "        if sparsity == 1:\n",
    "            i1 = B['Wtcoo_scaled'].indices()[1]  # rows over m, cols over k\n",
    "            B['WW1ij_scaled'] = torch.vstack([i1, i1])\n",
    "            B['WW1v_scaled'] = B['Wtcoo_scaled'].values() * B['Wtcoo_scaled'].values()\n",
    "        elif sparsity == 2:    \n",
    "            #B['WW1i_scaled'] = B['Wtcoo_scaled'].indices()  # rows over m, cols over k\n",
    "            #B['WW1v_scaled'] = B['Wtcoo_scaled'].values() * B['Wtcoo_scaled'].values()\n",
    "            ndim = 2\n",
    "            m = B['m'].item()\n",
    "            ii = B['Wtcoo_scaled'].indices().reshape(2, m, ndim, 1).broadcast_to(2, m, ndim, ndim)\n",
    "            iit = B['Wtcoo_scaled'].indices().reshape(2, m, 1, ndim).broadcast_to(2, m, ndim, ndim)\n",
    "\n",
    "            assert ii.size() == torch.Size([2, m, ndim, ndim])\n",
    "            assert iit.size() == torch.Size([2, m, ndim, ndim])\n",
    "\n",
    "            # Check that order IDs are the same in ndim x ndim dimension:\n",
    "            assert (ii[0, :, :, :] == ii[0, :, 0:1, 0:1]).all(), \"PKError: Inconsistency in order IDs!\"\n",
    "\n",
    "            # Premultiply values to simplify repeated calculations of W @ q @ W later:\n",
    "            v = B['Wtcoo_scaled'].values().reshape(m, ndim, 1).broadcast_to(m, ndim, ndim)\n",
    "            vt = B['Wtcoo_scaled'].values().reshape(m, 1, ndim).broadcast_to(m, ndim, ndim)\n",
    "            vv = v * vt\n",
    "\n",
    "            assert ii[1].size() == torch.Size([m, ndim, ndim])\n",
    "            assert iit[1].size() == torch.Size([m, ndim, ndim])\n",
    "            assert vv.size() == torch.Size([m, ndim, ndim])\n",
    "\n",
    "            # Get indices of registered portfolios and transpose\n",
    "            i2 =  ii[1].reshape(m * ndim * ndim)\n",
    "            i2t = iit[1].reshape(m * ndim * ndim)\n",
    "            ij2 = torch.vstack([i2, i2t])\n",
    "            #B['WW2ij_scaled'] = ii[1].reshape(m * ndim * ndim)\n",
    "            #B['WW2it_scaled'] = iit[1].reshape(m * ndim * ndim)\n",
    "            B['WW2ij_scaled'] = ij2\n",
    "            B['WW2v_scaled'] = vv\n",
    "            \n",
    "        elif sparsity == 9:\n",
    "            # Set up helper arrays to facilitate calculation of AQA for Btcoo:\n",
    "            # The following function uses numpy arrays and numba.jit to juggle indices:\n",
    "\n",
    "            WWrows, WWcols, WWtcols, WWvals = fBs_setup(\n",
    "                B['Wtcoo_scaled'].indices()[0].cpu().numpy(), \n",
    "                B['Wtcoo_scaled'].indices()[1].cpu().numpy(), \n",
    "                B['Wtcoo_scaled'].values().cpu().numpy(), \n",
    "                B['Wtcoo_scaled'].indices()[0].cpu().numpy(), \n",
    "                B['Wtcoo_scaled'].indices()[1].cpu().numpy(), \n",
    "                B['Wtcoo_scaled'].values().cpu().numpy()) \n",
    "\n",
    "            B['WWsr_scaled'] = torch.tensor(WWrows, dtype=torch.int64, device=device)  # indices for orders\n",
    "            #B['WWsi_scaled'] = torch.tensor(WWcols, dtype=torch.int64, device=device)  # indices for registered portfolios\n",
    "            #B['WWsit_scaled'] = torch.tensor(WWtcols, dtype=torch.int64, device=device) # transpose indices for registered portfolios\n",
    "            \n",
    "            _is = torch.tensor(WWcols, dtype=torch.int64, device=device)  # indices for registered portfolios \n",
    "            _ist = torch.tensor(WWtcols, dtype=torch.int64, device=device) # transpose indices for registered portfolios\n",
    "            _ijs = torch.vstack([_is, _ist])\n",
    "\n",
    "            B['WWsij_scaled'] = _ijs\n",
    "            B['WWsv_scaled'] = torch.tensor(WWvals, dtype=dtype, device=device)  # premultiplied products of weights\n",
    "        else: \n",
    "            assert sparsity == 99, \"Remaining books should be dense.\"\n",
    "            pass  # No special arrays needed to calculate W q Wt\n",
    "     \n",
    "    # Create stacked arrays\n",
    "\n",
    "    bk.bks['_Bsparse_scaled'] = {} \n",
    "    bk.bks['_Bdense_scaled'] = {}\n",
    "    bksparse = bk.bks['_Bsparse_scaled']\n",
    "    bkdense = bk.bks['_Bdense_scaled']\n",
    "\n",
    "    bksparse['ph_scaled'] = torch.hstack([v0] + [bk.bks[name]['ph_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] in {1, 2, 9}])\n",
    "\n",
    "    bksparse['ph_minus_pl_scaled'] = torch.hstack([v0] + [bk.bks[name]['ph_minus_pl_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] in {1, 2, 9}])\n",
    "\n",
    "    bksparse['q_scaled'] = torch.hstack([v0] + [bk.bks[name]['q_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] in {1, 2, 9}])\n",
    "\n",
    "\n",
    "    bkdense['ph_scaled'] = torch.hstack([v0] + [bk.bks[name]['ph_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 99])\n",
    "\n",
    "    bkdense['ph_minus_pl_scaled'] =  torch.hstack([v0] + [bk.bks[name]['ph_minus_pl_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 99])\n",
    "\n",
    "    bkdense['q_scaled'] =  torch.hstack([v0] + [bk.bks[name]['q_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 99])\n",
    "    \n",
    "    bksparse['Wtcoo_scaled'] = torch.vstack([Wtcoo0] + [bk.bks[name]['Wtcoo_scaled'] for name in options['bk_sparsity'] \n",
    "                                     if options['bk_sparsity'][name] in {1, 2, 9}]).coalesce()\n",
    "\n",
    "    bkdense['Wtdense_scaled'] = torch.vstack([Wtdense0] + [bk.bks[name]['Wtdense_scaled'] \n",
    "                                                     for name in options['bk_sparsity'] \n",
    "                                                     if options['bk_sparsity'][name] == 99])\n",
    "\n",
    "    #print(\"Should be big: \", bksparse['Wtcoo_scaled'])\n",
    "    #print(\"Might be size 0: \", bkdense['Wtdense_scaled'])\n",
    "    \n",
    "    bksparse['Wcoo_scaled'] = bksparse['Wtcoo_scaled'].t().coalesce()\n",
    "    \n",
    "    bksparse['Wtcsr_scaled'] = bksparse['Wtcoo_scaled'].to_sparse_csr()\n",
    "    \n",
    "    bksparse['Wcsr_scaled'] = bksparse['Wcoo_scaled'].to_sparse_csr()\n",
    "    \n",
    "    bkdense['Wtdense_scaled'] = torch.vstack([Wtdense0] + [bk.bks[name]['Wtdense_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 99])\n",
    "    \n",
    "    bksparse['WW1ij_scaled'] =  torch.hstack([ij0] + [bk.bks[name]['WW1ij_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 1])\n",
    "    \n",
    "    bksparse['WW1v_scaled'] =  torch.hstack([v0] + [bk.bks[name]['WW1v_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 1])\n",
    "\n",
    "    bksparse['WW2ij_scaled'] =  torch.hstack([i0] + [bk.bks[name]['WW2ij_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 2])\n",
    "\n",
    "    #bksparse['WW2it_scaled'] =  torch.hstack([i0] + [bk.bks[name]['WW2it_scaled'] \n",
    "    #                                            for name in options['bk_sparsity']\n",
    "    #                                            if options['bk_sparsity'][name] == 2])\n",
    "\n",
    "    bksparse['WW2v_scaled'] =  torch.hstack([v0] + [bk.bks[name]['WW2v_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 2])\n",
    "\n",
    "    bksparse['WWsr_scaled'] =  torch.hstack([i0] + [bk.bks[name]['WWsr_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 9])\n",
    "\n",
    "    bksparse['WWsij_scaled'] =  torch.hstack([i0] + [bk.bks[name]['WWsij_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 9])\n",
    "\n",
    "    #bksparse['WWsit_scaled'] =  torch.hstack([i0] + [bk.bks[name]['WWsit_scaled'] \n",
    "    #                                            for name in options['bk_sparsity']\n",
    "    #                                            if options['bk_sparsity'][name] == 9])\n",
    "\n",
    "    bksparse['WWsv_scaled'] =  torch.hstack([v0] + [bk.bks[name]['WWsv_scaled'] \n",
    "                                                for name in options['bk_sparsity']\n",
    "                                                if options['bk_sparsity'][name] == 9])\n",
    "\n",
    "    bksparse['WWiii_scaled'] = torch.hstack([bksparse['WW1ij_scaled'], bksparse['WW2ij_scaled'], \n",
    "                                                                       bksparse['WWsij_scaled']])\n",
    "\n",
    "    \n",
    "    bksparse['m'] = bksparse['Wtcoo_scaled'].size()[0]\n",
    "    bkdense['m'] = bkdense['Wtdense_scaled'].size()[0]\n",
    "\n",
    "    bksparse['m1'] = torch.tensor(m1, dtype=torch.int64, device='cpu')\n",
    "    bksparse['m2'] = torch.tensor(m2, dtype=torch.int64, device='cpu')\n",
    "    bksparse['ms'] = torch.tensor(ms, dtype=torch.int64, device='cpu')\n",
    "    bksparse['m'] = torch.tensor(m1 + m2 + ms, dtype=torch.int64, device='cpu')\n",
    "\n",
    "    #print(\"bkdense['m'] == bkdense['Wtdense_scaled'].size()[0]\", bkdense['m'], bkdense['Wtdense_scaled'].size()[0])\n",
    "    #print(\"bksparse['m'] == bksparse['Wtcoo_scaled'].size()[0]\", bksparse['m'], bksparse['Wtcoo_scaled'].size()[0])\n",
    "    \n",
    "    assert bksparse['m'] == bksparse['Wtcoo_scaled'].size()[0]\n",
    "\n",
    "    bkdense['md'] = torch.tensor(md, dtype=torch.int64, device='cpu')\n",
    "    bkdense['m'] =  torch.tensor(md, dtype=torch.int64, device='cpu')\n",
    "    \n",
    "    assert bkdense['m'] == bkdense['Wtdense_scaled'].size()[0]\n",
    "    \n",
    "    # for slicing vectors like x of dimension bkmisc['m']\n",
    "    \n",
    "    bksparse['mm10'] =  torch.tensor(0, dtype=torch.int64, device='cpu')\n",
    "    bksparse['mm11'] =  torch.tensor(m1, dtype=torch.int64, device='cpu')\n",
    "\n",
    "    bksparse['mm20'] =  torch.tensor(m1, dtype=torch.int64, device='cpu')\n",
    "    bksparse['mm21'] =  torch.tensor(m1 + m2, dtype=torch.int64, device='cpu')\n",
    "    \n",
    "    bksparse['mms0'] =  torch.tensor(m1 + m2, dtype=torch.int64, device='cpu')\n",
    "    bksparse['mms1'] =  torch.tensor(m1 + m2 + ms, dtype=torch.int64, device='cpu')\n",
    "    \n",
    "    bkdense['mmd0'] =  torch.tensor(m1 + m2 + m2, dtype=torch.int64, device='cpu')\n",
    "    bkdense['mmd1'] =  torch.tensor(m1 + m2 + ms + md, dtype=torch.int64, device='cpu')\n",
    "    \n",
    "    assert bkdense['mmd1'] == bkmisc['m']  # total number of all orders across all B\n",
    "    \n",
    "    # TODO: Add indices for stacked arrays???: Maybe not needed\n",
    "\n",
    "    # TODO: Delete unneeded arrays here:\n",
    " \n",
    "    #print(\"Strings to delete:\")\n",
    "    #for B in bk.bks:\n",
    "    #    if B not in {'_Bsparse_scaled', '_Bdense_scaled'}:\n",
    "    #        print(\"\\n\", B)\n",
    "    #        kkk = bk.bks[B].copy()\n",
    "    #        for kk in kkk:\n",
    "    #            if '_scaled' in kk:\n",
    "    #                print(kk, end=\", \")\n",
    "    #                del bk.bks[B][kk]\n",
    "    #print(\"\\nEnd of strings to delete\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_Wx(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], x, bLinux=0):\n",
    "\n",
    "    bkmisc = bks['misc']\n",
    "    bksparse = bks['_Bsparse_scaled']\n",
    "    bkdense = bks['_Bdense_scaled']\n",
    "    \n",
    "    RXwt = bkmisc['RXwt'] \n",
    "    p0wts = bkmisc['p0wts']\n",
    "    m = bkmisc['m'].item()\n",
    "    n = bkmisc['n'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "    \n",
    "    mm10 = bksparse['mm10'].item()\n",
    "    mm11 =  bksparse['mm11'].item()\n",
    "    \n",
    "    mm20 = bksparse['mm20'].item()\n",
    "    mm21 =  bksparse['mm21'].item()\n",
    "    \n",
    "    mms0 = bksparse['mms0'].item()\n",
    "    mms1 =  bksparse['mms1'].item()\n",
    "    \n",
    "    mmd0 = bkdense['mmd0'].item()\n",
    "    mmd1 =  bkdense['mmd1'].item()\n",
    "\n",
    "    slice1 = slice(mm10, mm11)\n",
    "    slice2 = slice(mm20, mm21)\n",
    "    sliced = slice(mmd0, mmd1)\n",
    "    slices = slice(mms0, mms1)\n",
    "    \n",
    "    temp = torch.zeros(k, dtype=RXwt.dtype, device=RXwt.device)\n",
    "\n",
    "    if RXwt.device != 'cpu' or bLinux != 0:\n",
    "        temp += bksparse['Wcsr_scaled'] @ x[0 : mms1]  # fixe slice to be nicer over all sparse indices\n",
    "    else:    \n",
    "        temp += f_sparse_coo_mv(bksparse['Wcoo_scaled'], x[0 : mms1])  # fixe slice to be nicer over all sparse indices\n",
    "\n",
    "    if bkdense['m'] > 0:    \n",
    "        temp += bkdense['Wtdense_scaled'].t() @ x[mmd0 : mmd1]  # fixe slice to be nicer over all sparse indices\n",
    "\n",
    "    #print(\"p0wts\", p0wts.shape, \", res\", res.shape, \"RXwt\", RXwt.shape)\n",
    "    \n",
    "    res = p0wts * temp[:n] + RXwt @ temp[n:]            \n",
    "    \n",
    "    return res\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_Wty(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], y, bLinux=0):\n",
    "\n",
    "    bkmisc = bks['misc']\n",
    "    bksparse = bks['_Bsparse_scaled']\n",
    "    bkdense = bks['_Bdense_scaled']\n",
    "    \n",
    "    #RXwt = bkmisc['RXwt'] \n",
    "    RXtwt = bkmisc['RXtwt'] \n",
    "    p0wts = bkmisc['p0wts']\n",
    "    #m = int(bkmisc['m'].item())\n",
    "    #n = int(bkmisc['n'].item())\n",
    "    #k = int(bkmisc['k'].item())\n",
    "    \n",
    "    pty = p0wts * y\n",
    "    Rty = torch.hstack([pty,  RXtwt @ y])\n",
    "\n",
    "    temps = []\n",
    "    #temp = torch.empty([1], dtype=RXt.dtype, device=RXt.device)  # Need to initialize in all branches\n",
    "\n",
    "    # The following algorithm is slightly slower but should work if everything is dense:\n",
    "    \n",
    "    #if RXtwt.device != 'cpu' or bLinux == 1:\n",
    "    #    temps.append( bksparse['Wtcsr_scaled'] @ Rty )\n",
    "    #else:    \n",
    "    #    temps.append( f_sparse_coo_mv(bksparse['Wtcoo_scaled'], Rty) )\n",
    "    #temps.append( bkdense['Wtdense_scaled'] @ Rty )\n",
    "    \n",
    "    #res = torch.hstack(temps)\n",
    "\n",
    "    # The following algorithm may be faster if size of sparse is greater than zero:\n",
    "    \n",
    "    if RXtwt.device != 'cpu' or bLinux == 1:\n",
    "        temp = bksparse['Wtcsr_scaled'] @ Rty\n",
    "    else:    \n",
    "        temp = f_sparse_coo_mv(bksparse['Wtcoo_scaled'], Rty) \n",
    "\n",
    "    if bkdense['m'] == 0:\n",
    "        res = temp\n",
    "    else:    \n",
    "        res = torch.hstack(temp,  bkdense['Wtdense_scaled'] @ Rty )\n",
    "    \n",
    "    \n",
    "    return res  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def f_WqW(bks, qwts):\n",
    "\n",
    "    bkmisc = bks['misc']\n",
    "    bksparse = bks['_Bsparse_scaled']\n",
    "    bkdense = bks['_Bdense_scaled']\n",
    "    \n",
    "    dtype = bkmisc['RXt'].dtype\n",
    "    device = bkmisc['RXt'].device\n",
    "    \n",
    "    m = bkmisc['m'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "    n = bkmisc['n'].item()\n",
    "    RXtwt = bkmisc['RXtwt'] \n",
    "    RXwt = bkmisc['RXwt'] \n",
    "    p0wts = bkmisc['p0wts']\n",
    "    \n",
    "    mm10 = bksparse['mm10'].item()\n",
    "    mm11 =  bksparse['mm11'].item()\n",
    "    \n",
    "    mm20 = bksparse['mm20'].item()\n",
    "    mm21 =  bksparse['mm21'].item()\n",
    "    \n",
    "    mms0 = bksparse['mms0'].item()\n",
    "    mms1 =  bksparse['mms1'].item()\n",
    "    \n",
    "    mmd0 = bkdense['mmd0'].item()\n",
    "    mmd1 =  bkdense['mmd1'].item()\n",
    "\n",
    "    slice1 = slice(mm10, mm11)\n",
    "    slice2 = slice(mm20, mm21)\n",
    "    sliced = slice(mmd0, mmd1)\n",
    "    slices = slice(mms0, mms1)\n",
    "\n",
    "    #qwts = qwts.reshape(m,)\n",
    "\n",
    "    v1 = bksparse['WW1v_scaled'] * qwts[slice1]\n",
    "    v2 = bksparse['WW2v_scaled'] * qwts[slice2].reshape(-1, 1, 1)\n",
    "    v2 = v2.reshape((-1,))\n",
    "    vs = bksparse['WWsv_scaled'] * torch.index_select(qwts[slices], 0, bksparse['WWsr_scaled'])\n",
    "    tempd = bkdense['Wtdense_scaled'].t() @ bkdense['Wtdense_scaled']\n",
    "    \n",
    "    #i1 = bksparse['WW1i_scaled'][1]\n",
    "    #ij1 = torch.vstack([i1, i1])\n",
    "    #ij2 = torch.vstack([bksparse['WW2i_scaled'], bksparse['WW2it_scaled']])\n",
    "    #ijs = torch.vstack([bksparse['WWsi_scaled'], bksparse['WWsit_scaled']])\n",
    "\n",
    "    iii = bksparse['WWiii_scaled']\n",
    "    vvv = torch.hstack([v1, v2, vs])\n",
    "    temp = torch.sparse_coo_tensor(iii, vvv, size=[k,k]).to_dense()\n",
    "    #res = torch.vstack([res1, res2, ress]).to_dense()\n",
    "    temp += tempd\n",
    "        \n",
    "    temp2 = (p0wts.reshape(n, 1) * temp[:n, :] + RXwt @ temp[n:, :])\n",
    "\n",
    "    res = p0wts.reshape(1, n) * temp2[:,:n] + temp2[:, n:] @ RXtwt\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ftest_WAqWBt: outputs\n",
      "sizes: torch.Size([16]) torch.Size([16]) torch.Size([16]) torch.Size([16]) torch.Size([20])\n",
      "\n",
      "f:colsa=array([1, 2, 0, 1, 3, 2, 3, 4], dtype=int64)\n",
      "rowsa=array([ 0,  0,  2,  6,  6,  9, 10, 12], dtype=int64)\n",
      "va=array([10., 20., 30., 40., 50., 60., 70., 80.])\n",
      "colsb=array([2, 0, 1, 1, 5, 7], dtype=int64)\n",
      "rowsb=array([ 0,  2,  6,  7,  8, 10], dtype=int64)\n",
      "vb=array([11., 22., 33., 44., 55., 66.])\n",
      "\n",
      "f:resc=array([ 0,  0,  2,  6,  6, 10], dtype=int64)\n",
      "resca=array([1, 2, 0, 1, 3, 3], dtype=int64)\n",
      "rescb=array([2, 2, 0, 1, 1, 7], dtype=int64)\n",
      "resv=array([ 110.,  220.,  660., 1320., 1650., 4620.])\n",
      "g: (3586,) 0.0030035972595214844\n",
      "g: (3586,) 1.1299598217010498\n",
      "g: (3586,) 0.0\n",
      "g: (3586,) 0.0\n",
      "g: (3586,) 0.0\n"
     ]
    }
   ],
   "source": [
    "# Function to set up gram matrix calculation WqW:\n",
    "# Function takes inputs to coo matrix constructor as inputs.\n",
    "\n",
    "#@numba.njit # Not necessary since numba.jit.script(fWAqWBt_setup) called later\n",
    "def fBs_setup(rowsa, colsa, va, rowsb, colsb, vb):\n",
    "    \"\"\"\n",
    "    This function operates on numpy arrays so that numba.jit can be used on it!\n",
    "    \n",
    "    Function to precalulate values for W @ q @ Q using inputs of arbitrary coo matrix.\n",
    "    \n",
    "    Inputs are row indices rowsa, column indices colsa, values va of what will be sparse coo matrix WA;\n",
    "    row indices rowsb, column indices colsb, values vb of what will be sparse coo matrix WB.\n",
    "\n",
    "    Returns elements of sparse coo matrix needed to help calculate WAt @ q @ WB, where q is a diagonal matrix.\n",
    "    This setup has row indices r, column WA indices colsa, column WB indices colsb,\n",
    "    values with WA[r[n], colsa[n]] * WB[r[n], colsb[n]] .\n",
    "    For a column with ia matches in WA and ib matches in WB, the setup has ia * ib rows.\n",
    "\n",
    "    PYTORCH COO TENSORS ARE SORTED BY ROW WHEN COALESCED.  TO CALCULATE W * q * Wt,\n",
    "    THIS FUNCTION SHOULD BE CALLED ON THE COALESCED TRANSPOSE OF THE TORCH COO TENSOR:\n",
    "\n",
    "    Wt = W.t().coalesce()\n",
    "    rows = Wt.indices()[0].numpy()\n",
    "    cols = Wt.indices()[1].numpy()\n",
    "    values = Wt.values().numpy()\n",
    "    resr, resca, rescb, resv = fWAqWBt_setup(rows, cols, values, rows, cols, values)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert rowsa.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert va.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    assert rowsb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert vb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    # Calculate exact size of the array needed to hold the results:\n",
    "    bca = np.bincount(rowsa)\n",
    "    bcb = np.bincount(rowsb)\n",
    "    bcsize = min(bca.shape[0], bcb.shape[0])\n",
    "    nsize = (bca[0:bcsize] * bcb[0:bcsize]).sum()\n",
    "\n",
    "    resr = np.empty((nsize,), dtype=np.int64)\n",
    "    resca = np.empty((nsize,), dtype=np.int64)\n",
    "    rescb = np.empty((nsize,), dtype=np.int64)\n",
    "    resv = np.empty((nsize,), dtype=np.float64)\n",
    "\n",
    "    sizea = colsa.shape[0]\n",
    "    sizeb = colsb.shape[0]\n",
    "\n",
    "    ia = 0\n",
    "    ib = 0\n",
    "    n = 0\n",
    "\n",
    "    while ia < sizea and ib < sizeb:\n",
    "        if rowsa[ia] < rowsb[ib]:\n",
    "            ia += 1\n",
    "            if rowsa[ia-1] > rowsa[ia]:\n",
    "                print(\"rowa should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue    \n",
    "        if rowsb[ib] < rowsa[ia]:        \n",
    "            ib += 1\n",
    "            if rowsb[ib-1] > rowsb[ib]:\n",
    "                print(\"rowb should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue\n",
    "        r = rowsa[ia]\n",
    "        iia = ia\n",
    "        while iia < sizea and rowsa[iia] == r:\n",
    "            iib = ib\n",
    "            while iib < sizeb and rowsb[iib] == r:\n",
    "                resr[n] = r\n",
    "                resca[n] = colsa[iia]\n",
    "                rescb[n] = colsb[iib]\n",
    "                resv[n] = va[iia] * vb[iib]\n",
    "                #print(f\"{iia=}, {iib=}, {ia=}, {ib=}, {n=}, {resr[n]=}, {resca[n]=}, {rescb[n]=}, {resv[n]=}\")\n",
    "                n += 1\n",
    "                iib += 1\n",
    "            iia += 1\n",
    "        ia = iia\n",
    "        ib = iib\n",
    "\n",
    "    return resr, resca, rescb, resv\n",
    "\n",
    "\n",
    "def fWAqWBt(r, ca, cb, v, size, q):\n",
    "    \"\"\"\n",
    "    This function takes torch tensors, which require conversion from the numpy arrays\n",
    "    which are output from setup function fWAqWBt_setup using numba.jit.  \n",
    "    TODO: NEED TO FIX THIS DESIGN ISSUE!\n",
    "    \n",
    "    Calculates matrix W @ q @ W where r indexes orders, ca indexes assets, cb indexes assets traspose,\n",
    "    v is values of product of values indexed by ca and cb, \n",
    "    size is shape of output (assets * assets n * n or registered portfolios by registered portfolios k * k),\n",
    "    q is a diagonal matrix.\n",
    "    \n",
    "    This is a homemade altorithm using index_select, then sparse_coo_tensor(...).to_dense().\n",
    "    The sparse_coo_tensor(...).to_dense() step is the bottleneck in the program.\n",
    "    \n",
    "    GPU memory is likely to be another bottleneck \n",
    "    if there are many random orders for portfolios containing many assets or registered portfolios.\n",
    "    \"\"\"\n",
    "    \n",
    "    vals = v * torch.index_select(q, 0, r)\n",
    "    ii = torch.vstack([ca, cb])\n",
    "    \n",
    "    res = torch.sparse_coo_tensor( ii, vals, size=size, \n",
    "                                  dtype=vals.dtype, device=vals.device ).to_dense()\n",
    "    return res\n",
    "\n",
    "def ftest_WAqWBt():\n",
    "    \n",
    "    n = 5\n",
    "    m = 20\n",
    "    nnz = 10\n",
    "\n",
    "    dtype = torch.float64\n",
    "    device = 'cpu'\n",
    "\n",
    "    ri = torch.randint(0, n, [nnz], dtype=torch.int64, device=device)\n",
    "    ci = torch.randint(0, m, [nnz], dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([ri, ci])\n",
    "    v = torch.randn([nnz], dtype=dtype, device=device)\n",
    "    A1coo = torch.sparse_coo_tensor(ii, v, size=(n, m), dtype=dtype, device=device)\n",
    "    \n",
    "    A1coot = A1coo.t().coalesce()\n",
    "    rti = A1coot.indices()[0].clone().detach()\n",
    "    cti = A1coot.indices()[1].clone().detach()\n",
    "    vt = A1coot.values().clone().detach()\n",
    "    \n",
    "    q = torch.randn((m,), dtype=dtype, device=device)\n",
    "    \n",
    "    r, ca, cb, v = fBs_setup(rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy(), \n",
    "                                 rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy())\n",
    "    \n",
    "    r = torch.tensor(r, device=device, dtype=torch.int64)\n",
    "    ca = torch.tensor(ca, device=device, dtype=torch.int64)\n",
    "    cb = torch.tensor(cb, device=device, dtype=torch.int64)\n",
    "    v = torch.tensor(v, device=device, dtype=dtype)\n",
    "\n",
    "    print(\"\\nftest_WAqWBt: outputs\")\n",
    "    print(\"sizes:\", r.size(), ca.size(), cb.size(), v.size(), q.size())\n",
    "    \n",
    "    res = fWAqWBt(r, ca, cb, v, (n,n), q)\n",
    "\n",
    "    return res\n",
    "    \n",
    "ftest_WAqWBt()\n",
    "    \n",
    "    \n",
    "\n",
    "def ftest(fWAqWBt_setup):\n",
    "\n",
    "    rowsa = np.array([0, 0, 2, 6, 6, 9, 10, 12], dtype=np.int64)\n",
    "    colsa = np.array([1, 2, 0, 1, 3, 2,  3,  4], dtype=np.int64)\n",
    "    va = np.array([10.00, 20.00, 30.00, 40.00, 50.00, 60.00, 70.00, 80.00], dtype=np.float64)\n",
    "\n",
    "    rowsb = np.array([0, 2, 6, 7, 8, 10], dtype=np.int64)\n",
    "    colsb = np.array([2, 0, 1, 1, 5, 7], dtype=np.int64)\n",
    "    vb = np.array([11.00, 22.00, 33.00, 44.00, 55.00, 66.00], dtype=np.float64)\n",
    "\n",
    "    resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsb, colsb, vb)\n",
    "\n",
    "    print(f\"\\nf:{colsa=}\\n{rowsa=}\\n{va=}\\n{colsb=}\\n{rowsb=}\\n{vb=}\")\n",
    "    print(f\"\\nf:{resc=}\\n{resca=}\\n{rescb=}\\n{resv=}\")\n",
    "\n",
    "    n = 10\n",
    "    m = 20\n",
    "    nnz = 15\n",
    "\n",
    "    for i in range(1000):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        rowsa = rng.integers(0, m, size=nnz)\n",
    "        colsa = rng.integers(0, n, size=nnz)\n",
    "        va = rng.standard_normal((nnz,))\n",
    "\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    \n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "def gtest(fWAqWBt_setup):\n",
    "\n",
    "    n = 50\n",
    "    m = 200\n",
    "    assets_per_order = 2\n",
    "\n",
    "    sizea = m * assets_per_order\n",
    "    sizeb = m * assets_per_order\n",
    "\n",
    "    rng = np.random.default_rng(12345)\n",
    "\n",
    "    rowsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    rowsa.sort()\n",
    "    colsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    va = rng.standard_normal(size=sizea)\n",
    "\n",
    "    rowsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    rowsb.sort()\n",
    "    colsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    vb = rng.standard_normal(size=sizeb)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(1):\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(\"g:\", resc.shape, dt)\n",
    "\n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "#resc, resca, rescb, resv = f()\n",
    "\n",
    "#fjtest = numba.njit(f)\n",
    "\n",
    "fBs_setup_jit = numba.njit(fBs_setup)\n",
    "\n",
    "ftest(fBs_setup)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "\n",
    "gtest(fBs_setup)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "\n",
    "\n",
    "#%timeit g(fBs_setup)\n",
    "#%timeit g(fBs_setup_jit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 0.37632036209106445 0.26979565620422363 6.877102375030518\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "def f_initialize_all_bks(bk, options):\n",
    "    #dtype = options['dtype']\n",
    "    #device = options['device']\n",
    "    #b_solve_dollars = options['b_solve_dollars']\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    f_initialize_misc_(bk, options)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    f_initialize_bks_from_dfs_(bk, options)\n",
    "    torch.cuda.synchronize()\n",
    "    t2 = time.time()\n",
    "    f_initialize_bks_scaled_for_qp_(bk, options)\n",
    "    torch.cuda.synchronize()\n",
    "    t3 = time.time()\n",
    "\n",
    "    print(\"times:\", t1 - t0, t2 - t1, t3 - t2)\n",
    "    \n",
    "    \n",
    "    #print(type(bk.bks), bk.bks.keys())\n",
    "    #for B in bk.bks:\n",
    "    #    print(\"\\n\", B)\n",
    "    #    for kk in bk.bks[B]:\n",
    "    #            print(kk, end=\", \")\n",
    "            \n",
    "    \n",
    "def f_initialize_all_bks_test():    \n",
    "    bk = OrderBook(Assumptions())\n",
    "    options = {'bk_sparsity' : {'A0' : 1, 'A0s' : 1, 'B1' : 1, 'B2' : 2, 'Bs' : 9, 'Bd' : 99},\n",
    "               'dtype' : torch.float64, 'device' : 'cuda', 'b_solve_dollars' : True}\n",
    "    f_initialize_all_bks(bk, options)\n",
    "    print(\"success\")\n",
    "\n",
    "f_initialize_all_bks_test()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fB1_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initializes the dictionary of orders B1 by adding to the dictionary indices B1['WW1i'] and values B1['WW1v'] \n",
    "    with squares of values in B1['Wcoo'']. This can be used to facilitate calculation of \n",
    "    fWW1(B1['W'], qwts) = B1['W'] @ z @ B1['W'].t(), where z is a diagonal matric.\n",
    "    \n",
    "    Usage: fB1_initialize(B1). Returns None, but changes B1.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = bk.df_single_asset\n",
    "\n",
    "    bkmisc = bk.bks['misc']\n",
    "    RXt = bkmisc['RXt']\n",
    "    p0 = bkmisc['p0']\n",
    "    n = bkmisc['n'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "    \n",
    "    m = df['n'].to_numpy().shape[0]\n",
    "    r = torch.tensor(range(df['n'].to_numpy().shape[0]), dtype=torch.int64, device=device)\n",
    "    c = torch.tensor(df['n'].to_numpy(), dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([r, c])\n",
    "    v = torch.tensor(df['w'].to_numpy(), dtype=dtype, device=device)\n",
    "\n",
    "    Wtcoo = torch.sparse_coo_tensor(ii, v, (m,k))\n",
    "    \n",
    "    B1 = {'is_sparse' : torch.tensor(1, dtype=torch.int64, device='cpu')}\n",
    "    B1['ph'] = torch.tensor(df['ph'].to_numpy(), dtype=dtype, device=device) \n",
    "    B1['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'].to_numpy(), dtype=dtype, device=device)            \n",
    "    B1['q'] = torch.tensor(df['q'].to_numpy(), dtype=dtype, device=device)\n",
    "    B1['Wtcoo'] = Wtcoo.coalesce()\n",
    "\n",
    "    if b_solve_dollars == True:\n",
    "        \n",
    "        print(\"B1---solve_dollars == True\")\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = B1['Wtcoo'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=torch.int64, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        B1['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, B1['Wtcoo']).coalesce()\n",
    "        B1['ph_scaled'] = B1['ph'] * Wnorminv\n",
    "        B1['ph_minus_pl_scaled'] = B1['ph_minus_pl'] * Wnorminv\n",
    "        B1['q_scaled'] = B1['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        B1['Wtcoo_scaled'] = B1['Wtcoo'].coalesce()\n",
    "        B1['ph_scaled'] = B1['ph']\n",
    "        B1['ph_minus_pl_scaled'] = B1['ph_minus_pl']\n",
    "        B1['q_scaled'] = B1['q']\n",
    "        \n",
    "    \n",
    "    B1['Wcoo_scaled'] = B1['Wtcoo_scaled'].t().coalesce()\n",
    "    B1['Wtcsr_scaled'] = B1['Wtcoo_scaled'].to_sparse_csr()\n",
    "    B1['Wcsr_scaled'] = B1['Wcoo_scaled'].to_sparse_csr() \n",
    "    \n",
    "    B1['WW1i_scaled'] = B1['Wtcoo_scaled'].indices()  # rows over m, cols over k\n",
    "    B1['WW1v_scaled'] = B1['Wtcoo_scaled'].values() * B1['Wtcoo_scaled'].values()\n",
    "    \n",
    "    bk.B1 = B1\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fWW1(B1 : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"_scaled\n",
    "    For_scaled orders in B1, which contain exactly one asset or registered portfolio per order,\n",
    "    this function calculates Wt @ z @ W from precalculated torch inputs_scaled.\n",
    "    \n",
    "    The first step multiplies the precalculated product values B1['WW1v'] by z.\n",
    "    Of the choice of three algorithms, the third (direct multiplication) is the fastest;\n",
    "    it is about 2X faster than the other two choices, which take about the same time.\n",
    "    \n",
    "    The second step sparse_coo_tensor(...).to_dense() places the calculated product values in the correct\n",
    "    rows and columns of the result matrix, which is n x n or k x k.  \n",
    "    The second step is the program bottleneck; it takes 5X-10X more time than the first step.\n",
    "    \"\"\"\n",
    "    \n",
    "    r = B1['WW1i_scaled'][0] # indices over m\n",
    "    c = B1['WW1i_scaled'][1] # indices over k\n",
    "    ii = torch.vstack([c, c])\n",
    "    k = B1['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    # The following two methods are equivalent. \n",
    "    # spares_coo_tensor(...).to_dens() is the big bottleneck, takes 5-10 times longer than vals = ....\n",
    "    # The csr and index_select optiosn take approximately the same time. The thrid option is twice as fast.\n",
    "    b_use_element_by_element = True\n",
    "    #b_use_csr_experimental = False\n",
    "    b_use_index_select = False\n",
    "    if b_use_element_by_element == True: #fastest\n",
    "        vals = B1['WW1v_scaled'] * z[B1['mm0']:B1['mm1']]  \n",
    "    #elif b_use_csr_experimental == True:\n",
    "    #    try:\n",
    "    #        vals = B1['WW1bigcsr'] @ z \n",
    "    #    except:\n",
    "    #        print(\"b_experimental_stuff == False, using index_select\")\n",
    "    #        vals = B1['WW1v'] * torch.index_select(z, 0, r)\n",
    "    elif b_use_index_select == True:\n",
    "        vals = B1['WW1v_scaled'] * torch.index_select(z, 0, r)\n",
    "    else:\n",
    "        assert False, \"Should not get here. Set b_use_element_by_element = True\"\n",
    "\n",
    "    #res = torch.sparse_coo_tensor(ii, vals, size=[k, k], \n",
    "    #                                dtype=vals.dtype, device=vals.device).to_den_scaledse()\n",
    "    res = torch.sparse_coo_tensor(ii, vals, size=[k, k], \n",
    "                                    dtype=vals.dtype, device=vals.device)\n",
    "\n",
    "    # This test shows that three methods give the same result if there is exactly one registered portfolio per order:\n",
    "    b_test_vals = False\n",
    "    if b_test_vals == True:\n",
    "        vals1 = B1['WW1bigcsr_scaled'] @ z \n",
    "        vals2 = B1['WW1v_scaled'] * torch.index_select(z, 0, r)\n",
    "        vals3 = B1['WW1v_scaled'] * z\n",
    "        print(\"vals1-2-3:\", vals1.sum().item(), vals2.sum().item(), vals3.sum().item())\n",
    "        assert torch.isclose(vals1, vals2).all(), \"vals1 != vals2\"\n",
    "        assert torch.isclose(vals1, vals3).all(), \"vals1 != vals3\"\n",
    "    \n",
    "    #torch.cuda.synchronize()\n",
    "    #print(\"B1['WW1v'] * torch.index_select(z, 0, r)\")\n",
    "    #%timeit -r 7 -n 10 vals = B1['WW1v'] * torch.index_select(z, 0, r); torch.cuda.synchronize()\n",
    "    \n",
    "    #print(\"B1['WW1bigcsr'] @ z:\")\n",
    "    #%timeit -r 7 -n 10 vals = B1['WW1bigcsr'] @ z; torch.cuda.synchroni_scaledze()_s_scaledcaled\n",
    "\n",
    "    #torch.cuda.synchronize()\n",
    "    #%timeit -r 7 -n 10  vals3 = B1['WW1v'] * z; torch.cuda.synchronize()\n",
    "    \n",
    "    #print(\"sparse_coo_tensor(...).to_dense()\")\n",
    "    #%timeit -r 7 -n 10 res = torch.sparse_coo_tensor(ii, vals, size=[k, k], dtype=vals.dtype, device=vals.device).to_dense(); torch.cuda.synchronize()\n",
    "    \n",
    "    #print(\"vals:\", vals)\n",
    "    #print(\"ii:\", ii)\n",
    "    #print(\"size:\", size)\n",
    "    \n",
    "    #indices2 = torch.vstack([c, c])\n",
    "    #res2 = torch.sparse_coo_tensor(indices2, vals).to_dense()\n",
    "\n",
    "    #print(\"B1['WW1bigcsr']: = \", B1['WW1bigcsr'].indices().max(dim=1))\n",
    "    #print(\"ii[0].max() should be mbig\", ii[0].max(), \", ii[1].max() should be k\", ii[1].max())\n",
    "    #print(\"vals.sum() should be same\", vals.sum().item(), vals2.sum().item())\n",
    "    #print(\"res and res2:\", res.sum().item(), res2.sum().item())\n",
    "    #print(\"vals = \", vals, \"vals2 = \", vals2)\n",
    "    \n",
    "    #assert torch.isclose(res, res2).all() == True, \"res != res2\"\n",
    "    \n",
    "    return res\n",
    "\n",
    "def ftestB1():\n",
    "    \n",
    "    bk = OrderBook(Assumptions())\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "    \n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    #f_initialize_torch_dictionaries_(bk, dtype, device)\n",
    "    fB1_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    B1 = bk.B1\n",
    "    \n",
    "    #for k in B1.keys():\n",
    "    #    printa(B1[k], k)\n",
    "    \n",
    "    m = B1['Wtcoo_scaled'].size()[0]\n",
    "    n = B1['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    B1['m'] = m # Changed when all initialized together\n",
    "    B1['mm0'] = 0 # Changed when all initialized together\n",
    "    B1['mm1'] = m # Changed when all initialized together\n",
    "    \n",
    "    print(\"m = \", m, \", n = \", n)\n",
    "    \n",
    "    y = torch.randn(n, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    \n",
    "    Wtcoo = B1['Wtcoo_scaled']\n",
    "    Wtcsr = B1['Wtcsr_scaled']\n",
    "    Wcoo = B1['Wcoo_scaled']\n",
    "    Wcsr = B1['Wcsr_scaled']\n",
    "    #Wcoo = Wtcoo.t().clone().detach()\n",
    "    #Wcsr = Wtcsr.t().clone().detach()\n",
    "    \n",
    "    print(\"coalesced???\", Wtcoo.is_coalesced(), Wtcoo.indices().size())\n",
    "    \n",
    "    resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "    resxcoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "\n",
    "    resxcoo = Wtcoo @ y\n",
    "    resxcoo = Wtcoo.t() @ x\n",
    "    resxcoo2 = Wcoo @ x\n",
    "\n",
    "    try:\n",
    "        resycsr = Wtcsr @ y\n",
    "        resxcsr = Wtcsr.t() @ x\n",
    "        resxcsr2 = Wcsr @ x\n",
    "    except:\n",
    "        print(\"sparse multiplication for csr not defined on cpu.\")\n",
    "    \n",
    "    Wtd = Wtcoo.to_dense()\n",
    "    Wd = Wtcoo.t().clone().detach()\n",
    "    \n",
    "    resyd = Wtd @ y\n",
    "    resxd = Wtd.t() @ x\n",
    "    resxd2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resycoo, resycsr).all()    \n",
    "    assert torch.isclose(resycoo, resyd).all()    \n",
    "\n",
    "    assert torch.isclose(resxcoo, resxcoo2).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr2).all()    \n",
    "    assert torch.isclose(resxcoo, resxd).all()    \n",
    "    assert torch.isclose(resxcoo, resxd2).all()    \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"fWW1(B1, x): Efficient but time consuming\")\n",
    "    %timeit -r 7 -n 10 fWW1(B1, x)\n",
    "    %timeit -r 7 -n 10 fWW1(B1, x)\n",
    "    %timeit -r 7 -n 10 fWW1(B1, x)\n",
    "\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wtcsr @ y Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y);  torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wcsr.t() @ y should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo @ y: Should be slow due to coo, not csr\")\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "   \n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wcsr @ x Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wtcsr.t() @ x should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo.t() @ x: should be slow due to coo and transpose\")\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "ftestB1()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fB2_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initializes the dictionary of orders B2 by adding to the dictionary indices B2['WW2i'] and values B2['WW2v'] \n",
    "    with squares of values in B2['Wcoo'']. This can be used to facilitate calculation of \n",
    "    fWW2(B2['W'], qwts) = B2['W'] @ z @ B2['W'].t(), where z is a diagonal matric.\n",
    "    \n",
    "    Usage: fB2_initialize(B2). Returns None, but changes bk.B2.\n",
    "    \"\"\"\n",
    "\n",
    "    df = bk.df_pairs_trade\n",
    "    bkmisc = bk.bks['misc']\n",
    "    p0 = bkmisc['p0']\n",
    "    RXt = bkmisc['RXt']\n",
    "    \n",
    "    # Assign indices for registered portfolios, over k\n",
    "    cb = torch.tensor(df['n_buy'], dtype=dtype, device=device)\n",
    "    cs = torch.tensor(df['n_sell'], dtype=dtype, device=device)\n",
    "    cbs = torch.hstack([cb, cs])\n",
    "    \n",
    "    ndim = 2\n",
    "    m = cb.size()[0]  \n",
    "    n = bkmisc['n']\n",
    "    k = bkmisc['k']\n",
    "    \n",
    "    # Assign order ids as a range over m:\n",
    "    #TODO: MIGHT CHANGE TO UNIQUE ORDER IDs FROM ORDER BOOK, BUT THIS WOULD MESS UP DENSE DIMENSIONS FOR ORDERS!\n",
    "    rb = torch.tensor(range(m), dtype=torch.float64, device=device)\n",
    "    rs = torch.tensor(range(m), dtype=torch.float64, device=device)\n",
    "    rbs = torch.hstack([rb, rs])\n",
    "    ii = torch.vstack([rbs, cbs])\n",
    "    \n",
    "    assert ii.size() == torch.Size([2, 2 * m])\n",
    "    \n",
    "    # Assign portfolio weights\n",
    "    vb = torch.tensor(df['w_buy'], dtype=dtype, device=device)\n",
    "    vs = torch.tensor(df['w_sell'], dtype=dtype, device=device)\n",
    "    v = torch.hstack([vb, vs])\n",
    "    \n",
    "    assert v.size() == torch.Size([2 * m])\n",
    "\n",
    "    Wtcoo = torch.sparse_coo_tensor(ii, v, (m, k))  # NOT COALESCED YET!\n",
    "    B2 = {'is_sparse' : torch.tensor(1, dtype=torch.int64, device='cpu')}\n",
    "\n",
    "    B2['ph'] = torch.tensor(df['ph'], dtype=dtype, device=device) \n",
    "    B2['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'], dtype=dtype, device=device)            \n",
    "    B2['q'] = torch.tensor(df['q'], dtype=dtype, device=device)\n",
    "    B2['Wtcoo'] = Wtcoo.coalesce()  # rows over m, cols over k, nnz = 2 * m\n",
    "    \n",
    "    if b_solve_dollars == True:\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = B2['Wtcoo'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        B2['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, B2['Wtcoo']).coalesce()\n",
    "        B2['ph_scaled'] = B2['ph'] * Wnorminv\n",
    "        B2['ph_minus_pl_scaled'] = B2['ph_minus_pl'] * Wnorminv\n",
    "        B2['q_scaled'] = B2['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        B2['Wtcoo_scaled'] = B2['Wtcoo'].coalesce()\n",
    "        B2['ph_scaled'] = B2['ph']\n",
    "        B2['ph_minus_pl_scaled'] = B2['ph_minus_pl']\n",
    "        B2['q_scaled'] = B2['q']\n",
    "        \n",
    "    \n",
    "    B2['Wcoo_scaled'] = B2['Wtcoo_scaled'].t().coalesce()\n",
    "    B2['Wtcsr_scaled'] = B2['Wtcoo_scaled'].to_sparse_csr()\n",
    "    B2['Wcsr_scaled'] = B2['Wcoo_scaled'].to_sparse_csr() \n",
    "    \n",
    "    #B2['WW1i_scaled'] = B2['Wtcoo_scaled'].indices()  # rows over m, cols over k\n",
    "    #B2['WW1v_scaled'] = B2['Wtcoo_scaled'].values() * B2['Wtcoo_scaled'].values()\n",
    "\n",
    "    ii = B2['Wtcoo_scaled'].indices().reshape(2, m, ndim, 1).broadcast_to(2, m, ndim, ndim)\n",
    "    iit = B2['Wtcoo_scaled'].indices().reshape(2, m, 1, ndim).broadcast_to(2, m, ndim, ndim)\n",
    "\n",
    "    assert ii.size() == torch.Size([2, m, ndim, ndim])\n",
    "    assert iit.size() == torch.Size([2, m, ndim, ndim])\n",
    "\n",
    "    # Check that order IDs are the same in ndim x ndim dimension:\n",
    "    assert (ii[0, :, :, :] == ii[0, :, 0:1, 0:1]).all(), \"PKError: Inconsistency in order IDs!\"\n",
    "\n",
    "    # Premultiply values to simplify repeated calculations of W @ q @ W later:\n",
    "    v = B2['Wtcoo_scaled'].values().reshape(m, ndim, 1).broadcast_to(m, ndim, ndim)\n",
    "    vt = B2['Wtcoo_scaled'].values().reshape(m, 1, ndim).broadcast_to(m, ndim, ndim)\n",
    "    vv = v * vt\n",
    "    \n",
    "    # Get indices of registered portfolios and transpose\n",
    "    B2['WW2i_scaled'] = ii[1]\n",
    "    B2['WW2it_scaled'] = iit[1]\n",
    "    B2['WW2v_scaled'] = vv\n",
    "    \n",
    "    assert B2['WW2i_scaled'].size() == torch.Size([m, ndim, ndim])\n",
    "    assert B2['WW2it_scaled'].size() == torch.Size([m, ndim, ndim])\n",
    "    assert B2['WW2v_scaled'].size() == torch.Size([m, ndim, ndim])\n",
    "\n",
    "    bk.B2 = B2\n",
    "    \n",
    "    return None\n",
    "\n",
    "#@torch.jit.script\n",
    "def fWW2(B2 : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"\n",
    "    For orders in B2, which contain exactly two assets or registered portfolios per order \n",
    "    (including pairs trades but also arbitrary positive and negative weights),\n",
    "    this function calculates Wt @ z @ W from precalculated torch inputs.\n",
    "    \n",
    "    The first step multiplies the precalculated product values B2['WW2v'] by z.\n",
    "    Of the choice of three algorithms, the third (direct multiplication) is the fastest;\n",
    "    it is about 2X faster than the other two choices, which take about the same time.\n",
    "    \n",
    "    The second step sparse_coo_tensor(...).to_dense() places the calculated product values in the correct\n",
    "    rows and columns of the result matrix, which is n x n or k x k.  \n",
    "    The second step is the program bottleneck; it takes 5X-10X more time than the first step.\n",
    "    \"\"\"\n",
    "    \n",
    "    m = B2['Wtcoo_scaled'].size()[0]\n",
    "    k = B2['Wtcoo_scaled'].size()[1]\n",
    "    ndim = 2\n",
    "    m_ndim_ndim = m * ndim * ndim\n",
    "\n",
    "    assert B2['Wtcoo_scaled'].indices().size() == torch.Size([2, ndim * m])\n",
    "    \n",
    "    r = B2['WW2i_scaled'] # size is [m, ndim, ndim], index over orders m\n",
    "    c = B2['WW2it_scaled'] # size is [m, ndim, ndim], index over registered portfolios k\n",
    "    ii = torch.vstack([r.reshape(m_ndim_ndim), c.reshape(m_ndim_ndim)])\n",
    "    vals = B2['WW2v_scaled'] * z[B2['mm0']:B2['mm1']].reshape(m, 1, 1)\n",
    "    vals = vals.reshape(m_ndim_ndim)\n",
    "    res = torch.sparse_coo_tensor(ii, vals, size=[k, k], \n",
    "                                    dtype=vals.dtype, device=vals.device)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def ftestB2():\n",
    "    \n",
    "    bk = OrderBook(Assumptions())\n",
    "    \n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "\n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    #f_initialize_torch_dictionaries_(bk, dtype, device)\n",
    "    fB2_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    B2 = bk.B2\n",
    "    \n",
    "    #for k in B2.keys():\n",
    "    #    printa(B2[k], k)\n",
    "    \n",
    "    m = B2['Wtcoo_scaled'].size()[0]\n",
    "    k = B2['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    B2['m'] = m # Changed when all initialized together\n",
    "    B2['mm0'] = 0 # Changed when all initialized together\n",
    "    B2['mm1'] = m # Changed when all initialized together\n",
    "\n",
    "    print(\"m = \", m, \", k = \", k)\n",
    "    \n",
    "    y = torch.randn(k, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    q = x * x\n",
    "    \n",
    "    Wtcoo = B2['Wtcoo_scaled']\n",
    "    Wtcsr = B2['Wtcsr_scaled']\n",
    "    Wcoo = B2['Wcoo_scaled']\n",
    "    Wcsr = B2['Wcsr_scaled']\n",
    "    \n",
    "    #print(\"coalesced???\", Wtcoo.is_coalesced(), Wcoo.indices().size())\n",
    "    \n",
    "    resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "    resxcoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "\n",
    "    resxcoo = Wtcoo @ y\n",
    "    resxcoo = Wtcoo.t() @ x\n",
    "    resxcoo2 = Wcoo @ x\n",
    "\n",
    "    try:\n",
    "        resycsr = Wtcsr @ y\n",
    "        resxcsr = Wtcsr.t() @ x\n",
    "        resxcsr2 = Wcsr @ x\n",
    "    except:\n",
    "        print(\"sparse multiplication for csr not defined on cpu.\")\n",
    "    \n",
    "    Wtd = Wtcoo.to_dense()\n",
    "    Wd = Wtcoo.t().clone().detach()\n",
    "    \n",
    "    resyd = Wtd @ y\n",
    "    resxd = Wtd.t() @ x\n",
    "    resxd2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resycoo, resycsr).all()    \n",
    "    assert torch.isclose(resycoo, resyd).all()    \n",
    "\n",
    "    #tmp = resxcoo - resxcoo2; print(tmp.min(), tmp.max())\n",
    "    \n",
    "    assert torch.isclose(resxcoo, resxcoo2).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr2).all()    \n",
    "    assert torch.isclose(resxcoo, resxd).all()    \n",
    "    assert torch.isclose(resxcoo, resxd2).all()    \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"fWW2(B2, x): Efficient but time consuming\")\n",
    "    %timeit -r 7 -n 10 res = fWW2(B2, q)\n",
    "    %timeit -r 7 -n 10 res = fWW2(B2, q)\n",
    "    %timeit -r 7 -n 10 res = fWW2(B2, q)\n",
    "\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wtcsr @ y Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y);  torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wcsr.t() @ y should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo @ y: Should be slow due to coo, not csr\")\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "   \n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wcsr @ x Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wtcsr.t() @ x should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo.t() @ x: should be slow due to coo and transpose\")\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "ftestB2()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to set up gram matrix calculation WqW:\n",
    "# Function takes inputs to coo matrix constructor as inputs.\n",
    "\n",
    "#@numba.njit # Not necessary since numba.jit.script(fWAqWBt_setup) called later\n",
    "def fBs_setup(rowsa, colsa, va, rowsb, colsb, vb):\n",
    "    \"\"\"\n",
    "    This function operates on numpy arrays so that numba.jit can be used on it!\n",
    "    \n",
    "    Function to precalulate values for W @ q @ Q using inputs of arbitrary coo matrix.\n",
    "    \n",
    "    Inputs are row indices rowsa, column indices colsa, values va of what will be sparse coo matrix WA;\n",
    "    row indices rowsb, column indices colsb, values vb of what will be sparse coo matrix WB.\n",
    "\n",
    "    Returns elements of sparse coo matrix needed to help calculate WAt @ q @ WB, where q is a diagonal matrix.\n",
    "    This setup has row indices r, column WA indices colsa, column WB indices colsb,\n",
    "    values with WA[r[n], colsa[n]] * WB[r[n], colsb[n]] .\n",
    "    For a column with ia matches in WA and ib matches in WB, the setup has ia * ib rows.\n",
    "\n",
    "    PYTORCH COO TENSORS ARE SORTED BY ROW WHEN COALESCED.  TO CALCULATE W * q * Wt,\n",
    "    THIS FUNCTION SHOULD BE CALLED ON THE COALESCED TRANSPOSE OF THE TORCH COO TENSOR:\n",
    "\n",
    "    Wt = W.t().coalesce()\n",
    "    rows = Wt.indices()[0].numpy()\n",
    "    cols = Wt.indices()[1].numpy()\n",
    "    values = Wt.values().numpy()\n",
    "    resr, resca, rescb, resv = fWAqWBt_setup(rows, cols, values, rows, cols, values)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert rowsa.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert va.shape == colsa.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    assert rowsb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "    assert vb.shape == colsb.shape, \"PKError: inconsistent dimensions\"\n",
    "\n",
    "    # Calculate exact size of the array needed to hold the results:\n",
    "    bca = np.bincount(rowsa)\n",
    "    bcb = np.bincount(rowsb)\n",
    "    bcsize = min(bca.shape[0], bcb.shape[0])\n",
    "    nsize = (bca[0:bcsize] * bcb[0:bcsize]).sum()\n",
    "\n",
    "    resr = np.empty((nsize,), dtype=np.int64)\n",
    "    resca = np.empty((nsize,), dtype=np.int64)\n",
    "    rescb = np.empty((nsize,), dtype=np.int64)\n",
    "    resv = np.empty((nsize,), dtype=np.float64)\n",
    "\n",
    "    sizea = colsa.shape[0]\n",
    "    sizeb = colsb.shape[0]\n",
    "\n",
    "    ia = 0\n",
    "    ib = 0\n",
    "    n = 0\n",
    "\n",
    "    while ia < sizea and ib < sizeb:\n",
    "        if rowsa[ia] < rowsb[ib]:\n",
    "            ia += 1\n",
    "            if rowsa[ia-1] > rowsa[ia]:\n",
    "                print(\"rowa should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue    \n",
    "        if rowsb[ib] < rowsa[ia]:        \n",
    "            ib += 1\n",
    "            if rowsb[ib-1] > rowsb[ib]:\n",
    "                print(\"rowb should be sorted. Coalesce sparse coo matrix first!\")\n",
    "            continue\n",
    "        r = rowsa[ia]\n",
    "        iia = ia\n",
    "        while iia < sizea and rowsa[iia] == r:\n",
    "            iib = ib\n",
    "            while iib < sizeb and rowsb[iib] == r:\n",
    "                resr[n] = r\n",
    "                resca[n] = colsa[iia]\n",
    "                rescb[n] = colsb[iib]\n",
    "                resv[n] = va[iia] * vb[iib]\n",
    "                #print(f\"{iia=}, {iib=}, {ia=}, {ib=}, {n=}, {resr[n]=}, {resca[n]=}, {rescb[n]=}, {resv[n]=}\")\n",
    "                n += 1\n",
    "                iib += 1\n",
    "            iia += 1\n",
    "        ia = iia\n",
    "        ib = iib\n",
    "\n",
    "    return resr, resca, rescb, resv\n",
    "\n",
    "\n",
    "def fWAqWBt(r, ca, cb, v, size, q):\n",
    "    \"\"\"\n",
    "    This function takes torch tensors, which require conversion from the numpy arrays\n",
    "    which are output from setup function fWAqWBt_setup using numba.jit.  \n",
    "    TODO: NEED TO FIX THIS DESIGN ISSUE!\n",
    "    \n",
    "    Calculates matrix W @ q @ W where r indexes orders, ca indexes assets, cb indexes assets traspose,\n",
    "    v is values of product of values indexed by ca and cb, \n",
    "    size is shape of output (assets * assets n * n or registered portfolios by registered portfolios k * k),\n",
    "    q is a diagonal matrix.\n",
    "    \n",
    "    This is a homemade altorithm using index_select, then sparse_coo_tensor(...).to_dense().\n",
    "    The sparse_coo_tensor(...).to_dense() step is the bottleneck in the program.\n",
    "    \n",
    "    GPU memory is likely to be another bottleneck \n",
    "    if there are many random orders for portfolios containing many assets or registered portfolios.\n",
    "    \"\"\"\n",
    "    \n",
    "    vals = v * torch.index_select(q, 0, r)\n",
    "    ii = torch.vstack([ca, cb])\n",
    "    \n",
    "    res = torch.sparse_coo_tensor( ii, vals, size=size, \n",
    "                                  dtype=vals.dtype, device=vals.device ).to_dense()\n",
    "    return res\n",
    "\n",
    "def ftest_WAqWBt():\n",
    "    \n",
    "    n = 5\n",
    "    m = 20\n",
    "    nnz = 10\n",
    "\n",
    "    dtype = torch.float64\n",
    "    device = 'cpu'\n",
    "\n",
    "    ri = torch.randint(0, n, [nnz], dtype=torch.int64, device=device)\n",
    "    ci = torch.randint(0, m, [nnz], dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([ri, ci])\n",
    "    v = torch.randn([nnz], dtype=dtype, device=device)\n",
    "    A1coo = torch.sparse_coo_tensor(ii, v, size=(n, m), dtype=dtype, device=device)\n",
    "    \n",
    "    A1coot = A1coo.t().coalesce()\n",
    "    rti = A1coot.indices()[0].clone().detach()\n",
    "    cti = A1coot.indices()[1].clone().detach()\n",
    "    vt = A1coot.values().clone().detach()\n",
    "    \n",
    "    q = torch.randn((m,), dtype=dtype, device=device)\n",
    "    \n",
    "    r, ca, cb, v = fBs_setup(rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy(), \n",
    "                                 rti.cpu().numpy(), cti.cpu().numpy(), vt.cpu().numpy())\n",
    "    \n",
    "    r = torch.tensor(r, device=device, dtype=torch.int64)\n",
    "    ca = torch.tensor(ca, device=device, dtype=torch.int64)\n",
    "    cb = torch.tensor(cb, device=device, dtype=torch.int64)\n",
    "    v = torch.tensor(v, device=device, dtype=dtype)\n",
    "\n",
    "    print(\"\\nftest_WAqWBt: outputs\")\n",
    "    print(\"sizes:\", r.size(), ca.size(), cb.size(), v.size(), q.size())\n",
    "    \n",
    "    res = fWAqWBt(r, ca, cb, v, (n,n), q)\n",
    "\n",
    "    return res\n",
    "    \n",
    "ftest_WAqWBt()\n",
    "    \n",
    "    \n",
    "\n",
    "def ftest(fWAqWBt_setup):\n",
    "\n",
    "    rowsa = np.array([0, 0, 2, 6, 6, 9, 10, 12], dtype=np.int64)\n",
    "    colsa = np.array([1, 2, 0, 1, 3, 2,  3,  4], dtype=np.int64)\n",
    "    va = np.array([10.00, 20.00, 30.00, 40.00, 50.00, 60.00, 70.00, 80.00], dtype=np.float64)\n",
    "\n",
    "    rowsb = np.array([0, 2, 6, 7, 8, 10], dtype=np.int64)\n",
    "    colsb = np.array([2, 0, 1, 1, 5, 7], dtype=np.int64)\n",
    "    vb = np.array([11.00, 22.00, 33.00, 44.00, 55.00, 66.00], dtype=np.float64)\n",
    "\n",
    "    resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsb, colsb, vb)\n",
    "\n",
    "    print(f\"\\nf:{colsa=}\\n{rowsa=}\\n{va=}\\n{colsb=}\\n{rowsb=}\\n{vb=}\")\n",
    "    print(f\"\\nf:{resc=}\\n{resca=}\\n{rescb=}\\n{resv=}\")\n",
    "\n",
    "    n = 10\n",
    "    m = 20\n",
    "    nnz = 15\n",
    "\n",
    "    for i in range(1000):\n",
    "        rng = np.random.default_rng(1234)\n",
    "        rowsa = rng.integers(0, m, size=nnz)\n",
    "        colsa = rng.integers(0, n, size=nnz)\n",
    "        va = rng.standard_normal((nnz,))\n",
    "\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    \n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "def gtest(fWAqWBt_setup):\n",
    "\n",
    "    n = 500\n",
    "    m = 20000\n",
    "    assets_per_order = 2\n",
    "\n",
    "    sizea = m * assets_per_order\n",
    "    sizeb = m * assets_per_order\n",
    "\n",
    "    rng = np.random.default_rng(12345)\n",
    "\n",
    "    rowsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    rowsa.sort()\n",
    "    colsa = rng.integers(low=0, high=n, size=sizea)\n",
    "    va = rng.standard_normal(size=sizea)\n",
    "\n",
    "    rowsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    rowsb.sort()\n",
    "    colsb = rng.integers(low=0, high=n, size=sizeb)\n",
    "    vb = rng.standard_normal(size=sizeb)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(1):\n",
    "        resc, resca, rescb, resv = fWAqWBt_setup(rowsa, colsa, va, rowsa, colsa, va)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(\"g:\", resc.shape, dt)\n",
    "\n",
    "    #return resc, resca, rescb, resv\n",
    "\n",
    "#resc, resca, rescb, resv = f()\n",
    "\n",
    "#fjtest = numba.njit(f)\n",
    "\n",
    "fBs_setup_jit = numba.njit(fBs_setup)\n",
    "\n",
    "ftest(fBs_setup)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "#fjtest(fBs_setup_jit)\n",
    "\n",
    "gtest(fBs_setup)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "gtest(fBs_setup_jit)\n",
    "\n",
    "\n",
    "#%timeit g(fBs_setup)\n",
    "#%timeit g(fBs_setup_jit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fBs_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initializes the dictionary of orders Bs by adding to the dictionary indices Bs['WWi'] and values Bs['WWv'] \n",
    "    with squares of values in bk.Bs['Wtcoo'']. This can be used to facilitate calculation of \n",
    "    fWWs(Bs['W'], qwts) = Bs['W'] @ qwts @ Bs['W'].t(), where qwts is a diagonal matric.\n",
    "\n",
    "    bk.Bs['Wtcoo'] contains orders with small (sparse) but different numbers of registered portfolios.\n",
    "\n",
    "    Usage: fBs_initialize_(bk). Returns None, but changes bk.Bs.\n",
    "    \n",
    "    The setup function fBs_setup(...) runs on the cpu so that numba.jit can be used to juggle indices.\n",
    "    \"\"\"\n",
    "\n",
    "    df = bk.df_sparse\n",
    "    bkmisc = bk.bks['misc']\n",
    "    p0 = bkmisc['p0']\n",
    "    RXt = bkmisc['RXt']\n",
    "    \n",
    "    n = bkmisc['n'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "\n",
    "    #BsWtcoo = bk.BsWtcoo # Get sparse weights from order book as numpy array converted to scipy coo\n",
    "    BsWtcoo_scipy = df[pd.RangeIndex(k)].sparse.to_coo()  \n",
    "    m = BsWtcoo_scipy.shape[0]  \n",
    "    assert k == BsWtcoo_scipy.shape[1]\n",
    "    rows = BsWtcoo_scipy.row\n",
    "    cols = BsWtcoo_scipy.col\n",
    "    rowscols = np.vstack([rows, cols])\n",
    "    values = BsWtcoo_scipy.data\n",
    "    \n",
    "    Bs = {'is_sparse' : torch.tensor(1, dtype=torch.int64, device='cpu')}\n",
    "    # rows over m, cols over k, nnz = 2 * m\n",
    "    Bs['Wtcoo'] = torch.sparse_coo_tensor(rowscols, values, (m, k), dtype=dtype, device=device).coalesce()  \n",
    "    Bs['ph'] = torch.tensor(df['ph'], dtype=dtype, device=device)\n",
    "    Bs['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'], dtype=dtype, device=device)\n",
    "    Bs['q'] = torch.tensor(df['q'], dtype=dtype, device=device)\n",
    "\n",
    "    if b_solve_dollars == True:\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = Bs['Wtcoo'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        Bs['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, Bs['Wtcoo']).coalesce()\n",
    "        Bs['ph_scaled'] = Bs['ph'] * Wnorminv\n",
    "        Bs['ph_minus_pl_scaled'] = Bs['ph_minus_pl'] * Wnorminv\n",
    "        Bs['q_scaled'] = Bs['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        Bs['Wtcoo_scaled'] = Bs['Wtcoo'].coalesce()\n",
    "        Bs['ph_scaled'] = Bs['ph']\n",
    "        Bs['ph_minus_pl_scaled'] = Bs['ph_minus_pl']\n",
    "        Bs['q_scaled'] = Bs['q']\n",
    "    \n",
    "    Bs['Wcoo_scaled'] = Bs['Wtcoo_scaled'].t().coalesce()\n",
    "    Bs['Wtcsr_scaled'] = Bs['Wtcoo_scaled'].to_sparse_csr()\n",
    "    Bs['Wcsr_scaled'] = Bs['Wcoo_scaled'].to_sparse_csr() \n",
    "\n",
    "    # Set up helper arrays to facilitate calculation of AQA for Btcoo:\n",
    "    # The following function uses numpy arrays and numba.jit to juggle indices:\n",
    "\n",
    "    WWrows, WWcols, WWtcols, WWvals = fBs_setup(\n",
    "        Bs['Wtcoo_scaled'].indices()[0].cpu().numpy(), \n",
    "        Bs['Wtcoo_scaled'].indices()[1].cpu().numpy(), \n",
    "        Bs['Wtcoo_scaled'].values().cpu().numpy(), \n",
    "        Bs['Wtcoo_scaled'].indices()[0].cpu().numpy(), \n",
    "        Bs['Wtcoo_scaled'].indices()[1].cpu().numpy(), \n",
    "        Bs['Wtcoo_scaled'].values().cpu().numpy()) \n",
    "\n",
    "    Bs['WWr_scaled'] = torch.tensor(WWrows, dtype=torch.int64, device=device)  # indices for orders\n",
    "    Bs['WWi_scaled'] = torch.tensor(WWcols, dtype=torch.int64, device=device)  # indices for registered portfolios\n",
    "    Bs['WWit_scaled'] = torch.tensor(WWtcols, dtype=torch.int64, device=device) # transpose indices for registered portfolios\n",
    "    Bs['WWv_scaled'] = torch.tensor(WWvals, dtype=dtype, device=device)  # premultiplied products of weights\n",
    "\n",
    "    bk.Bs = Bs\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def fWWs(Bs : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"\n",
    "    Calculates matrix W @ z @ W, where Bs['WWr'] indexes orders, Bs['WWi'] indexes assets, \n",
    "    Bs['WWit'] indexes assets traspose, Bs['WWv'] is values of product of values indexed by Bs['WWi'] and Bs['WWit'], \n",
    "    size is shape of output (assets * assets n * n or registered portfolios by registered portfolios k * k),\n",
    "    z is a diagonal matrix (as vector).\n",
    "    \n",
    "    This is a homemade altorithm using index_select, then sparse_coo_tensor(...).to_dense().\n",
    "    The sparse_coo_tensor(...).to_dense() step is the bottleneck in the program.\n",
    "    \n",
    "    GPU memory is likely to be another bottleneck \n",
    "    if there are many random orders for portfolios containing many assets or registered portfolios.\n",
    "    \"\"\"\n",
    "\n",
    "    size = Bs['Wtcoo_scaled'].size() \n",
    "    m = size[0]\n",
    "    k = size[1]\n",
    "    \n",
    "    vals = Bs['WWv_scaled'] * torch.index_select(z, 0, Bs['WWr_scaled'])\n",
    "    ii = torch.vstack([Bs['WWi_scaled'], Bs['WWit_scaled']])\n",
    "    res = torch.sparse_coo_tensor( ii, vals, size=(k, k), \n",
    "                                  dtype=vals.dtype, device=vals.device )\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def ftestBs():\n",
    "    \n",
    "    #bk = OrderBook(Assumptions())\n",
    "    bk = OrderBook(Assumptions(**{'Bs_M' : 100, 'Bs_Rmin' : 3, 'Bs_Rmax' : 6}))\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "\n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=False)\n",
    "    fBs_initialize_(bk, dtype, device, b_solve_dollars=False)\n",
    "    \n",
    "    Bs = bk.Bs\n",
    "    \n",
    "    m = Bs['Wtcoo'].size()[0]\n",
    "    k = Bs['Wtcoo'].size()[1]\n",
    "\n",
    "    Bs['m'] = m # Changed when all initialized together\n",
    "    Bs['mm0'] = 0 # Changed when all initialized together\n",
    "    Bs['mm1'] = m # Changed when all initialized together\n",
    "\n",
    "    print(\"m = \", m, \", k = \", k)\n",
    "    \n",
    "    y = torch.randn(k, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    q = x * x\n",
    "    \n",
    "    Wtcoo = Bs['Wtcoo_scaled']\n",
    "    \n",
    "    print(\"Bs['Wtcoo_scaled'].dtype = \", Bs['Wtcoo_scaled'].dtype, \n",
    "          \", Bs['Wtcoo_scaled'].device = \", Bs['Wtcoo_scaled'].device)\n",
    "    \n",
    "    Wtcsr = Bs['Wtcsr_scaled']\n",
    "    Wcoo = Bs['Wcoo_scaled']\n",
    "    Wcsr = Bs['Wcsr_scaled']\n",
    "    \n",
    "    resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "    resxcoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "\n",
    "    resxcoo = Wtcoo @ y\n",
    "    resxcoo = Wtcoo.t() @ x\n",
    "    resxcoo2 = Wcoo @ x\n",
    "\n",
    "    try:\n",
    "        resycsr = Wtcsr @ y\n",
    "        resxcsr = Wtcsr.t() @ x\n",
    "        resxcsr2 = Wcsr @ x\n",
    "    except:\n",
    "        print(\"sparse multiplication for csr not defined on cpu, using f_sparse_mv_for_cpu_and_cuda.\")\n",
    "        resycsr = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "        resxcsr = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "        resxcsr2 = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x)\n",
    "        \n",
    "    Wtd = Wtcoo.to_dense()\n",
    "    Wd = Wtcoo.t().clone().detach()\n",
    "    \n",
    "    resyd = Wtd @ y\n",
    "    resxd = Wtd.t() @ x\n",
    "    resxd2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resycoo, resycsr, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resycoo, resyd, rtol=1e-4, atol=1e-5).all()    \n",
    "\n",
    "    assert torch.isclose(resxcoo, resxcoo2, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr2, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resxcoo, resxd, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resxcoo, resxd2, rtol=1e-4, atol=1e-5).all()    \n",
    "    \n",
    "    i = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "    j = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "    ij = torch.vstack([i, j])\n",
    "    qcoo = torch.sparse_coo_tensor(ij, q, (m, m))\n",
    "    qcsr = qcoo.to_sparse_csr()\n",
    "\n",
    "    res1 = fWWs(Bs, q)\n",
    "    res2 = (Wcoo @ qcoo) @ Wtcoo \n",
    "    res3 = (Wcsr @ qcsr) @ Wtcsr \n",
    "    #res4d = torch.empty((k, k), dtype=dtype, device=device)\n",
    "    #torch.mm((Wcsr @ qcsr), Wtcsr, out=res4d)\n",
    "\n",
    "    print(res2.is_coalesced())\n",
    "\n",
    "    \n",
    "    res1d = res1.to_dense()\n",
    "    res2d = res2.to_dense()\n",
    "    res3d = res3.to_dense()\n",
    "\n",
    "    print(\"Should be same : \", res1d.sum().item(), res2d.sum().item(), res3d.sum().item())\n",
    "    \n",
    "    assert torch.isclose(res1d, res2d).all()\n",
    "    assert torch.isclose(res1d, res3d).all()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\nfWWs(Bs, x): Efficient but time consuming bottleneck due to torch.sparse_coo_tensor(...).to_dense()\")\n",
    "    %timeit -r 7 -n 10 res = fWWs(Bs, q); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = fWWs(Bs, q); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = fWWs(Bs, q); torch.cuda.synchronize()\n",
    "\n",
    "    print(\"FWWs: direct with coo torch.mm()\")\n",
    "    torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcoo @ qcoo) @ Wtcoo; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcoo @ qcoo) @ Wtcoo; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcoo @ qcoo) @ Wtcoo; torch.cuda.synchronize()\n",
    "\n",
    "    print(\"FWWs: direct with csr torch.mm()\")\n",
    "    torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcsr @ qcsr) @ Wtcsr; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcsr @ qcsr) @ Wtcsr; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = (Wcsr @ qcsr) @ Wtcsr; torch.cuda.synchronize()\n",
    "\n",
    "    print(\"FWWx: direct with csr torch.mm() to dense\")\n",
    "    torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcsr @ qcsr) @ Wtcsr).to_dense(); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcsr @ qcsr) @ Wtcsr).to_dense(); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcsr @ qcsr) @ Wtcsr).to_dense(); torch.cuda.synchronize()\n",
    "\n",
    "    print(\"FWWx: direct with coo torch.mm() to dense\")\n",
    "    torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcoo @ qcoo) @ Wtcoo).to_dense(); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcoo @ qcoo) @ Wtcoo).to_dense(); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = ((Wcoo @ qcoo) @ Wtcoo).to_dense(); torch.cuda.synchronize()\n",
    "\n",
    "    \n",
    "    try:\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"\\ncsr: Wtcsr @ y Should be fastest\")\n",
    "        %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    except:\n",
    "        print(\"Not defined on cpu\")\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y);  torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "\n",
    "    try:\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"csr: Wcsr.t() @ y should be slow due to transpose\")\n",
    "        %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    except:\n",
    "        print(\"Not defined on cpu.\")\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo @ y: Should be slow due to coo, not csr\")\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"\\ncsr: Wcsr @ x Should be fastest\")\n",
    "        %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    except:\n",
    "        print(\"Not defined on cpu.\")\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "\n",
    "    try:\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"csr: Wtcsr.t() @ x should be slow due to transpose\")\n",
    "        %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "        %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    except:\n",
    "        print(\"Not defined on cpu.\")\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo.t() @ x: should be slow due to coo and transpose\")\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "ftestBs()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fBd_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initialize dense orders.\n",
    "    \n",
    "    Precalculations do not help since their purpose was to facilitate sparse gram matrix calculations.\n",
    "    Here the gram matrix is dense.\n",
    "\n",
    "    bk.Bd['Wtcoo'] contains orders with large numbers of registered portfolios.\n",
    "\n",
    "    Usage: fBd_initialize_(bk). Returns None, but changes bk.Bd.\n",
    "    \"\"\"\n",
    "\n",
    "    df = bk.df_dense\n",
    "    \n",
    "    bkmisc = bk.bks['misc']\n",
    "    p0 = bkmisc['p0']\n",
    "    RXt = bkmisc['RXt']\n",
    "    \n",
    "    n = bkmisc['n'].item()\n",
    "    k = bkmisc['k'].item()\n",
    "    \n",
    "    BdWt = bk.df_dense[range(k)].to_numpy()\n",
    "    \n",
    "    m = BdWt.shape[0]  \n",
    "    assert k == BdWt.shape[1]\n",
    "    \n",
    "    Bd = {'is_sparse' : torch.tensor(0, dtype=torch.int64, device='cpu')}\n",
    "    Bd['ph'] = torch.tensor(df['ph'], dtype=dtype, device=device) \n",
    "    Bd['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'], dtype=dtype, device=device)            \n",
    "    Bd['q'] = torch.tensor(df['q'], dtype=dtype, device=device)\n",
    "    # rows over m, cols over k, nnz = 2 * m:\n",
    "    Bd['Wtdense'] = torch.tensor(BdWt, dtype=dtype, device=device)  \n",
    "\n",
    "    if b_solve_dollars == True:\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = Bd['Wtdense'].abs().mv(torch.hstack([p0, RXt.mv(p0)]))\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        Bd['Wtdense_scaled'] = torch.mm(Wnorminv_diagmat, Bd['Wtdense'])\n",
    "        Bd['ph_scaled'] = Bd['ph'] * Wnorminv\n",
    "        Bd['ph_minus_pl_scaled'] = Bd['ph_minus_pl'] * Wnorminv\n",
    "        Bd['q_scaled'] = Bd['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        Bd['Wtdense_scaled'] = Bd['Wtdense']\n",
    "        Bd['ph_scaled'] = Bd['ph']\n",
    "        Bd['ph_minus_pl_scaled'] = Bd['ph_minus_pl']\n",
    "        Bd['q_scaled'] = Bd['q']\n",
    "    \n",
    "    Bd['Wdense_scaled'] = Bd['Wtdense_scaled'].t().clone().detach()\n",
    "\n",
    "    bk.Bd = Bd\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def fWWd(Bd : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"\n",
    "    Calculates matrix Bd['Wtdense'] @ z @ Bd['Wdense'],\n",
    "    where z is of size m and output size is k x k.\n",
    "    \n",
    "    Computation time is likely to be a bottleneck.\n",
    "    \n",
    "    GPU memory is likely to be another bottleneck \n",
    "    if there are many random orders for portfolios containing many assets or registered portfolios.\n",
    "    \"\"\"\n",
    "\n",
    "    Wtdense_scaled = Bd['Wtdense_scaled']\n",
    "    \n",
    "    m = Wtdense_scaled.size()[0]\n",
    "    #k = Wtdense_scaled.size()[1]\n",
    "\n",
    "    res = (Wtdense_scaled * z.reshape(m, 1)) @ Wtdense_scaled.t()\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def ftestBd():\n",
    "    \n",
    "    #bk = OrderBook(Assumptions())\n",
    "    bk = OrderBook(Assumptions(**{'Bd_M' : 75, 'Bd_Rmin' : 50, 'Bd_Rmax' : 300}))\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "\n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    fBd_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "\n",
    "    Bd = bk.Bd\n",
    "    \n",
    "    m = Bd['Wtdense_scaled'].size()[0]\n",
    "    k = Bd['Wtdense_scaled'].size()[1]\n",
    "\n",
    "    Bd['m'] = m # Changed when all initialized together\n",
    "    Bd['mm0'] = 0 # Changed when all initialized together\n",
    "    Bd['mm1'] = m # Changed when all initialized together\n",
    "\n",
    "    print(\"m = \", m, \", k = \", k)\n",
    "    \n",
    "    y = torch.randn(k, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    q = x * x\n",
    "    \n",
    "    Wtd = Bd['Wtdense_scaled']\n",
    "    Wd = Wtd.t().clone().detach()\n",
    "    \n",
    "    print(\"Bd['Wtdense_scaled'].dtype = \", Bd['Wdense_scaled'].dtype, \n",
    "          \", Bd['Wtdense_scaled'].device = \", Bd['Wtdense_scaled'].device)\n",
    "\n",
    "    resy = Wtd @ y\n",
    "    resx = Wtd.t() @ x\n",
    "    resy2 = Wd.t() @ y\n",
    "    resx2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resy, resy2, rtol=1e-4, atol=1e-5).all()    \n",
    "    assert torch.isclose(resx, resx2, rtol=1e-4, atol=1e-5).all()    \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\nfWWd(Bd, x): Expensive dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 res = fWWd(Bd, q); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = fWWd(Bd, q); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 res = fWWd(Bd, q); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Wtd.t() @ x: \")\n",
    "    %timeit -r 7 -n 10 resy = Wtd.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd.t() @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Wd @ x: \")\n",
    "    %timeit -r 7 -n 10 resy = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\nWtd @ y: \")\n",
    "    %timeit -r 7 -n 10 resy = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wtd @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Wd.t() @ y: \")\n",
    "    %timeit -r 7 -n 10 resy = Wd.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resy = Wd.t() @ y; torch.cuda.synchronize()\n",
    "\n",
    "ftestBd()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fA0_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initializes the dictionary of orders A0 by adding to the dictionary indices A0['WW0i'] and values A0['WW0v'] \n",
    "    with squares of values in A0['Wcoo'']. This can be used to facilitate calculation of \n",
    "    fWW0(A0['W'], qwts) = A0['W'] @ z @ A0['W'].t(), where z is a diagonal matric.\n",
    "    \n",
    "    Usage: fA0_initialize(A0). Returns None, but changes A0.\n",
    "    \"\"\"\n",
    "\n",
    "    df = bk.df_exchange\n",
    "    bkmisc = bk.bks['misc']\n",
    "    p0 = bkmisc['p0']\n",
    "    n = bkmisc['n'].item()\n",
    "    #k = bkmisc['k'].item()\n",
    "    \n",
    "    #m = bk.n0.shape[0]\n",
    "    c = torch.tensor(df['n'].to_numpy(), dtype=torch.int64, device=device)\n",
    "    m = c.size()[0]\n",
    "    r = torch.tensor(range(c.size()[0]), dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([r, c])\n",
    "    v = torch.tensor(df['w'].to_numpy(), dtype=dtype, device=device)\n",
    "\n",
    "    Wtcoo = torch.sparse_coo_tensor(ii, v, (m, n))\n",
    "    \n",
    "    A0 = {'is_sparse' : torch.tensor(1, dtype=torch.int64, device='cpu')}\n",
    "    A0['ph'] = torch.tensor(df['ph'].to_numpy(), dtype=dtype, device=device) \n",
    "    A0['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'].to_numpy(), dtype=dtype, device=device)            \n",
    "    A0['q'] = torch.tensor(df['q'].to_numpy(), dtype=dtype, device=device)\n",
    "    A0['Wtcoo'] = Wtcoo.coalesce()\n",
    "\n",
    "    if b_solve_dollars == True:\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = A0['Wtcoo'].abs().mv(p0)\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        A0['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, A0['Wtcoo']).coalesce()\n",
    "        A0['ph_scaled'] = A0['ph'] * Wnorminv\n",
    "        A0['ph_minus_pl_scaled'] = A0['ph_minus_pl'] * Wnorminv\n",
    "        A0['q_scaled'] = A0['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        A0['Wtcoo_scaled'] = A0['Wtcoo'].coalesce()\n",
    "        A0['ph_scaled'] = A0['ph']\n",
    "        A0['ph_minus_pl_scaled'] = A0['ph_minus_pl']\n",
    "        A0['q_scaled'] = A0['q']\n",
    "    \n",
    "    A0['Wcoo_scaled'] = A0['Wtcoo_scaled'].t().coalesce()\n",
    "    A0['Wtcsr_scaled'] = A0['Wtcoo_scaled'].to_sparse_csr()\n",
    "    A0['Wcsr_scaled'] = A0['Wcoo_scaled'].to_sparse_csr() \n",
    "\n",
    "    A0['WW0i_scaled'] = A0['Wtcoo_scaled'].indices()  # rows over m, cols over n\n",
    "    A0['WW0v_scaled'] = A0['Wtcoo_scaled'].values() * A0['Wtcoo_scaled'].values()\n",
    "    \n",
    "    bk.A0 = A0\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fWW0(A0 : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"\n",
    "    For orders in A0, which contain exactly one asset or registered portfolio per order,\n",
    "    this function calculates Wt @ z @ W from precalculated torch inputs.\n",
    "    \n",
    "    The first step multiplies the precalculated product values A0['WW0v'] by z.\n",
    "    Of the choice of three algorithms, the third (direct multiplication) is the fastest;\n",
    "    it is about 2X faster than the other two choices, which take about the same time.\n",
    "    \n",
    "    The second step sparse_coo_tensor(...).to_dense() places the calculated product values in the correct\n",
    "    rows and columns of the result matrix, which is n x n or k x k.  \n",
    "    The second step is the program bottleneck; it takes 5X-10X more time than the first step.\n",
    "    \"\"\"\n",
    "    \n",
    "    r = A0['WW0i_scaled'][0] # indices over m\n",
    "    c = A0['WW0i_scaled'][1] # indices over k\n",
    "    ii = torch.vstack([c, c])\n",
    "    k = A0['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    # The following two methods are equivalent. \n",
    "    # spares_coo_tensor(...).to_dense() is the big bottleneck, takes 5-10 times longer than vals = ....\n",
    "    # sparse_coo_tensor.to_dense() is now consolidate into fWqW()\n",
    "    # The csr and index_select optiosn take approximately the same time. The thrid option is twice as fast.\n",
    "    b_use_element_by_element = True\n",
    "    if b_use_element_by_element == True: #fastest\n",
    "        vals = A0['WW0v_scaled'] * z[A0['mm0']:A0['mm1']]  \n",
    "    else:\n",
    "        vals = A0['WW0v_scaled'] * torch.index_select(z, 0, r)\n",
    "\n",
    "    res = torch.sparse_coo_tensor(ii, vals, size=[k, k], \n",
    "                                    dtype=vals.dtype, device=vals.device)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def ftestA0():\n",
    "    \n",
    "    bk = OrderBook(Assumptions())\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "    \n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    fA0_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    A0 = bk.A0\n",
    "    \n",
    "    m = A0['Wtcoo_scaled'].size()[0]\n",
    "    n = A0['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    A0['m'] = m # Changed when all initialized together\n",
    "    A0['mm0'] = 0 # Changed when all initialized together\n",
    "    A0['mm1'] = m # Changed when all initialized together\n",
    "\n",
    "    print(\"m = \", m, \", n = \", n)\n",
    "    \n",
    "    y = torch.randn(n, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    \n",
    "    Wtcoo = A0['Wtcoo_scaled']\n",
    "    Wtcsr = A0['Wtcsr_scaled']\n",
    "    Wcoo = A0['Wcoo_scaled']\n",
    "    Wcsr = A0['Wcsr_scaled']\n",
    "    #Wcoo = Wtcoo.t().clone().detach()\n",
    "    #Wcsr = Wtcsr.t().clone().detach()\n",
    "    \n",
    "    print(\"coalesced???\", Wtcoo.is_coalesced(), Wtcoo.indices().size())\n",
    "    \n",
    "    resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "    resxcoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "\n",
    "    resxcoo = Wtcoo @ y\n",
    "    resxcoo = Wtcoo.t() @ x\n",
    "    resxcoo2 = Wcoo @ x\n",
    "\n",
    "    try:\n",
    "        resycsr = Wtcsr @ y\n",
    "        resxcsr = Wtcsr.t() @ x\n",
    "        resxcsr2 = Wcsr @ x\n",
    "    except:\n",
    "        print(\"sparse multiplication for csr not defined on cpu.\")\n",
    "    \n",
    "    Wtd = Wtcoo.to_dense()\n",
    "    Wd = Wtcoo.t().clone().detach()\n",
    "    \n",
    "    resyd = Wtd @ y\n",
    "    resxd = Wtd.t() @ x\n",
    "    resxd2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resycoo, resycsr).all()    \n",
    "    assert torch.isclose(resycoo, resyd).all()    \n",
    "\n",
    "    assert torch.isclose(resxcoo, resxcoo2).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr2).all()    \n",
    "    assert torch.isclose(resxcoo, resxd).all()    \n",
    "    assert torch.isclose(resxcoo, resxd2).all()    \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"fWW0(A0, x): Efficient but time consuming\")\n",
    "    %timeit -r 7 -n 10 fWW0(A0, x)\n",
    "    %timeit -r 7 -n 10 fWW0(A0, x)\n",
    "    %timeit -r 7 -n 10 fWW0(A0, x)\n",
    "\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wtcsr @ y Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y);  torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wcsr.t() @ y should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo @ y: Should be slow due to coo, not csr\")\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "   \n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wcsr @ x Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wtcsr.t() @ x should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo.t() @ x: should be slow due to coo and transpose\")\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "ftestA0()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fA0s_initialize_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Initializes the dictionary of orders A0s by adding to the dictionary indices A0s['WW0si'] and values A0s['WW0sv'] \n",
    "    with squares of values in A0s['Wcoo'']. This can be used to facilitate calculation of \n",
    "    fWW0s(A0s['W'], qwts) = A0s['W'] @ z @ A0s['W'].t(), where z is a diagonal matric.\n",
    "    \n",
    "    Usage: fA0s_initialize(A0s). Returns None, but changes A0s.\n",
    "    \"\"\"\n",
    "\n",
    "    df = bk.df_stabilizing\n",
    "    bkmisc = bk.bks['misc']\n",
    "    p0 = bkmisc['p0']\n",
    "    n = bkmisc['n'].item()\n",
    "    #k = bkmisc['k'].item()\n",
    "    \n",
    "    c = torch.tensor(df['n'], dtype=torch.int64, device=device)\n",
    "    m = c.size()[0]\n",
    "    r = torch.tensor(range(m), dtype=torch.int64, device=device)\n",
    "    ii = torch.vstack([r, c])\n",
    "    v = torch.tensor(df['w'], dtype=dtype, device=device)\n",
    "\n",
    "    Wtcoo = torch.sparse_coo_tensor(ii, v, (m, n))\n",
    "    \n",
    "    A0s = {'is_sparse' : torch.tensor(1, dtype=torch.int64, device='cpu')}\n",
    "    A0s['ph'] = torch.tensor(df['ph'], dtype=dtype, device=device) \n",
    "    A0s['ph_minus_pl'] = torch.tensor(df['ph_minus_pl_dollars'], dtype=dtype, device=device)            \n",
    "    A0s['q'] = torch.tensor(df['q'], dtype=dtype, device=device)\n",
    "    A0s['Wtcoo'] = Wtcoo.coalesce()\n",
    "    \n",
    "    if b_solve_dollars == True:\n",
    "\n",
    "        # If b_solve_dollars == True, then Wnorm is gross long-short dollars.\n",
    "        Wnorm = A0s['Wtcoo'].abs().mv(p0)\n",
    "        Wnorminv = 1.00 / Wnorm\n",
    "        r = torch.tensor(range(m), dtype=dtype, device=device)\n",
    "        indices = torch.vstack([r, r])\n",
    "        Wnorminv_diagmat = torch.sparse_coo_tensor(indices, Wnorminv, dtype=dtype, device=device)\n",
    "        A0s['Wtcoo_scaled'] = torch.mm(Wnorminv_diagmat, A0s['Wtcoo']).coalesce()\n",
    "        A0s['ph_scaled'] = A0s['ph'] * Wnorminv\n",
    "        A0s['ph_minus_pl_scaled'] = A0s['ph_minus_pl'] * Wnorminv\n",
    "        A0s['q_scaled'] = A0s['q'] * Wnorm\n",
    "    \n",
    "    else:\n",
    "        # If b_solve_dollars == False, then Wnorm should perhaps gross long-short shares but is instead unchanged.\n",
    "            \n",
    "        A0s['Wtcoo_scaled'] = A0s['Wtcoo'].coalesce()\n",
    "        A0s['ph_scaled'] = A0s['ph']\n",
    "        A0s['ph_minus_pl_scaled'] = A0s['ph_minus_pl']\n",
    "        A0s['q_scaled'] = A0s['q']\n",
    "    \n",
    "    A0s['Wcoo_scaled'] = A0s['Wtcoo_scaled'].t().coalesce()\n",
    "    A0s['Wtcsr_scaled'] = A0s['Wtcoo_scaled'].to_sparse_csr()\n",
    "    A0s['Wcsr_scaled'] = A0s['Wcoo_scaled'].to_sparse_csr() \n",
    "    \n",
    "    A0s['WW0si_scaled'] = A0s['Wtcoo_scaled'].indices()  # rows over m, cols over n\n",
    "    A0s['WW0sv_scaled'] = A0s['Wtcoo_scaled'].values() * A0s['Wtcoo_scaled'].values()\n",
    "    \n",
    "    bk.A0s = A0s\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fWW0s(A0s : typing.Dict[str, torch.Tensor], z):\n",
    "    \"\"\"\n",
    "    For orders in A0s, which contain exactly one asset or registered portfolio per order,\n",
    "    this function calculates Wt @ z @ W from precalculated torch inputs.\n",
    "    \n",
    "    The first step multiplies the precalculated product values A0s['WW0sv'] by z.\n",
    "    Of the choice of three algorithms, the third (direct multiplication) is the fastest;\n",
    "    it is about 2X faster than the other two choices, which take about the same time.\n",
    "    \n",
    "    The second step sparse_coo_tensor(...).to_dense() places the calculated product values in the correct\n",
    "    rows and columns of the result matrix, which is n x n or k x k.  \n",
    "    The second step is the program bottleneck; it takes 5X-10X more time than the first step.\n",
    "    \"\"\"\n",
    "    \n",
    "    r = A0s['WW0si_scaled'][0] # indices over m\n",
    "    c = A0s['WW0si_scaled'][1] # indices over k\n",
    "    ii = torch.vstack([c, c])\n",
    "    k = A0s['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    # The following two methods are equivalent. \n",
    "    # sparse_coo_tensor(...).to_dense() is the big bottleneck, takes 5-10 times longer than vals = ....\n",
    "    # to_dense() now deferred to fWqW()\n",
    "    b_use_element_by_element = True\n",
    "    if b_use_element_by_element == True: #fastest\n",
    "        vals = A0s['WW0sv_scaled'] * z[A0s['mm0']:A0s['mm1']]  \n",
    "    else:\n",
    "        vals = A0s['WW0sv_scaled'] * torch.index_select(z, 0, r)\n",
    "\n",
    "    res = torch.sparse_coo_tensor(ii, vals, size=[k, k], \n",
    "                                    dtype=vals.dtype, device=vals.device)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def ftestA0s():\n",
    "    \n",
    "    bk = OrderBook(Assumptions())\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "    \n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    fA0s_initialize_(bk, dtype, device, b_solve_dollars=True)\n",
    "    A0s = bk.A0s\n",
    "    \n",
    "    m = A0s['Wtcoo_scaled'].size()[0]\n",
    "    n = A0s['Wtcoo_scaled'].size()[1]\n",
    "\n",
    "    A0s['m'] = m # Changed when all initialized together\n",
    "    A0s['mm0'] = 0 # Changed when all initialized together\n",
    "    A0s['mm1'] = m # Changed when all initialized together\n",
    "\n",
    "    print(\"m = \", m, \", n = \", n)\n",
    "    \n",
    "    y = torch.randn(n, device=device, dtype=dtype)\n",
    "    x = torch.randn(m, device=device, dtype=dtype)\n",
    "    \n",
    "    Wtcoo = A0s['Wtcoo_scaled']\n",
    "    Wtcsr = A0s['Wtcsr_scaled']\n",
    "    Wcoo = A0s['Wcoo_scaled']\n",
    "    Wcsr = A0s['Wcsr_scaled']\n",
    "    \n",
    "    print(\"coalesced???\", Wtcoo.is_coalesced(), Wtcoo.indices().size())\n",
    "    \n",
    "    resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y)\n",
    "    resxcoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr.t(), Wtcoo.t(), x)\n",
    "\n",
    "    resxcoo = Wtcoo @ y\n",
    "    resxcoo = Wtcoo.t() @ x\n",
    "    resxcoo2 = Wcoo @ x\n",
    "\n",
    "    try:\n",
    "        resycsr = Wtcsr @ y\n",
    "        resxcsr = Wtcsr.t() @ x\n",
    "        resxcsr2 = Wcsr @ x\n",
    "    except:\n",
    "        print(\"sparse multiplication for csr not defined on cpu.\")\n",
    "    \n",
    "    Wtd = Wtcoo.to_dense()\n",
    "    Wd = Wtcoo.t().clone().detach()\n",
    "    \n",
    "    resyd = Wtd @ y\n",
    "    resxd = Wtd.t() @ x\n",
    "    resxd2 = Wd @ x\n",
    "        \n",
    "    assert torch.isclose(resycoo, resycsr).all()    \n",
    "    assert torch.isclose(resycoo, resyd).all()    \n",
    "\n",
    "    assert torch.isclose(resxcoo, resxcoo2).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr).all()    \n",
    "    assert torch.isclose(resxcoo, resxcsr2).all()    \n",
    "    assert torch.isclose(resxcoo, resxd).all()    \n",
    "    assert torch.isclose(resxcoo, resxd2).all()    \n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"fWW0s(A0s, x): Efficient but time consuming\")\n",
    "    %timeit -r 7 -n 10 fWW0s(A0s, x)\n",
    "    %timeit -r 7 -n 10 fWW0s(A0s, x)\n",
    "    %timeit -r 7 -n 10 fWW0s(A0s, x)\n",
    "\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wtcsr @ y Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wtcsr @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y);  torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = f_sparse_mv_for_cpu_and_cuda(Wtcsr, Wtcoo, y); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wcsr.t() @ y should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wcsr.t() @ y; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo @ y: Should be slow due to coo, not csr\")\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycoo = Wtcoo @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo2 = Wcoo @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resyd = Wtd @ y; torch.cuda.synchronize()\n",
    "   \n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"\\ncsr: Wcsr @ x Should be fastest\")\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resycsr = Wcsr @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x): These are almost fastest:\")\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = f_sparse_mv_for_cpu_and_cuda(Wcsr, Wcoo, x); torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"csr: Wtcsr.t() @ x should be slow due to transpose\")\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcsr = Wtcsr.t() @ x; torch.cuda.synchronize()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"coo: Wtcoo.t() @ x: should be slow due to coo and transpose\")\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxcoo = Wtcoo.t() @ x; torch.cuda.synchronize()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"dense: Should be very slow since dense matrix multiply\")\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "    %timeit -r 7 -n 10 resxd2 = Wd @ x; torch.cuda.synchronize()\n",
    "\n",
    "ftestA0s()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def f_initialize_torch_dictionaries_(bk, dtype, device, b_solve_dollars):\n",
    "    \"\"\"\n",
    "    Instead of one big order book, create multiple smaller order books, as follows:\n",
    "    Dictionaries of orders for  registered portfolios (individual assets and index portfolios):\n",
    "    B1 = orders for one registered portfolio\n",
    "    B2 = orders for two registered portfolios\n",
    "    B3 = orders for three registered portfolios\n",
    "    Bs = orders for sparse (few) registered portfolios\n",
    "    Bd = orders for dense (many) registered portfolios\n",
    "    Dictionaries of orders for individual assets:\n",
    "    Aexch = exchange orders for individual assets\n",
    "    Astab = stabilizing orders for individual assets\n",
    "    As = orders for sparse (few) individual assets\n",
    "    Ad = orders for dense (many) individual assets\n",
    "\n",
    "    Each dictionary, such as BR2, contains inverse depth vector BR2['dvec'], \n",
    "    upper limit price BR2['ph'], difference between upper and lower limit prices BR2['ph_minus_pl'], \n",
    "    maximum number of portfolio units BR2['q'], zero quantity of portfolio units BR2['qzero']. \n",
    "    In addition, each dictionary contains a matrix of portfolio weights, \n",
    "    with different names for different types of dictionaries of orders\n",
    "    and different sizes depending on number of orders, assets, or registered portfolios.\n",
    "    Names use notation\n",
    "    BR1['W1tcoo'], BR2['W2tcoo'], BR3['W3tcoo'], BRs['Wstcoo'], BRd['Wdtcoo'],\n",
    "    BAexch['W1tcoo'], BAstab['W1tcoo'], BAs['Wstcoo'], BAd['Wdtcoo'].\n",
    "    The 't' in names like 'W2tcoo' means transpose. \n",
    "    Let n denote number of individual assets and k = n + kx denote number of registered portfolios,\n",
    "    and m prefix denote number of orders.\n",
    "    Sizes use notation like mbr1 x k for Ba1, mbaexch x n for BAexch.\n",
    "    Untransposed sizes would be k x mbr1, n x mbaexch.\n",
    "\n",
    "    NB: Converting orders to pytorch tensors may not generate an audit trail,\n",
    "    in the sense that it may not be easy to match specific orders back to the order book.\n",
    "    The connection is made through prices: Quantities executed are determined by market-clearing prices.\n",
    "    \"\"\"\n",
    "\n",
    "    # r = rows denotes index of m orders, c = columns denotes registered portfolio for that order.\n",
    "    # Dimensions are mbr1 x k because W1tcoo is the transpose of W in the paper.\n",
    "\n",
    "    dtypeint = torch.int64\n",
    "    #deviceint = device\n",
    "    deviceint = 'cpu'\n",
    "\n",
    "    fmisc_initialize_(bk, dtype, device, b_solve_dollars)    \n",
    "    \n",
    "    fA0_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    fA0s_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    #fAs_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    #fAd_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    \n",
    "    fB1_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    fB2_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    #fB3_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    fBs_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    fBd_initialize_(bk, dtype, device, b_solve_dollars)\n",
    "    \n",
    "    # THE ORDER OF THE DICTIONARY MUST CORRESPOND WITH THE OLD ORDER IN THE ORDER BOOK TO TEST BOTH TOGETHER,\n",
    "    # THE ORDER BOOK STACKS ORDER IN A SPECIFIC MANNER.\n",
    "    bk.bks.update( {'A0' : bk.A0, 'A0s' : bk.A0s, 'B1' : bk.B1, 'B2' : bk.B2, 'Bs' : bk.Bs, 'Bd' : bk.Bd} )\n",
    "\n",
    "    mm = 0\n",
    "    for _k in bk.bks:\n",
    "        if _k != 'misc':\n",
    "            bk.bks[_k]['mm0'] = torch.tensor(mm, dtype=dtypeint, device=deviceint)\n",
    "            if bk.bks[_k]['is_sparse'] == 1:\n",
    "                m = bk.bks[_k]['Wtcoo'].size()[0]\n",
    "            else:\n",
    "                m = bk.bks[_k]['Wtdense'].size()[0]\n",
    "            mm += m\n",
    "            bk.bks[_k]['m'] = torch.tensor(m, dtype=dtypeint, device=deviceint)\n",
    "            bk.bks[_k]['mm1'] = torch.tensor(mm, dtype=dtypeint, device=deviceint)\n",
    "    mm = torch.tensor(mm, dtype=dtypeint, device=deviceint)        \n",
    "\n",
    "    bk.bks['misc']['m'] = mm  # Total number of orders in all order books.\n",
    "\n",
    "    #bk.bks['misc'] = bk.misc\n",
    "    \n",
    "    #for kk in bk.bks:\n",
    "    #    print(kk)\n",
    "    #    for kkk in bk.bks[kk]:\n",
    "    #        print(kkk, bk.bks[kk][kkk].size(), bk.bks[kk][kkk].device, bk.bks[kk][kkk].dtype)\n",
    "    \n",
    "    \n",
    "def f_initialize_torch_dictionaries_test():\n",
    "    bk = OrderBook(Assumptions())\n",
    "    dtype = torch.float64\n",
    "    device = 'cuda'\n",
    "    f_initialize_torch_dictionaries_(bk, dtype, device, b_solve_dollars=True)\n",
    "    #print(dir(bk))\n",
    "    for kk in bk.bks:\n",
    "        print(kk, bk.bks[kk].keys())\n",
    "    \n",
    "    for k in ['m', 'n', 'kx', 'k']:\n",
    "        print(\":::\", k, bk.bks['misc'][k], end=\", \")\n",
    "    print(\"\")\n",
    "    for k in bk.bks:\n",
    "        if k != 'misc':\n",
    "            print(k, bk.bks[k]['m'].item(), bk.bks[k]['mm0'].item(), bk.bks[k]['mm1'].item())\n",
    "            \n",
    "    \n",
    "f_initialize_torch_dictionaries_test()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWx(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], x, bLinux=0):\n",
    "    \"\"\"\n",
    "    Matrix-vector product to aggregate weights for several order books.\n",
    "\n",
    "    The algorithm needs if-statement since mv-product not defined for csr matrics on cpu.\n",
    "\n",
    "    The algorithm uses PK's mv-product for coo matrices f_sparse_coo_mv on cpu \n",
    "    since it is faster than Pytorch's algorithm (why???).\n",
    "    \n",
    "    The algorithm loops over two types of order books. Order books B* are for registered portfolios. \n",
    "    Order books A* are for individual assets only.\n",
    "\n",
    "    If the order books B1, B2, Bs, Bd, A0, A0s, etc. change, the algorithm adjusts to only use order books\n",
    "    which are actuall in the dictionary bks.\n",
    "    \n",
    "    This makes it easy to investigate what happens if various order books are included or deleted.\n",
    "    \"\"\"\n",
    "\n",
    "    bkmisc = bks['misc']\n",
    "    RXwt = bkmisc['RXwt'] \n",
    "    p0wts = bkmisc['p0wts']\n",
    "    \n",
    "    #print(\"RX.dtype xyz\", RX.dtype)\n",
    "    \n",
    "    m = int(bkmisc['m'].item())\n",
    "    n = int(bkmisc['n'].item())\n",
    "    k = int(bkmisc['k'].item())\n",
    "    \n",
    "    Bx = torch.zeros(k, dtype=RXwt.dtype, device=RXwt.device)\n",
    "    Ax = torch.zeros(n, dtype=RXwt.dtype, device=RXwt.device)\n",
    "\n",
    "    if RXwt.device != 'cpu' or bLinux != 0:\n",
    "        for _k in bks:\n",
    "            bkk = bks[_k]\n",
    "            if _k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                mslice = slice(bkk['mm0'].item(), bkk['mm1'].item())\n",
    "                if bkk['is_sparse'].item() == 1: \n",
    "                    Bx += bkk['Wcsr_scaled'] @ x[mslice]\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    Bx += bkk['Wdense_scaled'] @ x[mslice]\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "            elif _k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                mslice = slice(bkk['mm0'].item(), bkk['mm1'].item())\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    Ax += bkk['Wcsr_scaled'] @ x[mslice]\n",
    "                elif bkk['is_sparse'].item() == 1:\n",
    "                    Ax += bkk['Wdense_scaled'] @ x[mslice]\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "    \n",
    "    #if RX.device == torch.device('cpu') and bLinux == 0: \n",
    "    else:\n",
    "        for _k in bks:\n",
    "            bkk = bks[_k]\n",
    "            if _k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                mslice = slice(bkk['mm0'].item(), bkk['mm1'].item())\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    Bx += f_sparse_coo_mv(bkk['Wcoo_scaled'], x[mslice])\n",
    "                elif bkk['is_sparse'].item() == 0:    \n",
    "                    Bx += bkk['Wdense_scaled'] @ x[mslice]\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "            elif _k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                mslice = slice(bkk['mm0'].item(), bkk['mm1'].item())\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    Ax += f_sparse_coo_mv(bkk['Wcoo_scaled'], x[mslice])\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    Ax += bks[_k]['Wdense_scaled'] @ x[mslice]\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "\n",
    "    Ax = p0wts * Ax                \n",
    "    Ax += p0wts * Bx[:n] + RXwt @ Bx[n:]            \n",
    "\n",
    "    return Ax                       \n",
    "                           \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWty_sliced(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], y, bLinux=0):\n",
    "    \n",
    "    #TODO: MORE EFFICIENT TO USE SLICES!\n",
    "\n",
    "    bkmisc = bks['misc']\n",
    "    RXtwt = bkmisc['RXtwt']\n",
    "    p0wts = bkmisc['p0wts']\n",
    "    m = int(bkmisc['m'].item())\n",
    "    \n",
    "    pty = p0wts * y\n",
    "    Rty = torch.hstack([pty,  RXtwt @ y])\n",
    "    \n",
    "    res = torch.empty([m], dtype=RXtwt.dtype, device=RXtwt.device)  # Need to initialize in all branches\n",
    "            \n",
    "    if RXtwt.device != 'cpu' or bLinux == 1:\n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtcsr_scaled'] @ Rty \n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtdense_scaled'] @ Rty \n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                \n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtcsr_scaled'] @ pty \n",
    "                elif bkk['is_sparse'].item() == 1:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtdense_scaled'] @ pty \n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "    \n",
    "    else:    \n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtcoo_scaled'] @ Rty \n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtdense_scaled'] @ Rty \n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtcoo_scaled'] @ pty \n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    res[bkk['mm0']:bkk['mm1']] = bkk['Wtdense_scaled'] @ pty \n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                           \n",
    "    return res  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWty(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], y, bLinux=0):\n",
    "    \n",
    "    #TODO: MORE EFFICIENT TO USE SLICES OR STACKING?  Testing says stacking is faster for dense tensors.\n",
    "    \n",
    "    RXtwt = bks['misc']['RXtwt']\n",
    "    p0wts = bks['misc']['p0wts']\n",
    "    \n",
    "    pty = p0wts * y\n",
    "    Rty = torch.hstack([pty,  RXtwt @ y])\n",
    "    \n",
    "    temps = []\n",
    "    #temp = torch.empty([1], dtype=RXt.dtype, device=RXt.device)  # Need to initialize in all branches\n",
    "            \n",
    "    if RXtwt.device != 'cpu' or bLinux == 1:\n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtcsr_scaled'] @ Rty )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ Rty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)    \n",
    "                \n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtcsr_scaled'] @ pty )\n",
    "                elif bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ pty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "    \n",
    "    else:    \n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( f_sparse_coo_mv(bkk['Wtcoo_scaled'], Rty) )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ Rty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( f_sparse_coo_mv(bkk['Wtcoo_scaled'], pty) )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ pty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "    \n",
    "    #print(\"temps\")\n",
    "    #for _x in temps:\n",
    "    #    print(_x.size())\n",
    "    \n",
    "    Wty = torch.hstack(temps)\n",
    "                           \n",
    "    return Wty  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWty_OLD(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], y, bLinux=0):\n",
    "    \n",
    "    #TODO: MORE EFFICIENT TO USE SLICES OR STACKING?  Testing says stacking is faster for dense tensors.\n",
    "    \n",
    "    RXtwt = bks['misc']['RXtwt']\n",
    "    p0wts = bks['misc']['p0wts']\n",
    "    \n",
    "    pty = p0wts * y\n",
    "    Rty = torch.hstack([pty,  RXtwt @ y])\n",
    "    \n",
    "    temps = []\n",
    "    #temp = torch.empty([1], dtype=RXt.dtype, device=RXt.device)  # Need to initialize in all branches\n",
    "            \n",
    "    if RXtwt.device != 'cpu' or bLinux == 1:\n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtcsr_scaled'] @ Rty )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ Rty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)    \n",
    "                \n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtcoo_scaled'] @ pty )\n",
    "                elif bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ pty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "    \n",
    "    else:    \n",
    "        for k in bks:\n",
    "            bkk = bks[k]\n",
    "            if k[0] == 'B' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( f_sparse_coo_mv(bkk['Wtcoo_scaled'], Rty) )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ Rty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "            elif k[0] == 'A' and bkk['m'].item() != 0:\n",
    "                if bkk['is_sparse'].item() == 1:\n",
    "                    temps.append( f_sparse_coo_mv(bkk['Wtcoo_scaled'], pty) )\n",
    "                elif bkk['is_sparse'].item() == 0:\n",
    "                    temps.append( bkk['Wtdense_scaled'] @ pty )\n",
    "                else:\n",
    "                    assert False, \"Should not get here!\"\n",
    "                #temps.append(temp)\n",
    "    \n",
    "    #print(\"temps\")\n",
    "    #for _x in temps:\n",
    "    #    print(_x.size())\n",
    "    \n",
    "    Wty = torch.hstack(temps)\n",
    "                           \n",
    "    return Wty  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWqW_bad_does_not_work(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], q):\n",
    "    \"\"\"\n",
    "    Build the input to the Cholesky decomposition.\n",
    "    \n",
    "    Rather than call to_dense on every component B1, B2, Bs, instead return uncoalesced coo tensors\n",
    "    and call to_dense() once for B1, B2, Bs in this function. Similar for A0 and A0s.\n",
    "    \n",
    "    Although addition of sparse coo tensor results in is_coalesced() == False, \n",
    "    the result actually seems to be coalesced, so addition is rather costly.\n",
    "    \n",
    "    Maybe more efficient to stack indices and values, then coalesce once.\n",
    "    \"\"\"\n",
    "    \n",
    "    p0wts = bks['misc']['p0wts']\n",
    "    p0wts_diagmat = bks['misc']['p0wts_diagmat']\n",
    "    RXwt =bks['misc']['RXwt']  # n x kx\n",
    "    RXtwt =bks['misc']['RXtwt'] # kx x n\n",
    "    kx = int(bks['misc']['kx'].item())\n",
    "    k = int(bks['misc']['k'].item())\n",
    "    #ki = int(k.item())\n",
    "    n = int(bks['misc']['n'].item())\n",
    "    \n",
    "    #temp = torch.zeros([k, k], dtype=RX.dtype, device=RX.device)\n",
    "    #tempB = torch.sparse_coo_tensor(size=[k, k], dtype=RXwt.dtype, device=RXwt.device)\n",
    "\n",
    "    temps = []\n",
    "    \n",
    "    if bks['B1']['m'].item() != 0:\n",
    "        temps.append( fWW1(bks['B1'], q) )\n",
    "        print(temps[-1].size())\n",
    "    if bks['B2']['m'].item() != 0:\n",
    "        temps.append( fWW2(bks['B2'], q) )\n",
    "        print(temps[-1].size())\n",
    "    if bks['Bs']['m'].item() != 0:\n",
    "        temps.append( fWWs(bks['Bs'], q) )\n",
    "        print(temps[-1].size())\n",
    "    if bks['A0']['m'].item() != 0:\n",
    "        temps.append( fWW0(bks['A0'], q).sparse_resize_((k, k), 2, 0 ) )\n",
    "        print(temps[-1].size())\n",
    "    if bks['A0s']['m'].item() != 0:\n",
    "        temps.append( fWW0s(bks['A0s'], q).sparse_resize_((k, k), 2, 0) )\n",
    "        print(temps[-1].size())\n",
    "\n",
    "    tempBd = torch.vstack(temps)\n",
    "        \n",
    "    tempBd = tempBd.to_dense()    \n",
    "        \n",
    "    if bks['Bd']['m'].item() != 0:\n",
    "        tempBd += fWWd(bks['Bd'], q)\n",
    "        \n",
    "    temp2 = (p0wts.reshape(n, 1) * tempBd[:n, :] + RXwt @ tempBd[n:, :])\n",
    "\n",
    "    res = p0wts.reshape(1, n) * temp2[:,:n] + temp2[:, n:] @ RXtwt\n",
    "\n",
    "    #tempA = torch.sparse_coo_tensor(size=[n, n], dtype=RXwt.dtype, device=RXwt.device)\n",
    "    \n",
    "    #if bks['A0']['m'].item() != 0:\n",
    "    #    tempA += fWW0(bks['A0'], q)\n",
    "    #if bks['A0s']['m'].item() != 0:\n",
    "    #    tempA += fWW0s(bks['A0s'], q)\n",
    "\n",
    "    #tempA = (p0wts_diagmat @ tempA) @ p0wts_diagmat   \n",
    "        \n",
    "    #tempA = tempA.to_dense()\n",
    "\n",
    "    #tempA = tempA * p0wts.reshape(1, n) * p0wts.reshape(n, 1)\n",
    "    \n",
    "    #res += tempA\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWqW(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], q):\n",
    "    \"\"\"\n",
    "    Build the input to the Cholesky decomposition.\n",
    "    \n",
    "    Rather than call to_dense on every component B1, B2, Bs, instead return uncoalesced coo tensors\n",
    "    and call to_dense() once for B1, B2, Bs in this function. Similar for A0 and A0s.\n",
    "    \n",
    "    Although addition of sparse coo tensor results in is_coalesced() == False, \n",
    "    the result actually seems to be coalesced, so addition is rather costly.\n",
    "    \n",
    "    Maybe more efficient to stack indices and values, then coalesce once.\n",
    "    \"\"\"\n",
    "    \n",
    "    p0wts = bks['misc']['p0wts']\n",
    "    p0wts_diagmat = bks['misc']['p0wts_diagmat']\n",
    "    RXwt =bks['misc']['RXwt']  # n x kx\n",
    "    RXtwt =bks['misc']['RXtwt'] # kx x n\n",
    "    kx = int(bks['misc']['kx'].item())\n",
    "    k = int(bks['misc']['k'].item())\n",
    "    #ki = int(k.item())\n",
    "    n = int(bks['misc']['n'].item())\n",
    "    \n",
    "    #temp = torch.zeros([k, k], dtype=RX.dtype, device=RX.device)\n",
    "    #tempB = torch.sparse_coo_tensor(size=[k, k], dtype=RXwt.dtype, device=RXwt.device)\n",
    "\n",
    "    indices_all = []\n",
    "    values_all = []\n",
    "    \n",
    "    if bks['B1']['m'].item() != 0:\n",
    "        temp = fWW1(bks['B1'], q)\n",
    "        indices_all.append(temp._indices())\n",
    "        values_all.append(temp._values())\n",
    "    if bks['B2']['m'].item() != 0:\n",
    "        temp = fWW2(bks['B2'], q)\n",
    "        indices_all.append(temp._indices())\n",
    "        values_all.append(temp._values())\n",
    "    if bks['Bs']['m'].item() != 0:\n",
    "        temp = fWWs(bks['Bs'], q)\n",
    "        indices_all.append(temp._indices())\n",
    "        values_all.append(temp._values())\n",
    "    if bks['A0']['m'].item() != 0:\n",
    "        temp = fWW0(bks['A0'], q)\n",
    "        indices_all.append(temp._indices())\n",
    "        values_all.append(temp._values())\n",
    "        #tempA0.sparse_resize_((k, k), 2, 0)\n",
    "        #tempB += tempA0\n",
    "    if bks['A0s']['m'].item() != 0:\n",
    "        temp = fWW0s(bks['A0s'], q)\n",
    "        indices_all.append(temp._indices())\n",
    "        values_all.append(temp._values())\n",
    "        #tempA0s.sparse_resize_((k, k), 2, 0)\n",
    "        #tempB += tempA0s\n",
    "\n",
    "    tempBd = torch.sparse_coo_tensor(torch.hstack(indices_all), torch.hstack(values_all), size=(k, k),\n",
    "                                    dtype=RXtwt.dtype, device=RXtwt.device)    \n",
    "        \n",
    "    tempBd = tempBd.to_dense()    \n",
    "        \n",
    "    if bks['Bd']['m'].item() != 0:\n",
    "        tempBd += fWWd(bks['Bd'], q)\n",
    "        \n",
    "    temp2 = (p0wts.reshape(n, 1) * tempBd[:n, :] + RXwt @ tempBd[n:, :])\n",
    "\n",
    "    res = p0wts.reshape(1, n) * temp2[:,:n] + temp2[:, n:] @ RXtwt\n",
    "\n",
    "    #tempA = torch.sparse_coo_tensor(size=[n, n], dtype=RXwt.dtype, device=RXwt.device)\n",
    "    \n",
    "    #if bks['A0']['m'].item() != 0:\n",
    "    #    tempA += fWW0(bks['A0'], q)\n",
    "    #if bks['A0s']['m'].item() != 0:\n",
    "    #    tempA += fWW0s(bks['A0s'], q)\n",
    "\n",
    "    #tempA = (p0wts_diagmat @ tempA) @ p0wts_diagmat   \n",
    "        \n",
    "    #tempA = tempA.to_dense()\n",
    "\n",
    "    #tempA = tempA * p0wts.reshape(1, n) * p0wts.reshape(n, 1)\n",
    "    \n",
    "    #res += tempA\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWqW_old(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], q):\n",
    "    \"\"\"\n",
    "    Build the input to the Cholesky decomposition.\n",
    "    \n",
    "    Rather than call to_dense on every component B1, B2, Bs, instead return uncoalesced coo tensors\n",
    "    and call to_dense() once for B1, B2, Bs in this function. Similar for A0 and A0s.\n",
    "    \"\"\"\n",
    "    \n",
    "    p0wts = bks['misc']['p0wts']\n",
    "    p0wts_diagmat = bks['misc']['p0wts_diagmat']\n",
    "    RXwt =bks['misc']['RXwt']  # n x kx\n",
    "    RXtwt =bks['misc']['RXtwt'] # kx x n\n",
    "    kx = int(bks['misc']['kx'].item())\n",
    "    k = int(bks['misc']['k'].item())\n",
    "    #ki = int(k.item())\n",
    "    n = int(bks['misc']['n'].item())\n",
    "    \n",
    "    #temp = torch.zeros([k, k], dtype=RX.dtype, device=RX.device)\n",
    "    tempB = torch.sparse_coo_tensor(size=[k, k], dtype=RXwt.dtype, device=RXwt.device)\n",
    "\n",
    "    if bks['B1']['m'].item() != 0:\n",
    "        tempB += fWW1(bks['B1'], q)\n",
    "    if bks['B2']['m'].item() != 0:\n",
    "        tempB += fWW2(bks['B2'], q)\n",
    "    if bks['Bs']['m'].item() != 0:\n",
    "        tempB += fWWs(bks['Bs'], q)\n",
    "    if bks['A0']['m'].item() != 0:\n",
    "        tempA0 = fWW0(bks['A0'], q)\n",
    "        tempA0.sparse_resize_((k, k), 2, 0)\n",
    "        tempB += tempA0\n",
    "    if bks['A0s']['m'].item() != 0:\n",
    "        tempA0s = fWW0s(bks['A0s'], q)\n",
    "        tempA0s.sparse_resize_((k, k), 2, 0)\n",
    "        tempB += tempA0s\n",
    "\n",
    "    tempBd = tempB.to_dense()    \n",
    "        \n",
    "    if bks['Bd']['m'].item() != 0:\n",
    "        tempBd += fWWd(bks['Bd'], q)\n",
    "        \n",
    "    temp2 = (p0wts.reshape(n, 1) * tempBd[:n, :] + RXwt @ tempBd[n:, :])\n",
    "\n",
    "    res = p0wts.reshape(1, n) * temp2[:,:n] + temp2[:, n:] @ RXtwt\n",
    "\n",
    "    #tempA = torch.sparse_coo_tensor(size=[n, n], dtype=RXwt.dtype, device=RXwt.device)\n",
    "    \n",
    "    #if bks['A0']['m'].item() != 0:\n",
    "    #    tempA += fWW0(bks['A0'], q)\n",
    "    #if bks['A0s']['m'].item() != 0:\n",
    "    #    tempA += fWW0s(bks['A0s'], q)\n",
    "\n",
    "    #tempA = (p0wts_diagmat @ tempA) @ p0wts_diagmat   \n",
    "        \n",
    "    #tempA = tempA.to_dense()\n",
    "\n",
    "    #tempA = tempA * p0wts.reshape(1, n) * p0wts.reshape(n, 1)\n",
    "    \n",
    "    #res += tempA\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWqW_old(bks : typing.Dict[str, typing.Dict[str, torch.Tensor]], q):\n",
    "    \"\"\"\n",
    "    Build the input to the Cholesky decomposition.\n",
    "    \"\"\"\n",
    "    \n",
    "    RX =bks['misc']['RX']  # n x kx\n",
    "    RXt =bks['misc']['RX'].t() # kx x n\n",
    "    kx = int(bks['misc']['kx'].item())\n",
    "    k = int(bks['misc']['k'].item())\n",
    "    #ki = int(k.item())\n",
    "    n = int(bks['misc']['n'].item())\n",
    "    \n",
    "    temp = torch.zeros([k, k], dtype=RX.dtype, device=RX.device)\n",
    "\n",
    "    if bks['B1']['m'].item() != 0:\n",
    "        temp += fWW1(bks['B1'], q)\n",
    "    if bks['B2']['m'].item() != 0:\n",
    "        temp += fWW2(bks['B2'], q)\n",
    "    if bks['Bs']['m'].item() != 0:\n",
    "        temp += fWWs(bks['Bs'], q)\n",
    "    if bks['Bd']['m'].item() != 0:\n",
    "        temp += fWWd(bks['Bd'], q)\n",
    "        \n",
    "    temp2 = (temp[:n] + RX @ temp[n:])\n",
    "\n",
    "    #print(\"temp\", temp.size(), \"temp2\", temp2.size(), \"RX\", RX.size(), \"RXt\", RXt.size(),\"n\", n)    \n",
    "\n",
    "    res = temp2[:,:n] + temp2[:, n:] @ RXt\n",
    "\n",
    "    if bks['A0']['m'].item() != 0:\n",
    "        res += fWW0(bks['A0'], q)\n",
    "    if bks['A0s']['m'].item() != 0:\n",
    "        res += fWW0s(bks['A0s'], q)\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Programming Algorithm\n",
    "\n",
    "The following cells contain the main quadratic programming algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell takes numpy results from the order book and converts them in Pytorch arrays to be used as inputs into the quadratic program algorithm.\n",
    "\n",
    "Since the QP algorithm is desined to allow torch.jit.script() to be called on relevant functions, any functions containing numpy code must be kept separate because they cannot be jitted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If previous version of this function is needed, see flow-sim-90-pk15\n",
    "\n",
    "# torch.jit.ignore # This function cannot be jitted.\n",
    "def solve_qp_torch_jit_setup(bk, * , KKT_inputs=None, options={}):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # t0 = time.time()\n",
    "\n",
    "    default_options = {\"b_time_function_calls\" : False, \"b_use_fWqW\" : False,   \n",
    "                       'b_use_torch_dictionaries' : True, \n",
    "                       'maxiter' : 200, 'miniter' : 3, \n",
    "                    'dtype' : torch.float64, 'device' : 'cuda', 'bjit' : False,\n",
    "                   'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "                   'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e8,\n",
    "                   'initial_z' : 1.00e-0, 'initial_s' : 1.00e-0,\n",
    "                   'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-15,\n",
    "                   'eta_over_sigma' : 0.2, 'sigma_exponent' : 4, 'sigma_fac' : 0.20, 'afac' : 1.00,\n",
    "                   'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "                   'one_fac' : 1.00, 'max_alpha' : 1.00, 'alpha_fac' : 0.99, \n",
    "                   'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.100,\n",
    "                   'max_num_regeps1' : 10, 'max_num_regeps2' : 10,\n",
    "                   'regeps0' : 1.00e-12, 'regeps0factor' : 100.00, 'regeps0mod' : 1, 'regeps_add_factor' : 1000.00,\n",
    "                   'regeps1' : 1.00e-15, 'regeps2' : 1.00e-12, 'regeps1factor' : 10.00,\n",
    "                   'print_time' : True, 'print_overall_time' : True, \n",
    "                    'print_volume_each_iteration' : False, 'print_summary_each_iteration' : False, \n",
    "                     'print_mkt_results' : False, \n",
    "                   'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                   'print_cholesky_regularizations' : True\n",
    "                  }\n",
    "\n",
    "    #default_options = {'maxiter' : 200, 'miniter' : 3, 'dtype' : torch.float64, 'device' : 'cpu',\n",
    "    #                   'b_solve_dollars' : True, 'num_polish_cho_solve' : 0,\n",
    "    #                   'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-15,\n",
    "    #                   'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e8,\n",
    "    #                   'initial_z' : 1.00, 'initial_s' : 1.00,\n",
    "    #                   'eta_over_sigma' : 0.00, 'sigma_exponent' : 3, 'sigma_fac' : 1.00, 'afac' : 0.9999,\n",
    "    #                   'gamma' : 1.00, \n",
    "    #                   'one_fac' : 1.00, 'max_alpha' : 0.99, 'alpha_fac' : 0.99, \n",
    "    #                   'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.200,\n",
    "    #                   'max_num_regesp1' : 10, 'max_num_regeps2' : 10,\n",
    "    #                   'regeps0' : 1.00e-17, 'regeps0factor' : 10.00, 'regeps0mod' : 3, \n",
    "    #                  'regeps1' : 1.00e-16, 'regeps2' : 1.00e-14, 'regepsfactor' : 10.00,\n",
    "    #                  'print_time' : True, 'print_mkt_results' : True,\n",
    "    #                  'print_volume_each_iteration' : False\n",
    "    #                 }\n",
    "\n",
    "    options = dict(default_options, **options)\n",
    "\n",
    "    #print(options)\n",
    "    \n",
    "    inputs = bk.qpinputs\n",
    "    \n",
    "    dtype = options['dtype']\n",
    "    \n",
    "    np_dtype = np.float64 if dtype == torch.float64 else np.float32\n",
    "    device = options['device']\n",
    "\n",
    "    # torch.jit.script needs a consistent type for bks: a dictionary of dictionaries of tensors.\n",
    "    # The following is a nothing dictionary of dictionaries of tensors to use when b_use_torch_dictionaries == False.\n",
    "    bk.bks={'misc' : {'b_use_torch_dictionaries' : torch.tensor(0, dtype=torch.int64, device=device)}}\n",
    "    if options['b_use_torch_dictionaries'] == True:\n",
    "        #f_initialize_torch_dictionaries_(bk, dtype, device, b_solve_dollars=options['b_solve_dollars'])\n",
    "        f_initialize_all_bks(bk, options)\n",
    "        \n",
    "        #for B in bk.bks:\n",
    "        #    print(\"\\n\", B)\n",
    "        #    for kk in bk.bks[B]:\n",
    "        #        print(kk, type(bk.bks[B][kk]), bk.bks[B][kk].shape)\n",
    "        \n",
    "    # bks is a dictionary of dictionaries of order books, bks['B1'], bks['B2'], bks['Bs'], bks['Bd'], \n",
    "    # bks['A0'] (exchange orders), bks['A0s'] (stabilizing orders), \n",
    "    # plus and extra dictionary bks['misc'] with other needed information from bk\n",
    "    # TODO: Add bks['B3'], bks['As'] (sparse orders for shares), bks['Ad'] (dense orders for shares).\n",
    "    bks = bk.bks    \n",
    "    \n",
    "    # Set up exogenous inputs to algorithm: c, b, h, Pv, Ws, Wst, RX, wtp0, n, m, m2\n",
    "\n",
    "    n = inputs['RXs'].shape[0]   # number of assets\n",
    "    m = inputs['Ws'].shape[1]    # number of orders\n",
    "    #k = RXs.shape[1] - n   # number of registered portfolios, not counting individual assets\n",
    "    #TODO: Carrying bk.c.M2 around as an ad hoc parameter is inelegant. Need to divide Ws into two matrices???\n",
    "    m2 = bk.c.M2 # number of pairs trades. Ws[:, :m - m2] is single-asset orders, Ws[:, m - m2:] is pairs trades.\n",
    "\n",
    "    #print(\"bk.c.M2 = \", bk.c.M2)\n",
    "    \n",
    "    _ph = torch.as_tensor(inputs['ph'], dtype=dtype, device=device)   # dense array (m,) upper limit prices for portfolios, \n",
    "    _mkt_clear = torch.as_tensor(inputs['mkt_clear'], dtype=dtype, device=device)   # dense array (n,) zeros for market clearing\n",
    "    _xzero = torch.as_tensor(inputs['xzero'], dtype=dtype, device=device)   #inputs['xzero'] = dense array(m,) zeros \n",
    "    _q = torch.as_tensor(inputs['q'], dtype=dtype, device=device)   #inputs['q'] = dense array(m,) for q for inequality constraints\n",
    "    _dvec = torch.as_tensor(inputs['Dsmat'].diagonal(), dtype=dtype, device=device)  # diagonal of diagonal matrix D in paper, inverse impact of orders\n",
    "    \n",
    "    #_Ws = scipy.sparse.csr_matrix(inputs['Ws'], dtype=np_dtype) # (n+k, m) matrix of registered portfolio weights in order\n",
    "    #_Wst = scipy.sparse.csr_matrix(_Ws.T, dtype=np_dtype)\n",
    "    Ws = torch.sparse_coo_tensor(indices=np.vstack([inputs['Wcoo'].row, inputs['Wcoo'].col]), \n",
    "                                 values=inputs['Wcoo'].data,\n",
    "                                 size=inputs['Wcoo'].shape, dtype=dtype, device=device)    \n",
    "    Ws = Ws.coalesce()\n",
    "    Wst = torch.sparse_coo_tensor(indices=np.vstack([inputs['Wtcoo'].row, inputs['Wtcoo'].col]), \n",
    "                                 values=inputs['Wtcoo'].data,\n",
    "                                 size=inputs['Wtcoo'].shape, dtype=dtype, device=device)\n",
    "    Wstabs = torch.sparse_coo_tensor(indices=np.vstack([inputs['Wtcoo'].row, inputs['Wtcoo'].col]), \n",
    "                                 values=np.abs(inputs['Wtcoo'].data),\n",
    "                                 size=inputs['Wtcoo'].shape, dtype=dtype, device=device)\n",
    "    Wst = Wst.coalesce()\n",
    "    #_RX = inputs['RX']\n",
    "    RX = torch.as_tensor(inputs['RX'], dtype=dtype, device=device)\n",
    "    RXt = RX.T.clone().detach()\n",
    "    # wtp0 = scaling factor by which to multiply prices at end of algorithm.\n",
    "    # vainv = scaling factor to rescale xunits at end of algorithm\n",
    "\n",
    "    # Rescale prices of assets to one dollar, rescale quantities accordingly, keep wtp0 and vainv for rescaling at end.\n",
    "    # Vector wtp0v says individual asset weights are p0 units of one-dollar assets.\n",
    "    \n",
    "    if options['b_solve_dollars'] == True:\n",
    "        #print(\"b_solve_dollars: True\")\n",
    "        # Step 1: Normalize shares to one dollar:\n",
    "        # wtp0 not used except to multiply normalized clearing prices by wtp0 to rescale to original scale\n",
    "        assert (inputs['p0'] > 0.00).all(), \"PKError: All initial asset prices guesses should be positive, okay to comment out.\"\n",
    "        #_wtp0 = scipy.sparse.diags(inputs['p0'].astype(np_dtype).reshape(-1))  # benchmark price\n",
    "        #wtp0v = torch.as_tensor(_wtp0.diagonal(), dtype=dtype, device=device)\n",
    "        wtp0v = torch.tensor(inputs['p0'], dtype=dtype, device=device)\n",
    "        wtp0v = wtp0v.__abs__()  # make sure weights are positive\n",
    "        wtp0invv = torch.as_tensor(1.00 / wtp0v, dtype=dtype, device=device)\n",
    "        #_wtp0inv = scipy.sparse.diags(1.00 / _wtp0.diagonal()) # Number of rescaled shares to trade single asset portfolio\n",
    "        #wtp0invv = torch.as_tensor(_wtp0inv.diagonal(), dtype=dtype, device=device)\n",
    "        RXwt = wtp0v.reshape(-1, 1) * RX\n",
    "        RXtwt = RXwt.T.clone().detach()\n",
    "        #fR = FpR(wtp0v, wtp0v.reshape(-1, 1) * RX)  # (n, n+k) definitions of registered portfolios = [p, RX], faster if RX is dense\n",
    "        # va = dollar long-short gross size of indexes, rescaled to one dollar\n",
    "        assert (RX >= 0.00).all(), \"PKerror: All portfolio weights should be nonnegative, okay to comment out.\"\n",
    "        \n",
    "        #Step 2: Normalize portfolio price to one dollar by scaling by L1 norm\n",
    "        #_va = scipy.sparse.diags(_Wst.__abs__() @ (FR(_RX.__abs__()).T @ _wtp0.diagonal().__abs__()))\n",
    "        #vav = torch.as_tensor(_va.diagonal(), dtype=dtype, device=device)\n",
    "        #Wstabs = torch.sparse_coo_tensor(Wst.indices(), Wst.data(), size=Wst.size(), dtype=dtype, device=device)\n",
    "        #Wstabs.data = torch.abs(Wstabs.data())\n",
    "        vav = Wstabs.mv(torch.hstack([wtp0v, RXt.mv(wtp0v)]))  # Like L1 norm\n",
    "        #_vainv = scipy.sparse.diags(1.00 / _va.diagonal())    \n",
    "        vainvv = 1.00 / vav\n",
    "        \n",
    "        # We would like to do element-by-element multiplication of matrices Ws and Wts by vectors vainv,\n",
    "        # but Pytorch does not allow efficient element-by-element multiplication with sparse matrices!\n",
    "        # torch.sparse.mm() works with sparse coo matrices but is exceptionally slow!\n",
    "        # As a temporary solution, it is expedient to do the calculations in scipy,\n",
    "        # then use the scipy sparse matrix to create a Pytorch tensor.\n",
    "        # This temporary fix can be changed in the future when Pytorch has good element-by-element multiplication,\n",
    "        # or torch.sparse.mm() works efficiently.\n",
    "        \n",
    "        #Wsx = Ws.mul(vainvv.reshape(1, -1))  #This should work in Pytorch, but does not work\n",
    "        #Wstx = Wst.mul(vainvv.reshape(-1, 1))  #This should work in Pytorch, but does not work\n",
    "\n",
    "        _vainvv = vainvv.cpu().numpy()\n",
    "        _vainv = scipy.sparse.diags(_vainvv)\n",
    "        _Ws = scipy.sparse.coo_matrix((Ws.values().cpu().numpy(), \n",
    "                                       (Ws.indices()[0, :].cpu().numpy(), Ws.indices()[1,:].cpu().numpy())),\n",
    "                                      shape=Ws.size()).tocsr()\n",
    "        _Wsx = (_Ws @ _vainv).tocoo()  # Scale portfolio weights by L1 norm\n",
    "        _Wstx = _Wsx.T\n",
    "        Wsx = torch.sparse_coo_tensor(indices=np.vstack([_Wsx.row, _Wsx.col]), values=_Wsx.data, \n",
    "                                      size=_Wsx.shape, dtype=dtype, device=device)\n",
    "        Wstx = torch.sparse_coo_tensor(indices=np.vstack([_Wsx.col, _Wsx.row]), values=_Wsx.data, \n",
    "                                       size=_Wstx.shape, dtype=dtype, device=device)\n",
    "        \n",
    "        #for tup in [(_wtp0, '_wtp0'), (wtp0v, 'wtp0v'), (_wtp0inv, '_wtp0inv'), (wtp0invv, 'wtp0invv'), \n",
    "        #            (_va, '_va'), (vav, 'vav'), (vainvv, 'vainvv')]:\n",
    "        #    printa(*tup)\n",
    "        \n",
    "        #_mkt_clear = wtp0invv * _mkt_clear   # dense array (n,), no effect since zeros already\n",
    "        _mkt_clear = wtp0v * _mkt_clear   # dense array (n,), no effect since zeros already\n",
    "        _q = vav * _q\n",
    "        _xzero = vav * _xzero # no effect since zeros already\n",
    "        _ph = vainvv * _ph \n",
    "        _dvec = vainvv * _dvec * vainvv\n",
    "    else:  \n",
    "        #print(\"b_solve_dollars: False\")\n",
    "        # Solve for dollars\n",
    "        # assert c.index_prices == 1.00 and c.asset_price == 1.00, \"PKError: Solving for assets requires price = 1.00\"\n",
    "        #fR = FR(RX)  # (n, n+k) definitions of registered portfolios = [I_n, RX], faster if RX is dense\n",
    "        \n",
    "        wtp0v = torch.ones_like(_mkt_clear, dtype=dtype, device=device)\n",
    "\n",
    "        RXwt = RX\n",
    "        RXtwt=  RXt\n",
    "\n",
    "        vainvv = torch.ones_like(_ph, dtype=dtype, device=device)\n",
    "        _vainv = scipy.sparse.diags(np.ones_like(inputs['ph'], dtype=np_dtype))\n",
    "\n",
    "        Wsx = Ws\n",
    "        Wstx = Wst\n",
    "        \n",
    "    #Define matrices as linear operators:\n",
    "    \n",
    "    #fW = Fsparse_torch(Ws=_Ws, M2=m2, Wst=_Wst, dtype=dtype, device=device)   \n",
    "    #fW = Fsparse_torch(Ws=Wsx, M2=m2, Wst=Wstx, dtype=dtype, device=device)\n",
    "\n",
    "    Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N = Fw_init(\n",
    "        Wsx, Wstx, m2, dtype, device)\n",
    "\n",
    "    # Convert options to tensors and place in dict, which compiler converts to typing.Dict[str, torch.Tensor]:\n",
    "    \n",
    "    options_ten = {}\n",
    "    for k in options:\n",
    "        if k not in {'dtype', 'device', 'bk_sparsity'}:\n",
    "            _dtype = torch.int64 if type(options[k]) in {int, np.int32, np.int64} else dtype\n",
    "            options_ten[k] = torch.tensor(options[k], dtype=_dtype, device=device)\n",
    "            \n",
    "    #print(type(options_ten))        \n",
    "    \n",
    "    #for k in options_ten:\n",
    "    #    print(k, type(options_ten[k]), options_ten[k].dtype, options_ten[k])\n",
    "    \n",
    "    # pa = torch.as_tensor(bk.pa, device=device, dtype=dtype)\n",
    "    \n",
    "    return (options_ten, dtype, device, n, m, m2, _ph, _mkt_clear, _xzero, _q, _dvec, \n",
    "            Wsx, Wstx, wtp0v, RXwt, RXtwt, _vainv, \n",
    "            Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N, bks)\n",
    "\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell calculates market stats from the order book. It needs to be a separate function since the order book uses numpy.  It is called from code which might use torch.jit.script, but this code needs to be excluded from jitting because it uses numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work because bk not compatible with torch.jit.\n",
    "# TODO: Need algorithm to calculate volume within algorithm, based on QP itself, not order book.\n",
    "#@torch.jit.ignore()\n",
    "def update_demand_torch_no_jit(bk, y):\n",
    "    bk.update_demand(y.reshape(-1))\n",
    "    msg, mkt_stats = bk.calculate_volume_stats()\n",
    "    ucpM = mkt_stats['unclpM']\n",
    "    return ucpM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting fcholesky_ex into a separate function may make profiling easier. Remember, however, that the gpu calculations are asynchronous. The torch.cuda.synchronize() command may not make profiling transparent without synchronizing before the function call too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.jit.script\n",
    "def fcholesky_ex(AQAadj):\n",
    "    cho_fac, code = torch.linalg.cholesky_ex(AQAadj)\n",
    "    #torch.cuda.synchronize()\n",
    "    return cho_fac, code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining solve_qp_torch_jit_fcholesky() as separate function makes profiling more transparent.\n",
    "\n",
    "Remember that gpu is asynchronous so some torch.cuda.synchronize() calls may be needed.\n",
    "\n",
    "solve_qp_torch_jit_fcholesky() is called only one time, at the end of solve_qp_torch_jit_set_up_solver(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def solve_qp_torch_jit_fcholesky(options : typing.Dict[str, torch.Tensor], AQA, num_cholesky_regularizations : int,\n",
    "                                niter : int):\n",
    "\n",
    "    # Cholesky factorization is n*n*n/3 ops:\n",
    "    # Naive Strategy: If Cholesky decomposition fails due to poor conditioning, \n",
    "    # add larger and larger small positive amounts to diagonal until Cholesky decompostion succeeds\n",
    "\n",
    "    n = AQA.shape[0]\n",
    "\n",
    "    #for tup in [(AQA,'AQA'), (num_cholesky_regularizations,'num_cholesky_regularizations')]:\n",
    "    #    printa(*tup)\n",
    "\n",
    "    #torch.cuda.synchronize()\n",
    "\n",
    "    ni1 = 0\n",
    "    ni2 = 0\n",
    "\n",
    "    for ni1 in range(int(options['max_num_regeps1'].item())):\n",
    "        if ni1 == 0:\n",
    "            diageps = options['regeps0'] * options['regeps0factor']**(niter % options['regeps0mod'])\n",
    "        else:\n",
    "            diageps = options['regeps1'] * (options['regeps1factor']**(ni1 - 1))\n",
    "\n",
    "        #print(\"diageps = \", diageps.item())    \n",
    "            \n",
    "        #AQAadj[:, :] = AQA + scipy.sparse.diags(AQA.diagonal()) * diageps \n",
    "        AQAadj = AQA.clone().detach()\n",
    "        AQAadj_diag = AQAadj.diagonal()  # This is a reference to the diagonal of AQAadj!\n",
    "        #diag_min = AQAadj_diag.min()\n",
    "        AQAadj_diag *= (1.00 + diageps)\n",
    "        AQAadj_diag += diageps * options['regeps_add_factor']\n",
    "        #AQAadj.ravel()[::n+1] *= (1.00 + diageps)\n",
    "        #AQAadj.ravel()[::n+1] += diageps\n",
    "\n",
    "        # Set to True to convert AQAadj to \"correlation\" matrix to see if condition number changes:\n",
    "        b_make_diagonals_one = False\n",
    "        if b_make_diagonals_one == True:\n",
    "            # Get diagonal of matrix:\n",
    "            print(\"cond AQAadj = \", torch.linalg.cond(AQAadj))\n",
    "            diag = AQAadj.ravel()[::n+1]\n",
    "            assert diag.min() >= 0.00, \"PKError: Diagonal of positive semidefinite matrix should be nonnegative!\"\n",
    "            # Calculate inverse of elements of diagonal, keeping zeros equal to zero:\n",
    "            diag_inv = torch.where(diag > 0.00, 1.00 / diag, 0.00)\n",
    "            diag_inv_sqrt = diag_inv.sqrt()\n",
    "            # Make diagonal elements (except zeros) equal to one by rescaling rows and columns:\n",
    "            AQAadj_corr = diag_inv_sqrt.reshape(-1, 1) * AQAadj * diag_inv_sqrt.reshape(1, -1)\n",
    "            print(\"cond AQAadj_corr = \", torch.linalg.cond(AQAadj_corr))\n",
    "        \n",
    "        #torch.cuda.synchronize()\n",
    "\n",
    "        #cho_fac, code = torch.linalg.cholesky_ex(AQAadj)\n",
    "        cho_fac, code = fcholesky_ex(AQAadj)\n",
    "        \n",
    "        if code.item() != 0:\n",
    "            print(\"code = \", code.item())\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "\n",
    "        if code.item() != 0:\n",
    "            num_cholesky_regularizations += 1\n",
    "            #print(\"num_cholesky_regularizations = \", num_cholesky_regularizations, \", ni1 = \", ni1)\n",
    "            continue\n",
    "\n",
    "        #try:\n",
    "        #    print(\"cho_fac condition number = \", torch.linalg.cond(cho_fac))\n",
    "        #except:\n",
    "        #    print(\"Could not calculate cho_fac condition number\")\n",
    "\n",
    "        bchofail = False\n",
    "\n",
    "        if ni1 > 0 and options['print_cholesky_regularizations'] == 1:\n",
    "            print(\"num_cholesky_regularizations = \", num_cholesky_regularizations, \", ni1 = \", ni1)\n",
    "        \n",
    "        return cho_fac, AQA, num_cholesky_regularizations, bchofail\n",
    "\n",
    "    #print(\"invoking regeps2\")\n",
    "\n",
    "    for ni2 in range(int(options['max_num_regeps2'].item())):\n",
    "        #AQAadj[:, :] = AQA + (scipy.sparse.diags(\n",
    "        #    AQA.diagonal() + AQA.diagonal().mean() * options['regeps2'] * 10.00**ni) * \n",
    "        #             options['regeps2'] * 10.00**ni)\n",
    "        diagmean = AQA.ravel()[::n+1].mean() * options['regeps2'] * 100.00**ni2\n",
    "        AQAadj = AQA.clone().detach()\n",
    "        AQAadj.ravel()[::n+1] += diagmean\n",
    "        #cho_fac = scipy.linalg.cho_factor(AQAadj, lower=False, overwrite_a=False, check_finite=True)\n",
    "        #cho_fac, code = torch.linalg.cholesky_ex(AQAadj)\n",
    "        cho_fac, code = fcholesky_ex(AQAadj)\n",
    "        if code.item() != 0:\n",
    "            num_cholesky_regularizations += 1\n",
    "            #print(\"num_cholesky_regularizations = \", num_cholesky_regularizations, \", ni2 = \", ni2)\n",
    "            continue\n",
    "        bchofail = False\n",
    "\n",
    "        if ni1 > 0 or ni2 > 0:\n",
    "            print(\"num_cholesky_regularizations = \", num_cholesky_regularizations, \n",
    "                  \", ni1 = \", ni1 + 1, \", ni2 = \", ni2)\n",
    "        \n",
    "        return cho_fac, AQA, num_cholesky_regularizations, bchofail\n",
    "\n",
    "        num_cholesky_regularizations += 1\n",
    "        #print(\"num_cholesky_regularizations = \", num_cholesky_regularizations, \n",
    "        #          \", regeps2 = \", options['regeps2'], \", ni2 = \", ni2)\n",
    "        continue\n",
    "    bchofail = True\n",
    "    cho_fac = torch.empty((0,0), dtype=AQA.dtype, device=AQA.device)\n",
    "    print(\"Cholesky failed unexpectedly: \", \n",
    "          \"num_cholesky_regularizations = \", num_cholesky_regularizations, \n",
    "          \", ni = \", ni1 + 1, \", ni2 = \", ni2 + 1)\n",
    "\n",
    "    return cho_fac, AQA, num_cholesky_regularizations, bchofail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve_qp_torch_jit_solve() quickly solves the linearized system using the cholesky factorization previously created by a more expensive Cholesky decomposition.\n",
    "\n",
    "A different algorithm might try something else, like conjugate gradient, but would probably be slower even if the cost of the Cholesky decomposition is taken into account.\n",
    "\n",
    "This function needs to be separate because it is called in multiple places: once using default initialization, once each iteration, again each iteration to polish first called using Mehrotra correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def solve_qp_torch_jit_solve(_zmu, _zlambda, _smu, _slambda, _zsimu, _zsilambda, Qv, wtp0v, RXwt, RXtwt, AQA,\n",
    "        Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, bchofail : bool, cho_fac : torch.Tensor, options : typing.Dict[str, torch.Tensor], \n",
    "        bx, by, _bzmu, _bzlambda, _bsmu, _bslambda, \n",
    "        bks : typing.Dict[str, typing.Dict[str, torch.Tensor]]):\n",
    "    \n",
    "    # m = Qv.shape[0]\n",
    "    n = AQA.shape[0]\n",
    "\n",
    "    # see equation 49\n",
    "    \n",
    "    _bszmu = _bsmu / _zmu\n",
    "    _bszlambda = _bslambda / _zlambda\n",
    "    \n",
    "    _bbzmu = _bzmu + _smu + _bszmu\n",
    "    _bbzlambda = _bzlambda + _slambda + _bszlambda\n",
    "    \n",
    "    bbx = bx + _zsilambda * _bbzlambda - _zsimu * _bbzmu\n",
    "\n",
    "    if bks['misc']['b_use_torch_dictionaries'] == 1:\n",
    "        #bby = fWx(bks, Qv * bbx) - by\n",
    "        bby = f_Wx(bks, Qv * bbx) - by\n",
    "    else:    \n",
    "        tempa = f_sparse_mv_for_cpu_and_cuda(Fw_Wcsr, Fw_Wcoo, Qv * bbx)    \n",
    "        bby = wtp0v * tempa[:n] + RXwt @ tempa[n:] - by\n",
    "\n",
    "    if bks['misc']['b_use_torch_dictionaries'] == 1 and options['b_time_function_calls'] == 1:\n",
    "        nreps = 100\n",
    "        t0 = timeit.default_timer()    \n",
    "        torch.cuda.synchronize()\n",
    "        for _ in range(nreps):\n",
    "            #bby = fWx(bks, Qv * bbx) - by\n",
    "            bby = f_Wx(bks, Qv * bbx) - by\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = timeit.default_timer()\n",
    "        for _ in range(nreps):\n",
    "            tempa = f_sparse_mv_for_cpu_and_cuda(Fw_Wcsr, Fw_Wcoo, Qv * bbx)    \n",
    "            bby = wtp0v * tempa[:n] + RXwt @ tempa[n:] - by\n",
    "            torch.cuda.synchronize()\n",
    "        t2 = timeit.default_timer()\n",
    "        print(\"B fwx = \", t1 - t0, \", old = \", t2 - t1)\n",
    "\n",
    "    # TODO: ??? Even if dtype=np.float32, should cholesky solve should be np.float64 to preserve accuracy?\n",
    "    if bchofail == False:\n",
    "        #dy = torch.linalg.cholesky_solve(cho_fac, bby)\n",
    "        dy = torch.cholesky_solve(bby.reshape(-1, 1), cho_fac).reshape(-1)\n",
    "        #TODO: The following polishing loop never seems to work. Is there a bug?\n",
    "        for _ in range(int(options['num_polish_cho_solve'].item())):\n",
    "            dy = dy + torch.cholesky_solve((bby - AQA @ dy).reshape(-1, 1), cho_fac).reshape(-1)\n",
    "    else:\n",
    "        # This will force end of algorithm with nonconvergence:\n",
    "        dy = torch.zeros_like(by)    \n",
    "\n",
    "    if bks['misc']['b_use_torch_dictionaries'] == 1:\n",
    "        #dx = Qv * ( bbx - fWty(bks, dy) ) \n",
    "        dx = Qv * ( bbx - f_Wty(bks, dy) ) \n",
    "    else:\n",
    "        dx = Qv * ( bbx - f_sparse_mv_for_cpu_and_cuda(Fw_Wtcsr, Fw_Wtcoo, torch.hstack([wtp0v * dy, RXtwt @ dy])) )\n",
    "\n",
    "    if bks['misc']['b_use_torch_dictionaries'] == 1 and options['b_time_function_calls'] == 1:\n",
    "        nreps = 100\n",
    "        t0 = timeit.default_timer()    \n",
    "        torch.cuda.synchronize()\n",
    "        for _ in range(nreps):\n",
    "            #dx = Qv * ( bbx - fWty(bks, dy) ) ; torch.cuda.synchronize()\n",
    "            dx = Qv * ( bbx - f_Wty(bks, dy) ) ; torch.cuda.synchronize()\n",
    "        t1 = timeit.default_timer()\n",
    "        for _ in range(nreps):\n",
    "            dx = Qv * ( bbx - f_sparse_mv_for_cpu_and_cuda(Fw_Wtcsr, Fw_Wtcoo, torch.hstack([wtp0v * dy, RXtwt @ dy])) ); torch.cuda.synchronize()\n",
    "        t2 = timeit.default_timer()\n",
    "        print(\"B fwty = \", t1 - t0, \", old = \", t2 - t1)\n",
    "        \n",
    "    _dzmu = _zsimu * (-dx - _bbzmu)\n",
    "    _dzlambda = _zsilambda * (dx - _bbzlambda)\n",
    "    \n",
    "    _dsmu = -_dzmu / _zsimu - _bszmu - _smu\n",
    "    _dslambda = -_dzlambda / _zsilambda - _bszlambda - _slambda\n",
    "\n",
    "    return dx, dy, _dzmu, _dzlambda, _dsmu, _dslambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function solve_qp_torch_jit_set_up_solver() has two expensive calculations:\n",
    "\n",
    "1. It calculates the matrix AQA to be decomposed by Cholesky decomposition. This matrix has the form A Qv At, where Qv is a diagonal positive definite matrix, with one diagonal entry per order, which changes every iteration. If we write A = R W as the matrix of portfolio weights, where R is a matrix of individual portfolio and index portfolio definitions and W is a matrix of individual asset weights and pairs weights, then AQA = R W Qv W^t R^t. The matrix W has columns with only one (individual asset order) or two (pairs trade order) nonzero elements per column.  For numerical efficiency, the calculation is done as  AQA = R (W Qv W^t) R^t instead of AQA = (R W) Qv (W R)^t.  This avoids calculating portfolio weights many times when the same portfolio is traded many times.\n",
    "\n",
    "2. It calls solve_qp_torch_jit_fcholesky(), which does the expensive Cholesky decomposition.  This is an n-cubed algorithm in the number of assets, so computation time grows dramatically as the number of assets grows.\n",
    "\n",
    "This is put into a separate function to make profiling easier.  Remember that gpu is asynchronous and may need to add torch.cuda.synchronize() to obtain accurate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def solve_qp_torch_jit_set_up_solver(options : typing.Dict[str, torch.Tensor],  \n",
    "                    num_cholesky_regularizations : int, _zmu, _zlambda, _smu, _slambda, _dvec, \n",
    "                  Fw_Wcsr, Fw_Wtcsr, Fw_indices, Fw_data, Fw_data4, Fw_M1 : int, Fw_N : int, wtp0v, RXwt, RXtwt, niter : int,\n",
    "                    bks : typing.Dict[str, typing.Dict[str, torch.Tensor]]):\n",
    "    \n",
    "    # m = _dvec.shape[0]\n",
    "    n = RXwt.shape[0]\n",
    "    k = n + RXwt.shape[1]\n",
    "    \n",
    "    #print(\"RXwt\", type(RXwt))\n",
    "    \n",
    "    # This function defines AQA = fR @  Ws @ Q @ Ws.T @ fr.T, then calculates a cholesky decomposition of AQA:\n",
    "    # Computation time for calculating AQA is greater than for the cholesky decomposition???\n",
    "    \n",
    "    _zsimu = _zmu / _smu\n",
    "    _zsilambda = _zlambda / _slambda\n",
    "    \n",
    "    Qv = 1.00 / (_dvec + _zsilambda + _zsimu)\n",
    "\n",
    "    if options['b_use_torch_dictionaries'] == True:\n",
    "        \n",
    "        if options['b_use_fWqW'] == 1:\n",
    "            #print(\"using fWqW\")\n",
    "            #AQA = fWqW(bks, Qv)\n",
    "            AQA = f_WqW(bks, Qv)\n",
    "        else:\n",
    "            #print(\"using csr\")\n",
    "            Qdiag = torch.sparse_csr_tensor(bks['misc']['rangem1'], bks['misc']['rangem'], Qv)\n",
    "            #_tmp = torch.mm(Fw_Wcsr, Qdiag)\n",
    "            #WQW = torch.mm(_tmp, Fw_Wtcsr).to_dense()\n",
    "            _tmp = torch.mm(Qdiag, Fw_Wtcsr)\n",
    "            WQW = torch.mm(Fw_Wcsr, _tmp).to_dense()\n",
    "            RWQW = wtp0v.reshape(-1, 1) * WQW[:n, :] + RXwt @ WQW[n:, :] \n",
    "            AQA = wtp0v.reshape(1, -1) * RWQW[:, :n] + RWQW[:, n:] @ RXtwt\n",
    "    else:    \n",
    "        #print(\"using default\")\n",
    "        WQW = Fw_WQW(Qv, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N)\n",
    "\n",
    "        #print(\"WQW cond num = \", torch.linalg.cond(WQW))\n",
    "\n",
    "        #RWQW = fR._matmat(WQW)  # works with dense=False or dense=True in line defining WQW, not clear which is faster\n",
    "\n",
    "        RWQW = wtp0v.reshape(-1, 1) * WQW[:n, :] + RXwt @ WQW[n:, :] \n",
    "        #AQA[: ,:] = (fR @ RWQW.T).astype(AQAdtype)\n",
    "        AQA = wtp0v.reshape(1, -1) * RWQW[:, :n] + RWQW[:, n:] @ RXtwt\n",
    "\n",
    "    if bks['misc']['b_use_torch_dictionaries'] == 1 and options['b_time_function_calls'] == 1:\n",
    "        nreps = 100\n",
    "        t0 = timeit.default_timer()    \n",
    "        torch.cuda.synchronize()\n",
    "        for _ in range(nreps):\n",
    "            if options['b_use_fWqW'] == True:\n",
    "                #print(\"using fWqW\")\n",
    "                #AQA = fWqW(bks, Qv)\n",
    "                AQA = f_WqW(bks, Qv)\n",
    "            else:\n",
    "                #print('using csr')\n",
    "                Qdiag = torch.sparse_csr_tensor(bks['misc']['rangem1'], bks['misc']['rangem'], Qv, dtype=dtype, device=device)\n",
    "                #_tmp = torch.mm(Fw_Wcsr, Qdiag)\n",
    "                #WQW = torch.mm(_tmp, Fw_Wtcsr).to_dense()\n",
    "                _tmp = torch.sparse.mm(Qdiag, Fw_Wtcsr)\n",
    "                WQW = torch.sparse.mm(Fw_Wcsr, _tmp).to_dense()\n",
    "                RWQW = wtp0v.reshape(-1, 1) * WQW[:n, :] + RXwt @ WQW[n:, :] \n",
    "                _AQA = wtp0v.reshape(1, -1) * RWQW[:, :n] + RWQW[:, n:] @ RXtwt\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = timeit.default_timer()\n",
    "        for _ in range(nreps):\n",
    "            #print(\"using base\")\n",
    "            WQW = Fw_WQW(Qv, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N)\n",
    "\n",
    "            #print(\"WQW cond num = \", torch.linalg.cond(WQW))\n",
    "\n",
    "            #RWQW = fR._matmat(WQW)  # works with dense=False or dense=True in line defining WQW, not clear which is faster\n",
    "\n",
    "            RWQW = wtp0v.reshape(-1, 1) * WQW[:n, :] + RXwt @ WQW[n:, :] \n",
    "            #AQA[: ,:] = (fR @ RWQW.T).astype(AQAdtype)\n",
    "            _AQA = wtp0v.reshape(1, -1) * RWQW[:, :n] + RWQW[:, n:] @ RXtwt\n",
    "            torch.cuda.synchronize()\n",
    "        t2 = timeit.default_timer()\n",
    "        print(\"B fwqw = \", t1 - t0, \", old = \", t2 - t1)\n",
    "\n",
    "    #print(\"AQA cond num = \", torch.linalg.cond(AQA))\n",
    "    #printa(AQA, 'AQA')\n",
    "    \n",
    "    cho_fac, AQA, num_cholesky_regularizations, bchofail = solve_qp_torch_jit_fcholesky(\n",
    "                            options, AQA, num_cholesky_regularizations, niter)    \n",
    "\n",
    "    return _zsimu, _zsilambda, cho_fac, AQA, Qv, num_cholesky_regularizations, bchofail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main algorithm in next cell. \n",
    "\n",
    "This function can be jitted using Pytorch because it only uses allowed Pytorch functions. Instead of setting torch.jit.script as decorator immediately below, tha main function solve_qp() calls torch.jit.script(solve_qp_torch_jit_algo) as an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@torch.jit.script\n",
    "def solve_qp_torch_jit_algo(options : typing.Dict[str, torch.Tensor], dtype : torch.dtype, device : torch.device, \n",
    "         KKT_inputs : typing.Optional[typing.Dict[str, torch.Tensor]], \n",
    "         _ph, _mkt_clear, _xzero, _q, _dvec, Wsx, Wstx, wtp0v, RXwt, RXtwt, \n",
    "         Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, \n",
    "        bks : typing.Dict[str, typing.Dict[str, torch.Tensor]]):\n",
    "\n",
    "    # N = num assets\n",
    "    # NX = num portfolios\n",
    "    # M = num orders, excluding exchange\n",
    "    # M2 = num pairs trades\n",
    "    \n",
    "    # n = N\n",
    "    # m = M + 2*N, (includes 2*N exchange orders)\n",
    "    # m2 = M2\n",
    "\n",
    "    # c = (m,)\n",
    "    # b = (n,)\n",
    "    # h = (2*m,)\n",
    "    # Pv = (m,)\n",
    "    # Wsx = (N + NX, m), n = num assets, p = num portfolios, m = num orders + 2 * num assets\n",
    "    # Wstx = (m, N + NX)\n",
    "    # wtp0v = (n,)\n",
    "    # RXwt = (n, NX)\n",
    "    # RXtwt = (NX, n)\n",
    "    # Fw_Wcsr = (N + NX, m)\n",
    "    # Fw_Wtcsr = (N + NX, m)\n",
    "    # Fw_indices = (2, m + 3*M2) = (2, 2*N + M + 3*M2) = (2, 2*N + M1 + 4*M2)\n",
    "    # Fw_data = (m + 3*M2,) \n",
    "    # Fw_data4 = (M2, 4)\n",
    "\n",
    "    # NO Fw_M1 = 3 * M2 + 2 * N\n",
    "    # Fw_M1 = m - M2\n",
    "    # Fw_N = N + NX\n",
    "    \n",
    "    n = _mkt_clear.shape[0]\n",
    "    m = _ph.shape[0]\n",
    "    m2 = Fw_data4.shape[0]\n",
    "    #Fw_M1 = Fw_data.shape[0] - m + 2 * n\n",
    "    Fw_M1 = m - m2\n",
    "    Fw_N = Fw_Wcsr.shape[0]\n",
    "    \n",
    "    x = torch.empty_like(_ph) # shape=(m,), m = num orders + 2 * num assets = num orders including exchange trading\n",
    "    y = torch.empty_like(_mkt_clear) # shape=(n,), n = num assets\n",
    "        \n",
    "    _zmu = torch.empty_like(_q)\n",
    "    _zlambda = torch.empty_like(_q)\n",
    "    _smu = torch.empty_like(_q)\n",
    "    _slambda = torch.empty_like(_q)\n",
    "\n",
    "    dx = torch.empty_like(x)\n",
    "    dy = torch.empty_like(y)\n",
    "\n",
    "    rxnorm = torch.tensor(-999.999, dtype=dtype, device=device)\n",
    "    rynorm = torch.tensor(-999.999, dtype=dtype, device=device)\n",
    "    rznorm = torch.tensor(-999.999, dtype=dtype, device=device)\n",
    "\n",
    "    # Main algorithm begins here:\n",
    "    \n",
    "    ##torch.cuda.empty_cache()\n",
    "    \n",
    "    bchofail = False\n",
    "    \n",
    "    num_cholesky_regularizations = 0\n",
    "    \n",
    "    Qv = torch.as_tensor(torch.ones_like(_dvec), dtype=dtype, device=device)\n",
    "    AQA = torch.tensor((n,n), dtype=dtype, device=device)\n",
    "    \n",
    "    # Initial value for alpha for first and second pass:\n",
    "    alpha0 = torch.tensor(-99999.00, dtype=dtype, device=device)\n",
    "    alpha1 = torch.tensor(-99999.00, dtype=dtype, device=device)\n",
    "    nubar = torch.tensor(-9999.00, dtype=dtype, device=device)\n",
    "\n",
    "    alphap = -999.99\n",
    "    alphad = -999.99\n",
    "    \n",
    "    # Next step: Initialize x, y, _zmu, _zlambda, _smu, _slambda\n",
    "    \n",
    "    if KKT_inputs is not None:  #Initialize with previous results if there are any\n",
    "\n",
    "        #print(\"Initializing from inputs\")\n",
    "\n",
    "        x[:] = KKT_inputs['x']\n",
    "        y[:] = KKT_inputs['y']\n",
    "        \n",
    "        _zmu = KKT_inputs['z'][:m]\n",
    "        _zlambda = KKT_inputs['z'][m:]\n",
    "        _smu = KKT_inputs['s'][:m]\n",
    "        _slambda = KKT_inputs['s'][m:]\n",
    "\n",
    "        nubar = KKT_inputs['nubar']\n",
    "\n",
    "    elif options['initialize_with_midpoint'] == 1:    # Pick big nubar = 10**8 and x = 0.50*_q (midpoint)\n",
    "        \n",
    "        # options['initialize_with_midpoint'] require initializing y, \n",
    "        # but there is not good choice to use.\n",
    "\n",
    "        #print('initialize_with_midpoint', options['initialize_with_midpoint'].item())    \n",
    "\n",
    "        # Initializing so that x == q/2, slack variable has no error (and stays that way), so slack variable is unnecessary\n",
    "\n",
    "        nubar = options['initial_nubar_midpoint']\n",
    "        \n",
    "        x[:] = 0.50 * _q\n",
    "        y[:] = 0.00  # Set initial prices to zero since no obvious alternative \n",
    "        _smu = x\n",
    "        _slambda = _q - x\n",
    "        _zmu = nubar / _smu\n",
    "        _zlambda = nubar / _smu\n",
    "\n",
    "    else:  # default initialization like Cvxopt algorithm when options['initial_z'] = options['initial_s'] = 1.00\n",
    "\n",
    "        #print('default_initialization')\n",
    "        \n",
    "        # Since options['initial_z'] and options['initial_s'] are scalars, need to get dimensions of\n",
    "        # _zmu, _zlambda, _smu, and _slambda correct.\n",
    "        \n",
    "        _zmu[:] = options['initial_z']\n",
    "        _zlambda[:] = options['initial_z']\n",
    "        _smu[:] = options['initial_s']\n",
    "        _slambda[:] = options['initial_s']\n",
    "\n",
    "        _zsimu, _zsilambda, cho_fac, AQA, Qv, num_cholesky_regularizations, bchofail = solve_qp_torch_jit_set_up_solver(\n",
    "                      options, num_cholesky_regularizations, _zmu, _zlambda, _smu, _slambda, _dvec, \n",
    "                      Fw_Wcsr, Fw_Wtcsr, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N, wtp0v, RXwt, RXtwt, 0, \n",
    "                    bks=bks)\n",
    "\n",
    "        x, y, _zmu, _zlambda, _smu, _slambda = solve_qp_torch_jit_solve(_zmu, _zlambda, _smu, _slambda, \n",
    "                    _zsimu, _zsilambda, Qv, wtp0v, RXwt, RXtwt, AQA,  \n",
    "                    Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, bchofail, cho_fac, options, bx=_ph, by=_mkt_clear, \n",
    "                    _bzmu=_xzero, _bzlambda=_q, _bsmu=-_smu, _bslambda=-_slambda, bks=bks) \n",
    "\n",
    "        nubar = torch.tensor(1.00e+30, dtype=dtype, device=device)\n",
    "\n",
    "        #s = -z # PK: not sure if this is correct?\n",
    "\n",
    "        alphap = -torch.minimum((-_zmu).min(), (-_zlambda).min())\n",
    "        \n",
    "        if alphap > 0.00:\n",
    "            \n",
    "            _smu = -_zmu + ((1.00 / options['afac']) + alphap)\n",
    "            _slambda = -_zlambda + ((1.00 / options['afac']) + alphap)\n",
    "        \n",
    "        alphad =  -torch.minimum(_zmu.min(), _zlambda.min())\n",
    "        \n",
    "        if alphad > 0.00:\n",
    "            \n",
    "            _zmu = _zmu  + ((1.00 / options['afac']) + alphad)\n",
    "            _zlambda = _zlambda  + ((1.00 / options['afac']) + alphad)\n",
    "\n",
    "    # dt_update_xyzs = 0.00\n",
    "    \n",
    "    ###############################################    \n",
    "\n",
    "    _dzmu = torch.empty_like(_zmu)\n",
    "    _dzlambda = torch.empty_like(_zlambda)\n",
    "    _dsmu = torch.empty_like(_smu)\n",
    "    _dslambda = torch.empty_like(_slambda)\n",
    "\n",
    "    xold = x\n",
    "    yold = y\n",
    "    _zmu_old = _zmu\n",
    "    _zlambda_old = _zlambda\n",
    "    _smu_old = _smu\n",
    "    _slambda_old = _slambda\n",
    "    \n",
    "    tiny_num = torch.tensor(1.00e-30, dtype=dtype, device=device)\n",
    "\n",
    "    # Main loop of algorithm:    \n",
    "   \n",
    "    #torch.cuda.synchronize()\n",
    "\n",
    "    niter = 0\n",
    "    for niter in range(int(options['maxiter'].item())):\n",
    "\n",
    "        if bchofail == True:\n",
    "            # Pretend maximum iterations have occurred if Cholesky failed already:\n",
    "            niter = options['maxiter'] + 2\n",
    "\n",
    "        nubar_old = nubar\n",
    "\n",
    "        # *** The following should be 2m????:\n",
    "        \n",
    "        nubar = (_smu.dot(_zmu) + _slambda.dot(_zlambda)) / (2.00 * m)  #equation 41 in paper\n",
    "                \n",
    "        # Truncate previous step if nubar has increased:\n",
    "\n",
    "        if niter > 0:\n",
    "            _count = 0\n",
    "            for _count in range(int(options['max_num_trunc'].item())):\n",
    "                if nubar > nubar_old:\n",
    "                    alpha1 = options['alpha_trunc_factor'] * alpha1\n",
    "\n",
    "                    if options['print_alpha_trunc_factor'] == 1:\n",
    "                        print(\"nubar > nubar_old, alpha1 = \", alpha1.item(), \n",
    "                              #\"alpha_trunc_factor = \", options['alpha_trunc_factor'].item(),\n",
    "                             \"nubar_old = \", nubar_old.item(), \"nubar = \", nubar.item())\n",
    "                    \n",
    "                    x = xold + alpha1 * dx\n",
    "                    y = yold + alpha1 * dy\n",
    "                    \n",
    "                    _zmu = _zmu_old + alpha1 * _dzmu\n",
    "                    _zlambda = _zlambda_old + alpha1 * _dzlambda\n",
    "                    _smu = _smu_old + alpha1 * _dsmu\n",
    "                    _slambda = _slambda_old + alpha1 * _dslambda\n",
    "                    \n",
    "                    _zmu = torch.maximum(_zmu, tiny_num)\n",
    "                    _zlambda = torch.maximum(_zlambda, tiny_num)\n",
    "                    _smu = torch.maximum(_smu, tiny_num)\n",
    "                    _slambda = torch.maximum(_slambda, tiny_num)\n",
    "                    \n",
    "                    nubar = (_smu.dot(_zmu) + _slambda.dot(_zlambda)) / (2.00 * m)\n",
    "\n",
    "                else:\n",
    "                    break \n",
    "\n",
    "            if _count > 0:\n",
    "                if options['print_trunc'] == 1:\n",
    "                    print(\"trunc=\", _count + 1)\n",
    "                    \n",
    "        # Calculate current error rx, ry, rz and terminate if close enough to zero:        \n",
    "\n",
    "        if bks['misc']['b_use_torch_dictionaries'] == 1:\n",
    "            #temp_Wt_Rt_pa = fWty(bks, y)\n",
    "            \n",
    "            for _k in bks:\n",
    "                try:\n",
    "                    print(_k, bks[_k].size())\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            temp_Wt_Rt_pa = f_Wty(bks, y)\n",
    "        else:\n",
    "            temp_Rt_pa = torch.hstack([wtp0v * y, RXtwt @ y]).reshape(-1)  #equation 42 in paper\n",
    "            temp_Wt_Rt_pa = f_sparse_mv_for_cpu_and_cuda(Fw_Wtcsr, Fw_Wtcoo, temp_Rt_pa)  #equation 42 in paper\n",
    "\n",
    "        if bks['misc']['b_use_torch_dictionaries'] == 1 and options['b_time_function_calls'] == 1:\n",
    "            nreps = 100\n",
    "            t0 = timeit.default_timer()    \n",
    "            torch.cuda.synchronize()\n",
    "            for _ in range(nreps):\n",
    "                #temp_Wt_Rt_pa = fWty(bks, y)\n",
    "                temp_Wt_Rt_pa = f_Wty(bks, y)\n",
    "                torch.cuda.synchronize()\n",
    "            t1 = timeit.default_timer()\n",
    "            for _ in range(nreps):\n",
    "                temp_Rt_pa = torch.hstack([wtp0v * y, RXtwt @ y]).reshape(-1)  #equation 42 in paper\n",
    "                temp_Wt_Rt_pa = f_sparse_mv_for_cpu_and_cuda(Fw_Wtcsr, Fw_Wtcoo, temp_Rt_pa)  #equation 42 in paper\n",
    "                torch.cuda.synchronize()\n",
    "            t2 = timeit.default_timer()\n",
    "            print(\"A fwty = \", t1 - t0, \", old = \", t2 - t1)\n",
    "\n",
    "        #fprn(\"Fw_Wtcsr:\", torch.abs(Fw_Wtcsr.values()).max(), \".3e\")\n",
    "        #fprn(\"Fw_Wtcoo:\", torch.abs(Fw_Wtcoo.values()).max(), \".3e\")\n",
    "        #fprn(\", y:\", torch.abs(y).max(), \".3e\")\n",
    "        #fprn(\", temp_Rt_pa:\", torch.abs(temp_Rt_pa).max(), \".3e\")\n",
    "        #fprn(\", x:\", torch.abs(x).max(), \".3e\")\n",
    "        #fprn(\", temp_Wt_Rt_pa: \", torch.abs(temp_Wt_Rt_pa).max(), \".3e\")\n",
    "        #fprn(\", _zlambda:\", torch.abs(_zlambda).max(), \".3e\")\n",
    "        #fprn(\", _zmu:\", torch.abs(_zmu).max(), \".3e\")\n",
    "        #print(\"\")\n",
    "\n",
    "        #print('x', x.size(), 'temp_Wt_Rt_pa', temp_Wt_Rt_pa.size())\n",
    "        \n",
    "        rx = _dvec * x + temp_Wt_Rt_pa + _zlambda - _zmu - _ph  #equation 42 in paper\n",
    "\n",
    "        if bks['misc']['b_use_torch_dictionaries'] == 1:\n",
    "            #ry = fWx(bks, x) - _mkt_clear\n",
    "            ry = f_Wx(bks, x) - _mkt_clear\n",
    "        else:\n",
    "            _W_x = f_sparse_mv_for_cpu_and_cuda(Fw_Wcsr, Fw_Wcoo, x)   #equation 43 in paper\n",
    "            _RXwt_Wx = RXwt @ _W_x[n:]  # equation 43 in paper\n",
    "            ry = wtp0v * _W_x[:n] + _RXwt_Wx - _mkt_clear  # equation 43 in paper\n",
    "\n",
    "        if bks['misc']['b_use_torch_dictionaries'] == 1 and options['b_time_function_calls'] == 1:\n",
    "            nreps = 100\n",
    "            t0 = timeit.default_timer()    \n",
    "            torch.cuda.synchronize()\n",
    "            for _ in range(nreps):\n",
    "                #ry = fWx(bks, x) - _mkt_clear\n",
    "                ry = f_Wx(bks, x) - _mkt_clear\n",
    "                torch.cuda.synchronize()\n",
    "            t1 = timeit.default_timer()\n",
    "            for _ in range(nreps):\n",
    "                _W_x = f_sparse_mv_for_cpu_and_cuda(Fw_Wcsr, Fw_Wcoo, x)   #equation 43 in paper\n",
    "                _RXwt_Wx = RXwt @ _W_x[n:]  # equation 43 in paper\n",
    "                ry = wtp0v * _W_x[:n] + _RXwt_Wx - _mkt_clear  # equation 43 in paper\n",
    "                torch.cuda.synchronize()\n",
    "            t2 = timeit.default_timer()\n",
    "\n",
    "            print(\"A fwx = \", t1 - t0, \", old = \", t2 - t1)\n",
    "        \n",
    "        _rzmu = -x + _smu - _xzero  # equation 44 in paper\n",
    "        _rzlambda = x + _slambda - _q  # equation 45 in paper\n",
    "        \n",
    "        rxnorm = torch.linalg.norm(rx, ord=np.inf)  # sup norm np.abs(rx).max()    \n",
    "        rynorm = torch.linalg.norm(ry, ord=np.inf)    \n",
    "        rznorm = torch.maximum(torch.linalg.norm(_rzmu, ord=np.inf), torch.linalg.norm(_rzlambda, ord=np.inf))\n",
    "\n",
    "        if options['print_volume_each_iteration'] == 1:\n",
    "            #prn(\"ucpM=\", ucmP, \".2e\")\n",
    "            #print(\"\")\n",
    "            pass\n",
    "        if options['print_summary_each_iteration'] == 1:\n",
    "            fprni(\"i=\", niter) \n",
    "            fprn(\", a0=\", alpha0.item(), \".3e\")\n",
    "            fprn(\", a1=\", alpha1.item(), \".3e\")\n",
    "            fprn( \", rx=\", rxnorm.item(), \".2e\")\n",
    "            fprn(\", ry=\", rynorm.item(), \".2e\") \n",
    "            fprn(\", rz=\", rznorm.item(), \".2e\")\n",
    "            fprn(\", nubar=\", nubar.item(), \".2e\")\n",
    "            print(\"\")\n",
    "\n",
    "        # Test tolerance and terminate if close enough or if Cholesky has failed already:    \n",
    "            \n",
    "        if ((niter >= options['miniter']) and (rxnorm < options['xtol']) and (rynorm < options['ytol']) \n",
    "            and (rznorm < options['ztol']) and (nubar < options['stol']) ):\n",
    "            break #xyz\n",
    "        if bchofail == True:\n",
    "            break\n",
    "\n",
    "        # Can try Cholesky decomposition every other iteration, but it slows done computation time!    \n",
    "        #if niter % 2 == 0: \n",
    "        \n",
    "        _zsimu, _zsilambda, cho_fac, AQA, Qv, num_cholesky_regularizations, bchofail = solve_qp_torch_jit_set_up_solver(\n",
    "                        options, num_cholesky_regularizations, _zmu, _zlambda, _smu, _slambda, _dvec, \n",
    "                        Fw_Wcsr, Fw_Wtcsr, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N, wtp0v, RXwt, RXtwt, niter, bks=bks)\n",
    "\n",
    "        # TODO: options['nubarfactor'] should be in [0, eps] for small eps since\n",
    "        # nubar (the average of s * z) may be large relative to some elements of s * z (???)\n",
    "        # The parameter sigma deals with this on second iteration (???)\n",
    "        # To avoid these issues, set options['nubarfactor'] = 0.00.\n",
    "        \n",
    "        _rsmu = torch.zeros_like(_xzero)\n",
    "        _rslambda = torch.zeros_like(_q)\n",
    "        \n",
    "        if options['nubarfactor'] != options['nubarfactor'] * 0.00:\n",
    "            assert False, \"PKError: Should not get here. Should have options['nubarfactor'] = 0.00\" \n",
    "            _rsmu -= options['nubarfactor'] * nubar\n",
    "            _rslambda -= options['nubarfactor'] * nubar\n",
    "\n",
    "        dx, dy, _dzmu, _dzlambda, _dsmu, _dslambda = solve_qp_torch_jit_solve(_zmu, _zlambda, _smu, _slambda, \n",
    "                            _zsimu, _zsilambda, Qv, wtp0v, RXwt, RXtwt, AQA, \n",
    "                             Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, bchofail, cho_fac, options, \n",
    "                             bx=-rx, by=-ry, _bzmu=-_rzmu, _bzlambda=-_rzlambda , _bsmu=_rsmu, _bslambda=_rslambda,\n",
    "                            bks=bks)\n",
    "\n",
    "        alpha0 = options['afac']  # options['afac'] = 1.00 for default case\n",
    "        if options['sigma_fac'] != 0.00:\n",
    "            rmin = torch.minimum(torch.minimum((_dsmu / _smu).min(), (_dslambda / _slambda).min()),\n",
    "                                 torch.minimum((_dzmu / _zmu).min(), (_dzlambda / _zlambda).min()))\n",
    "\n",
    "            #print(\"options[sigma_fac'] != 0.00, alpha0 = \", alpha0.item())\n",
    "\n",
    "            if rmin < -1.00: \n",
    "                alpha0 = -options['afac'] / rmin\n",
    "                #print(\"rmin < -1.00 when sigma_fac != 0.00, alpha0 = \", alpha0.item(),)\n",
    "            #print(\"alpha0 = \", alpha0.item())    \n",
    "            \n",
    "            rho = (( ( _smu + alpha0 * _dsmu).dot(_zmu + alpha0 * _dzmu ) \n",
    "                + ( _slambda + alpha0 * _dslambda).dot(_zlambda + alpha0 * _dzlambda) )\n",
    "                   / ( _smu.dot(_zmu) + _slambda.dot(_zlambda) ))\n",
    "\n",
    "            sigma = max(0.00, min(1.00, rho))**options['sigma_exponent']\n",
    "\n",
    "            _rsmu = options['gamma'] * _dsmu * _dzmu - options['sigma_fac'] * sigma * nubar\n",
    "            _rslambda = options['gamma'] * _dslambda * _dzlambda - options['sigma_fac'] * sigma * nubar\n",
    "\n",
    "            eta_fac = 1.00 - options['eta_over_sigma'] * sigma\n",
    "            rx = eta_fac * rx\n",
    "            ry = eta_fac * ry\n",
    "            \n",
    "            #rz = eta_fac * rz\n",
    "\n",
    "            _rzmu = eta_fac * _rzmu\n",
    "            _rzlambda = eta_fac * _rzlambda\n",
    "        else:  # options['gamma'] = 1 for Mehrotra correction!\n",
    "            _rsmu = options['gamma'] * _dsmu * _dzmu - options['nubarfactor'] * nubar\n",
    "            _rslambda = options['gamma'] * _dslambda * _dzlambda - options['nubarfactor'] * nubar\n",
    "\n",
    "        dx, dy, _dzmu, _dzlambda, _dsmu, _dslambda = solve_qp_torch_jit_solve(_zmu, _zlambda, _smu, _slambda, \n",
    "                                _zsimu, _zsilambda, Qv, wtp0v, RXwt, RXtwt, AQA,\n",
    "                                Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, bchofail, cho_fac, options, \n",
    "                                bx=-rx, by=-ry, _bzmu=-_rzmu, _bzlambda=-_rzlambda, _bsmu=_rsmu, _bslambda=_rslambda,\n",
    "                                bks=bks)\n",
    "\n",
    "        xold = x\n",
    "        yold = y\n",
    "        _zmu_old = _zmu\n",
    "        _zlambda_old = _zlambda\n",
    "        _smu_old = _smu\n",
    "        _slambda_old = _slambda\n",
    "\n",
    "        rmin = torch.min(torch.min((_dsmu / _smu).min(), (_dslambda / _slambda).min()), \n",
    "                         torch.min((_dzmu / _zmu).min(), (_dzlambda / _zlambda).min()))\n",
    "\n",
    "        alpha1 = options['one_fac']\n",
    "\n",
    "        if rmin < -1.00:\n",
    "\n",
    "            alpha1 = -options['alpha_fac'] * options['one_fac'] / rmin\n",
    "\n",
    "        alpha1 = torch.min(alpha1, options['max_alpha'])\n",
    "\n",
    "        x = x + alpha1 * dx\n",
    "        y = y + alpha1 * dy\n",
    "        \n",
    "        _zmu = _zmu + alpha1 * _dzmu\n",
    "        _zlambda = _zlambda + alpha1 * _dzlambda\n",
    "        _smu = _smu + alpha1 * _dsmu\n",
    "        _slambda = _slambda + alpha1 * _dslambda\n",
    "        \n",
    "        _zmu = torch.maximum(_zmu, tiny_num)\n",
    "        _zlambda = torch.maximum(_zlambda, tiny_num)\n",
    "        _smu = torch.maximum(_smu, tiny_num)\n",
    "        _slambda = torch.maximum(_slambda, tiny_num)\n",
    "        \n",
    "    # Main algorithm ends here    \n",
    "\n",
    "    # print(torch.cuda.memory_stats())\n",
    "    \n",
    "    #torch.cuda.synchronize()\n",
    "\n",
    "    z = torch.hstack([_zmu, _zlambda])\n",
    "    s = torch.hstack([_smu, _slambda])\n",
    "\n",
    "    return x, y, z, s, wtp0v, nubar, niter, bchofail, num_cholesky_regularizations, rxnorm, rynorm, rznorm, AQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve_qp_torch_jit_finish() calculates useful results in numpy, not pytorch.\n",
    "\n",
    "Needs to be a separate function since torch.jit is not available for numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.jit.ignore  # This function cannot be jitted. Uses numpy.\n",
    "def solve_qp_torch_jit_finish(bk, options, x, y, z, s, wtp0v, _vainv, nubar, niter, bchofail, \n",
    "                              num_cholesky_regularizations, rxnorm, rynorm, rznorm, t0, AQA):\n",
    "    \n",
    "    #torch.cuda.synchronize()\n",
    "    \n",
    "    inputs = bk.qpinputs\n",
    "    \n",
    "    KKT_results = {}\n",
    "    KKT_results['x'] = x.cpu().numpy()  # executed quantity on order (notional dollars), shape (m,)\n",
    "    KKT_results['y'] = y.cpu().numpy()  # market prices for assets as fraction of initial price p0 (wtp0), shape (n,)\n",
    "    KKT_results['z'] = z.cpu().numpy()   # stacked price multipliers (lambda, mu from paper) for orders, shape (2 * m,)\n",
    "    KKT_results['s'] = s.cpu().numpy()   # stacked quantity slack variables x and q-x for order, shape (2 * m,)\n",
    "\n",
    "    KKT_results['xunits'] = _vainv * x.cpu().numpy()   # executed quantity on order (portfolio units), shape (m,)\n",
    "    KKT_results['p'] = (wtp0v * y).cpu().numpy()  # market prices for assets, shape (n,)\n",
    "    \n",
    "    KKT_results['q'] = inputs['q']\n",
    "    KKT_results['order_type'] = inputs['order_type']\n",
    "    KKT_results['constr_order_type'] = inputs['constr_order_type']\n",
    "    KKT_results['b_exch_q_constraint'] = inputs['b_exch_q_constraint']\n",
    "    KKT_results['b_stab_q_constraint'] = inputs['b_stab_q_constraint']\n",
    "    KKT_results['nubar'] = nubar #Old nubar from previous iteration, current nubar is s.dot(z) / m\n",
    "\n",
    "    \n",
    "    # Computation time includes updating KKT_results but not calculating sim_stats and mkt_stats:\n",
    "\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    if options['print_time'] == True: \n",
    "        print(\"dt = \", dt, \", bchofail = \", bchofail)\n",
    "\n",
    "    sim_stats = {}\n",
    "    sim_stats['dt'] = dt  # execution time in seconds\n",
    "    sim_stats['niter'] = niter  # number of iterations when terminated\n",
    "    sim_stats['bmaxiter'] = False\n",
    "    if niter == options['maxiter'] and bchofail == False:\n",
    "        sim_stats['bmaxiter'] = True\n",
    "    sim_stats['bchofail'] = bchofail  # False if cholesky never failed, True if cholesky failed\n",
    "    sim_stats['num_cholesky_regularizations'] = num_cholesky_regularizations  # number of times diagonal augments to make Cholesky work.\n",
    "    sim_stats['rxnorm'] = rxnorm.item()  # supnorm of error in x = order quantities\n",
    "    sim_stats['rynorm'] = rynorm.item()  # supnorm of error in y = prices\n",
    "    sim_stats['rznorm'] = rznorm.item()  # supnorm of error in z = price multipliers\n",
    "    sim_stats['nubar'] = nubar.item()  # slack product z @ s / m, which should be zero at exact solution \n",
    "    sim_stats['pmean_pct'] = KKT_results['y'].mean() * 100.00\n",
    "    sim_stats['pstd_pct'] = KKT_results['y'].std() * 100.00\n",
    "    sim_stats['n_bad_p'] = (np.abs(KKT_results['y'] - 1.00) > 1.00).sum()\n",
    "\n",
    "    b_exch_order = (KKT_results['order_type'] == 0)\n",
    "    b_stab_order = (KKT_results['order_type'] == -1)\n",
    "    _r = np.empty_like(inputs['q'][b_exch_order])\n",
    "    _r[:] = np.inf\n",
    "    np.divide(KKT_results['xunits'][b_exch_order], inputs['q'][b_exch_order], \n",
    "                   out=_r, where=inputs['q'][b_exch_order] != 0.00) \n",
    "    sim_stats['num_exch_full'] = (np.isclose(_r , 1.00, equal_nan=False).sum())\n",
    "\n",
    "    stab_frac = np.zeros_like(inputs['q'][b_stab_order])\n",
    "    np.divide(KKT_results['xunits'][b_stab_order], inputs['q'][b_stab_order], \n",
    "                          out=stab_frac, where=inputs['q'][b_stab_order] > 0.00)\n",
    "    sim_stats['num_stab_full'] = np.isclose(stab_frac, 1.00, equal_nan=False).sum()\n",
    "    sim_stats['num_stab_active'] = (stab_frac > 1.0e-5).sum()\n",
    "    sim_stats['cond_num'] = np.linalg.cond(AQA.cpu().numpy())\n",
    "\n",
    "    # use order book bk to calculate uncleared demand and other variables:\n",
    "    bk.update_demand(KKT_results['p'].reshape(-1))\n",
    "    # Update summary of volume statistics.  This takes some time!\n",
    "    msg, mkt_stats = bk.calculate_volume_stats()\n",
    "    msg = (msg + \", nexq=\" + \"{:.1f}\".format(sim_stats['num_exch_full']) \n",
    "           + \", nstq=\" + \"{:.1f}\".format(sim_stats['num_stab_full']) \n",
    "           + \", nsta=\" + \"{:.1f}\".format(sim_stats['num_stab_active']))\n",
    "    if options['print_mkt_results'] == True:\n",
    "        print(msg, end=\",\")\n",
    "        print(f\"cn={sim_stats['cond_num']:1.2e}\")\n",
    "        \n",
    "    #print(f\"{fW.dt=}, {dt_update_xyzs=}\")    \n",
    "    \n",
    "    #torch.cuda.synchronize()\n",
    "        \n",
    "    return sim_stats, KKT_results, mkt_stats    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve_qp() is the main function to call to solve the quadratic programming problem for market clearing prices and quantities.  The function has three inputs:\n",
    "\n",
    "1. bk is a simulated order book containing information about orders.\n",
    "\n",
    "2. KKT_inputs contains values for quantities x and multipliers zmu, zlambda, smu, slambda used to initialize the algorithm.  This is usually None, in which case the algorithm has two default initialization options. KKT_inputs are not None only in two-step algorithms which start with 32-bit arrays, then shifts to 64-bit arrays in an effort to speed up calculations. Experience shows that 32-bit calculations are not very accurate and crash frequently, but calculations are twice as fast.  Except for testing the concept KKT_inputs is set to None throughout this notebook.\n",
    "\n",
    "3. The function argument options={} is a dictionary containing options governing the estimation strategy. If options are not specified or the dictionary options does not contain a relevant specific option, then default options are used.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.jit.ignore # This function cannot be jitted. Uses numpy\n",
    "def solve_qp(bk, * , KKT_inputs=None, options={}):\n",
    "    \n",
    "    options0 = options.copy()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    (options, dtype, device, n, m, m2, _ph, _mkt_clear, _xzero, _q, _d, Wsx, Wstx, wtp0v, RXwt, RXtwt, _vainv, \n",
    "            Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N, \n",
    "             bks) = (\n",
    "            solve_qp_torch_jit_setup(bk, KKT_inputs=KKT_inputs, options=options0))\n",
    "\n",
    "    #print(\"Start algorithm:\")\n",
    "    #print('Fw_N:', Fw_N)\n",
    "    #print('Fw_M1:', Fw_M1)\n",
    "    ##print('qwts:', qwts.shape)\n",
    "    #print('Fw_indices:', Fw_indices.shape)\n",
    "    #print('Fw_data:', Fw_data.shape)\n",
    "    #print('Fw_data:', Fw_data.shape)\n",
    "    #print('Fw_data4:', Fw_data4.shape)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    #for x in [options, dtype, torch.device(device), KKT_inputs, n, m, m2, c, b, h, \n",
    "    #                        Pv, Wsx, Wstx, wtp0v, RXwt, RXtwt, \n",
    "    #                        Fw_Wcsr, Fw_Wtcsr, Fw_indices, Fw_data, Fw_data4, Fw_M1, Fw_N]:\n",
    "    #    printa(x)\n",
    "    # xxx\n",
    "\n",
    "    if options['bjit'] == True:\n",
    "        #print('bjit', True)\n",
    "        solve_qp_torch_jit_algo_jitted_or_not = torch.jit.script(solve_qp_torch_jit_algo)\n",
    "    else:\n",
    "        #print('bjit', False)\n",
    "        solve_qp_torch_jit_algo_jitted_or_not = solve_qp_torch_jit_algo\n",
    "        \n",
    "    device = torch.device(device)    \n",
    "\n",
    "    if KKT_inputs is not None:\n",
    "        for k in KKT_inputs:\n",
    "            KKT_inputs[k] = torch.as_tensor(KKT_inputs[k], device=device, dtype=dtype)\n",
    "    \n",
    "    x, y, z, s, wtp0v, nubar, niter, bchofail, num_cholesky_regularizations, rxnorm, rynorm, rznorm, AQA = (\n",
    "        solve_qp_torch_jit_algo_jitted_or_not(options, dtype, device, KKT_inputs, \n",
    "                        _ph, _mkt_clear, _xzero, _q, _d, Wsx, Wstx, wtp0v, RXwt, RXtwt, \n",
    "                        Fw_Wcsr, Fw_Wtcsr, Fw_Wcoo, Fw_Wtcoo, Fw_indices, Fw_data, Fw_data4, bks=bks))\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t2 = time.time()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    sim_stats, KKT_results, mkt_stats = solve_qp_torch_jit_finish(bk, options0, x, y, z, s, wtp0v, _vainv,\n",
    "         nubar, niter, bchofail, num_cholesky_regularizations, rxnorm, rynorm, rznorm, t0, AQA)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    t3 = time.time()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    if options['print_overall_time'] == True:\n",
    "        print(f\"\\n{t2-t0}, {t1-t0=}, {t2-t1=}, {t3-t2=}\\n\")\n",
    "    \n",
    "    return sim_stats, KKT_results, mkt_stats    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp2(bk, * , KKT_inputs=None, options32={}, options64={}, bk2=None):\n",
    "    \"\"\"\n",
    "    Solves the quadratic program by running the algorithm twice.  \n",
    "    The first pass should use np.float32; it is faster but less accurate.\n",
    "    The second pass should use np.float64; it is slower but increases accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    default_options32 = {\"b_time_function_calls\" : False, \"b_use_fWqW\" : True, 'b_use_torch_dictionaries' : False, \n",
    "                       'maxiter' : 200, 'miniter' : 3, \n",
    "                       'dtype' : torch.float64, 'device' : 'cuda', 'bjit' : False,\n",
    "                       'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "                       'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e+8,\n",
    "                       'initial_z' : 1.00e-0, 'initial_s' : 1.00e-0,\n",
    "                       'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-8,\n",
    "                      'eta_over_sigma' : 0.00, 'sigma_exponent' : 3, 'sigma_fac' : 0.00, 'afac' : 0.9999,\n",
    "                       'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "                       'one_fac' : 0.99, 'max_alpha' : 0.99, 'alpha_fac' : 0.99, 'alpha_trunc_factor' : 0.900,\n",
    "                       'regeps0' : 1.00e-12, 'regeps0factor' : 100.00, 'regeps0mod' : 1,  'regeps_add_factor' : 1.00e1,\n",
    "                       'regeps1' : 1.00e-11, 'regeps1factor' : 100.00, 'regeps2' : 1.00e-8,\n",
    "                       'print_time' : True, 'print_overall_time' : True, \n",
    "                        'print_volume_each_iteration' : False, 'print_summary_each_iteration' : True, \n",
    "                         'print_mkt_results' : False, \n",
    "                      'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                     'print_cholesky_regularizations' : True\n",
    "                      }\n",
    "\n",
    "    default_options64 = {\"b_time_function_calls\" : False, \"b_use_fWqW\" : True, 'b_use_torch_dictionaries' : False, \n",
    "                        'maxiter' : 200, 'miniter' : 3, \n",
    "                        'dtype' : torch.float64, 'device' : 'cuda', 'bjit' : False,\n",
    "                       'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "                       'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e+8,\n",
    "                       'initial_z' : 1.00e-0, 'initial_s' : 1.00e-0,\n",
    "                       'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-15,\n",
    "                      'eta_over_sigma' : 0.00, 'sigma_exponent' : 3, 'sigma_fac' : 0.00, 'afac' : 0.9999,\n",
    "                       'gamma' : 1.00,  'nubarfactor' : 0.00,\n",
    "                       'one_fac' : 0.99, 'max_alpha' : 0.99, 'alpha_fac' : 0.99, 'alpha_trunc_factor' : 0.900,\n",
    "                       'regeps0' : 1.00e-17, 'regeps0factor' : 10.00, 'regeps0mod' : 3,  'regeps_add_factor' : 1000.00,\n",
    "                       'regeps1' : 1.00e-14, 'regeps2' : 1.00e-5, 'regeps1factor' : 5.00,\n",
    "                       'print_time' : True, 'print_overall_time' : True, \n",
    "                        'print_volume_each_iteration' : False, 'print_summary_each_iteration' : True, \n",
    "                         'print_mkt_results' : False, \n",
    "                       'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                     'print_cholesky_regularizations' : True\n",
    "                      }\n",
    "\n",
    "    if bk2 is None:\n",
    "        bk2 = bk\n",
    "    \n",
    "    #options32 = dict(default_options32, **options32)    \n",
    "\n",
    "    #print(f\"solve_qp2: {dict(default_options32, **options32)=}\")\n",
    "    \n",
    "    sim_stats32, KKT_results32, mkt_stats32 = solve_qp(bk, options=dict(default_options32, **options32))\n",
    "\n",
    "    #options64 = dict(defautl_options64, **options64)\n",
    "    \n",
    "    sim_stats64, KKT_results64, mkt_stats64 = solve_qp(bk2, KKT_inputs=KKT_results32, \n",
    "                                                       options=dict(default_options64, **options64))\n",
    "\n",
    "    return sim_stats32, KKT_results32, mkt_stats32, sim_stats64, KKT_results64, mkt_stats64\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on PK's Results so far:\n",
    "\n",
    "The results show that the base model (b_use_torch_dictionaries == False) is the fastest.\n",
    "With b_use_torch dictionaries, the b_use_fWqW is about 10-30 percent slower, probably due to packaging\n",
    "the orders books from exchange, stabilizing, market for one asset, and pairs trades in different arrays.\n",
    "The fast base model packages all orders into one array and indexes into the array in an error-prone ad hoc manner.\n",
    "We need a cleaner way to index into all the order books at once.\n",
    "\n",
    "The alternative approach (b_use_fWqW == False) is about 50 percent slower \n",
    "because the fWqW bespoke function is replaced by a generic function\n",
    "based on matrix multiplication of sparse matrices by sparse matrices.  \n",
    "This function takes 3-4 times as long as the base case bespoke \n",
    "and about 3 times as long as the bespoke function fWqW.\n",
    "It took a lot of experimentation to make this function as fast as it is.\n",
    "This function can handle portfolios of arbitrary sparse size, not just one or two assets.\n",
    "\n",
    "This b_time_function_calls stuff does not compile with torch.jit.script because jit does not allow timer.\n",
    "To use jit, need to comment out the timing code.  \n",
    "Even if the code is never executed, the jit compiler wants to compile it anyway.\n",
    "(This can be helpful for debugging but is a nuisance for time; \n",
    "could put timing code into a torch.jit.ignore function.)\n",
    "\n",
    "Bottom Line: Need a nice way of having separate order books consistent with the new approach.\n",
    "Need also to stack the order books together programatically, with proper indexing generated on the fly.\n",
    "It should be easy to add and subtract order books.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test solve 1 pass jit\n",
      "\n",
      "times: 0.0009872913360595703 0.0895853042602539 0.4028787612915039\n",
      "i=0, a0=-1.000e+05, a1=-1.000e+05, rx=5.10e+01, ry=3.54e+03, rz=0.00e+00, nubar=1.00e+08\n",
      "i=1, a0=3.657e-01, a1=5.899e-01, rx=2.19e+01, ry=1.52e+03, rz=1.82e-12, nubar=4.29e+07\n",
      "i=2, a0=6.079e-01, a1=8.980e-01, rx=2.95e+00, ry=1.62e+02, rz=1.82e-12, nubar=4.57e+06\n",
      "i=3, a0=9.354e-01, a1=9.888e-01, rx=1.42e-01, ry=1.81e+00, rz=1.82e-12, nubar=5.12e+04\n",
      "i=4, a0=9.904e-01, a1=9.807e-01, rx=3.89e-03, ry=3.50e-02, rz=1.82e-12, nubar=9.90e+02\n",
      "i=5, a0=6.818e-01, a1=8.211e-01, rx=6.74e-04, ry=6.32e-03, rz=1.82e-12, nubar=1.79e+02\n",
      "i=6, a0=6.109e-01, a1=7.459e-01, rx=1.82e-04, ry=1.63e-03, rz=1.82e-12, nubar=4.61e+01\n",
      "i=7, a0=5.582e-01, a1=7.800e-01, rx=4.36e-05, ry=3.68e-04, rz=1.82e-12, nubar=1.04e+01\n",
      "i=8, a0=3.032e-01, a1=4.882e-01, rx=2.36e-05, ry=1.97e-04, rz=1.82e-12, nubar=5.56e+00\n",
      "i=9, a0=4.480e-01, a1=6.073e-01, rx=9.61e-06, ry=7.95e-05, rz=1.82e-12, nubar=2.25e+00\n",
      "i=10, a0=2.477e-01, a1=6.638e-01, rx=3.77e-06, ry=3.01e-05, rz=1.82e-12, nubar=8.51e-01\n",
      "i=11, a0=5.036e-01, a1=5.869e-01, rx=1.56e-06, ry=1.26e-05, rz=1.82e-12, nubar=3.58e-01\n",
      "i=12, a0=3.937e-01, a1=3.398e-01, rx=1.06e-06, ry=8.47e-06, rz=1.82e-12, nubar=2.39e-01\n",
      "i=13, a0=5.211e-01, a1=6.352e-01, rx=3.99e-07, ry=3.14e-06, rz=1.82e-12, nubar=8.90e-02\n",
      "i=14, a0=4.365e-01, a1=5.841e-01, rx=1.74e-07, ry=1.34e-06, rz=1.82e-12, nubar=3.80e-02\n",
      "i=15, a0=3.979e-01, a1=4.931e-01, rx=9.20e-08, ry=6.99e-07, rz=1.82e-12, nubar=1.98e-02\n",
      "i=16, a0=5.269e-01, a1=5.438e-01, rx=4.27e-08, ry=3.23e-07, rz=1.82e-12, nubar=9.13e-03\n",
      "i=17, a0=4.486e-01, a1=6.174e-01, rx=1.66e-08, ry=1.27e-07, rz=1.82e-12, nubar=3.60e-03\n",
      "i=18, a0=4.532e-01, a1=5.542e-01, rx=7.85e-09, ry=5.78e-08, rz=9.09e-13, nubar=1.64e-03\n",
      "i=19, a0=5.196e-01, a1=5.914e-01, rx=3.10e-09, ry=2.40e-08, rz=9.09e-13, nubar=6.80e-04\n",
      "i=20, a0=3.854e-01, a1=6.522e-01, rx=1.17e-09, ry=8.75e-09, rz=1.82e-12, nubar=2.49e-04\n",
      "i=21, a0=4.541e-01, a1=6.924e-01, rx=3.52e-10, ry=2.78e-09, rz=1.82e-12, nubar=7.97e-05\n",
      "i=22, a0=3.724e-01, a1=6.066e-01, rx=1.47e-10, ry=1.13e-09, rz=1.82e-12, nubar=3.29e-05\n",
      "i=23, a0=3.310e-01, a1=7.220e-01, rx=4.88e-11, ry=3.48e-10, rz=1.82e-12, nubar=1.01e-05\n",
      "i=24, a0=4.294e-01, a1=6.945e-01, rx=1.54e-11, ry=1.12e-10, rz=1.82e-12, nubar=3.23e-06\n",
      "i=25, a0=4.191e-01, a1=6.992e-01, rx=4.96e-12, ry=3.82e-11, rz=1.82e-12, nubar=1.02e-06\n",
      "i=26, a0=5.456e-01, a1=7.995e-01, rx=1.11e-12, ry=7.46e-11, rz=1.82e-12, nubar=2.12e-07\n",
      "i=27, a0=7.787e-01, a1=8.263e-01, rx=1.84e-13, ry=1.18e-10, rz=1.82e-12, nubar=3.70e-08\n",
      "i=28, a0=5.995e-01, a1=8.789e-01, rx=2.22e-14, ry=1.09e-11, rz=1.82e-12, nubar=4.64e-09\n",
      "i=29, a0=7.391e-01, a1=8.785e-01, rx=2.66e-15, ry=9.28e-11, rz=1.82e-12, nubar=5.68e-10\n",
      "i=30, a0=7.324e-01, a1=9.147e-01, rx=6.66e-16, ry=4.91e-11, rz=1.82e-12, nubar=4.89e-11\n",
      "i=31, a0=8.950e-01, a1=9.786e-01, rx=6.66e-16, ry=2.00e-11, rz=1.82e-12, nubar=1.05e-12\n",
      "i=32, a0=9.784e-01, a1=9.852e-01, rx=6.66e-16, ry=5.46e-11, rz=9.09e-13, nubar=1.56e-14\n",
      "i=33, a0=9.925e-01, a1=9.884e-01, rx=6.66e-16, ry=3.82e-11, rz=9.09e-13, nubar=1.81e-16\n",
      "dt =  3.188549518585205 , bchofail =  False\n",
      "unclpM=5.6e-07, exchpM=1.1e-02, stabpM=1.8e-09, pairspM=1.5e+05, dv10^6=1.0111e+01, nexq=0.0, nstq=0.0, nsta=4.0,cn=2.15e+08\n",
      "\n",
      "3.1193788051605225, t1-t0=0.8469648361206055, t2-t1=2.272413969039917, t3-t2=0.27947187423706055\n",
      "\n",
      "5 largest and 5 smallest prices:\n",
      "[ 59.16695926  64.11174459  70.35931813  76.88122904  79.70069088\n",
      " 112.02139597 113.20859514 115.60034249 119.98600638 130.62827695]\n",
      "\n",
      "\n",
      "\n",
      "test solve 1 pass no jit unless explicitly set as option\n",
      "\n",
      "Assumptions(N=500, M=1000000, exch_liq_model='mina', exch_epsilon=0.0001, exch_phpl_frac=100.0, stab_max_qv=1e-08, stab_ph_frac=0.7, stab_pl_frac=0.2, fracMA=0.5, subfracMX=0.5, num_size_indexes=5, num_industry_indexes=10, market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, std_num_orders_asset=1.7, std_order_size=1.5, dv_single_asset_orders=10000000.0, std_limit_price=0.1, limit_bias=0.3, avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0, index_prices=100.0, mean_asset_price=100.0, std_asset_price=0.0, invariance_exponent=0.3333333333333333, fraction_buy_orders_asset=0.5, Bs_M=0, Bs_Rmin=1, Bs_Rmax=5, Bs_Wscale=1.0, Bs_std_ph_dollars=1.0, Bd_M=0, Bd_Rmin=20, Bd_Rmax=50, Bd_Wscale=1.0, Bd_std_ph_dollars=1.0, fracMX=0.25, fracM2=0.25, MX=250000, M2=250000, MA=500000, M0=1000, M0s=1000, M1=750000, Mall=1002000, NX=32, NR=532, ew_mkt_index_share=0.05, vw_mkt_index_share=0.75, industry_index_subshare=0.5, ew_size_index_share=0.024999999999999994, vw_size_index_share=0.07499999999999998, ew_industry_index_share=0.024999999999999994, vw_industry_index_share=0.07499999999999998)\n",
      "{'bk_sparsity': {'A0': 1, 'A0s': 1, 'B1': 1, 'B2': 2, 'Bs': 9, 'Bd': 99}, 'b_time_function_calls': False, 'b_use_fWqW': True, 'b_use_torch_dictionaries': True, 'maxiter': 200, 'miniter': 3, 'dtype': torch.float64, 'device': 'cuda', 'bjit': False, 'b_solve_dollars': True, 'num_polish_cho_solve': 0, 'initialize_with_midpoint': True, 'initial_nubar_midpoint': 100000000.0, 'initial_z': 1.0, 'initial_s': 1.0, 'xtol': 0.1, 'ytol': 0.1, 'ztol': 0.1, 'stol': 1e-15, 'eta_over_sigma': 0.2, 'sigma_exponent': 4, 'sigma_fac': 0.2, 'afac': 1.0, 'gamma': 1.0, 'nubarfactor': 0.0, 'one_fac': 1.0, 'max_alpha': 1.0, 'alpha_fac': 0.99, 'max_num_trunc': 10, 'alpha_trunc_factor': 0.1, 'max_num_regeps1': 10, 'max_num_regeps2': 10, 'regeps0': 1e-12, 'regeps0factor': 100.0, 'regeps0mod': 1, 'regeps_add_factor': 10.0, 'regeps1': 1e-11, 'regeps1factor': 100.0, 'regeps2': 1e-08, 'print_time': True, 'print_overall_time': True, 'print_volume_each_iteration': False, 'print_summary_each_iteration': True, 'print_mkt_results': True, 'print_trunc': False, 'print_alpha_trunc_factor': False, 'print_cholesky_regularizations': True}\n",
      "times: 0.0009999275207519531 0.05650782585144043 0.1333305835723877\n",
      "i=0, a0=-1.000e+05, a1=-1.000e+05, rx=5.10e+01, ry=3.54e+03, rz=0.00e+00, nubar=1.00e+08\n",
      "i=1, a0=3.657e-01, a1=5.899e-01, rx=2.19e+01, ry=1.52e+03, rz=9.09e-13, nubar=4.29e+07\n",
      "i=2, a0=6.079e-01, a1=8.980e-01, rx=2.33e+00, ry=1.62e+02, rz=9.09e-13, nubar=4.57e+06\n",
      "i=3, a0=9.354e-01, a1=9.888e-01, rx=3.43e-01, ry=1.81e+00, rz=1.82e-12, nubar=5.12e+04\n",
      "i=4, a0=9.904e-01, a1=9.807e-01, rx=1.01e-02, ry=3.50e-02, rz=1.82e-12, nubar=9.90e+02\n",
      "i=5, a0=6.818e-01, a1=8.211e-01, rx=1.86e-03, ry=6.32e-03, rz=1.82e-12, nubar=1.79e+02\n",
      "i=6, a0=6.109e-01, a1=7.459e-01, rx=4.74e-04, ry=1.63e-03, rz=1.82e-12, nubar=4.61e+01\n",
      "i=7, a0=5.582e-01, a1=7.800e-01, rx=1.08e-04, ry=3.68e-04, rz=1.82e-12, nubar=1.04e+01\n",
      "i=8, a0=3.032e-01, a1=4.882e-01, rx=5.75e-05, ry=1.97e-04, rz=1.82e-12, nubar=5.56e+00\n",
      "i=9, a0=4.480e-01, a1=6.073e-01, rx=2.33e-05, ry=7.95e-05, rz=1.82e-12, nubar=2.25e+00\n",
      "i=10, a0=2.477e-01, a1=6.638e-01, rx=8.81e-06, ry=3.01e-05, rz=1.82e-12, nubar=8.51e-01\n",
      "i=11, a0=5.036e-01, a1=5.869e-01, rx=3.68e-06, ry=1.26e-05, rz=1.82e-12, nubar=3.58e-01\n",
      "i=12, a0=3.937e-01, a1=3.398e-01, rx=2.48e-06, ry=8.47e-06, rz=1.82e-12, nubar=2.39e-01\n",
      "i=13, a0=5.211e-01, a1=6.352e-01, rx=9.27e-07, ry=3.14e-06, rz=1.82e-12, nubar=8.90e-02\n",
      "i=14, a0=4.365e-01, a1=5.841e-01, rx=3.96e-07, ry=1.34e-06, rz=1.82e-12, nubar=3.80e-02\n",
      "i=15, a0=3.979e-01, a1=4.931e-01, rx=2.06e-07, ry=6.99e-07, rz=1.82e-12, nubar=1.98e-02\n",
      "i=16, a0=5.269e-01, a1=5.438e-01, rx=9.47e-08, ry=3.23e-07, rz=1.82e-12, nubar=9.13e-03\n",
      "i=17, a0=4.486e-01, a1=6.174e-01, rx=3.74e-08, ry=1.27e-07, rz=1.82e-12, nubar=3.60e-03\n",
      "i=18, a0=4.532e-01, a1=5.542e-01, rx=1.71e-08, ry=5.78e-08, rz=9.09e-13, nubar=1.64e-03\n",
      "i=19, a0=5.196e-01, a1=5.914e-01, rx=6.88e-09, ry=2.40e-08, rz=9.09e-13, nubar=6.80e-04\n",
      "i=20, a0=3.854e-01, a1=6.522e-01, rx=2.54e-09, ry=8.77e-09, rz=1.82e-12, nubar=2.49e-04\n",
      "i=21, a0=4.541e-01, a1=6.924e-01, rx=7.90e-10, ry=2.77e-09, rz=1.82e-12, nubar=7.97e-05\n",
      "i=22, a0=3.724e-01, a1=6.066e-01, rx=3.32e-10, ry=1.14e-09, rz=1.82e-12, nubar=3.29e-05\n",
      "i=23, a0=3.310e-01, a1=7.220e-01, rx=1.04e-10, ry=3.47e-10, rz=9.09e-13, nubar=1.01e-05\n",
      "i=24, a0=4.294e-01, a1=6.945e-01, rx=3.35e-11, ry=1.11e-10, rz=1.82e-12, nubar=3.23e-06\n",
      "i=25, a0=4.191e-01, a1=6.992e-01, rx=1.06e-11, ry=3.57e-11, rz=1.82e-12, nubar=1.02e-06\n",
      "i=26, a0=5.456e-01, a1=7.995e-01, rx=2.18e-12, ry=2.08e-11, rz=1.82e-12, nubar=2.12e-07\n",
      "i=27, a0=7.787e-01, a1=8.263e-01, rx=3.69e-13, ry=5.46e-11, rz=1.82e-12, nubar=3.70e-08\n",
      "i=28, a0=5.995e-01, a1=8.789e-01, rx=4.73e-14, ry=4.55e-11, rz=1.82e-12, nubar=4.64e-09\n",
      "i=29, a0=7.391e-01, a1=8.785e-01, rx=5.77e-15, ry=1.02e-10, rz=1.82e-12, nubar=5.68e-10\n",
      "i=30, a0=7.324e-01, a1=9.147e-01, rx=6.66e-16, ry=1.29e-10, rz=1.82e-12, nubar=4.89e-11\n",
      "i=31, a0=8.950e-01, a1=9.786e-01, rx=8.88e-16, ry=3.46e-11, rz=1.82e-12, nubar=1.05e-12\n",
      "i=32, a0=9.784e-01, a1=9.852e-01, rx=6.66e-16, ry=7.39e-12, rz=9.09e-13, nubar=1.56e-14\n",
      "i=33, a0=9.925e-01, a1=9.884e-01, rx=6.66e-16, ry=6.00e-12, rz=9.09e-13, nubar=1.81e-16\n",
      "dt =  1.2109670639038086 , bchofail =  False\n",
      "unclpM=5.7e-07, exchpM=1.1e-02, stabpM=1.8e-09, pairspM=1.5e+05, dv10^6=1.0111e+01, nexq=0.0, nstq=0.0, nsta=4.0,cn=2.15e+08\n",
      "\n",
      "1.1414625644683838, t1-t0=0.5039749145507812, t2-t1=0.6374876499176025, t3-t2=0.23927092552185059\n",
      "\n",
      "5 largest and 5 smallest prices:\n",
      "[ 59.16695926  64.11174459  70.35931813  76.88122904  79.70069088\n",
      " 112.02139597 113.20859514 115.60034249 119.98600638 130.62827695]\n",
      "\n",
      "\n",
      "\n",
      "test solve 2 pass\n",
      "\n",
      "i=0, a0=-1.000e+05, a1=-1.000e+05, rx=8.48e-04, ry=4.49e+01, rz=3.96e+00, nubar=9.78e+04\n",
      "i=1, a0=9.800e-01, a1=7.933e-01, rx=1.82e-03, ry=9.49e+00, rz=8.19e-01, nubar=2.09e+04\n",
      "i=2, a0=9.800e-01, a1=7.821e-01, rx=3.97e-03, ry=1.96e+00, rz=1.80e-01, nubar=4.57e+03\n",
      "i=3, a0=9.800e-01, a1=8.467e-01, rx=3.36e-03, ry=2.79e-01, rz=2.78e-02, nubar=7.04e+02\n",
      "i=4, a0=9.800e-01, a1=6.163e-01, rx=1.40e-03, ry=1.26e-01, rz=1.07e-02, nubar=2.68e+02\n",
      "i=5, a0=9.800e-01, a1=7.583e-01, rx=8.13e-04, ry=3.09e+00, rz=3.91e-03, nubar=6.47e+01\n",
      "i=6, a0=9.800e-01, a1=6.355e-01, rx=7.81e-04, ry=2.91e+00, rz=1.95e-03, nubar=2.36e+01\n",
      "i=7, a0=9.800e-01, a1=8.489e-01, rx=7.81e-04, ry=4.78e+00, rz=9.77e-04, nubar=3.56e+00\n",
      "i=8, a0=9.800e-01, a1=6.809e-01, rx=7.81e-04, ry=1.37e-01, rz=9.77e-04, nubar=1.14e+00\n",
      "i=9, a0=9.800e-01, a1=4.595e-01, rx=7.81e-04, ry=2.19e+00, rz=9.77e-04, nubar=6.14e-01\n",
      "i=10, a0=9.800e-01, a1=6.146e-01, rx=7.81e-04, ry=2.94e+00, rz=9.77e-04, nubar=2.37e-01\n",
      "i=11, a0=9.800e-01, a1=4.573e-01, rx=7.81e-04, ry=2.00e+00, rz=9.77e-04, nubar=1.28e-01\n",
      "i=12, a0=9.800e-01, a1=6.375e-01, rx=7.81e-04, ry=1.09e+00, rz=9.77e-04, nubar=4.66e-02\n",
      "i=13, a0=9.800e-01, a1=4.886e-01, rx=6.84e-04, ry=8.04e-01, rz=9.77e-04, nubar=2.38e-02\n",
      "i=14, a0=9.800e-01, a1=6.284e-01, rx=7.81e-04, ry=7.53e-01, rz=9.77e-04, nubar=8.85e-03\n",
      "i=15, a0=9.800e-01, a1=3.718e-01, rx=7.81e-04, ry=8.46e-01, rz=9.77e-04, nubar=5.56e-03\n",
      "i=16, a0=9.800e-01, a1=5.471e-01, rx=4.39e-04, ry=8.97e-01, rz=9.77e-04, nubar=2.52e-03\n",
      "i=17, a0=9.800e-01, a1=4.635e-01, rx=6.84e-04, ry=7.66e-01, rz=9.77e-04, nubar=1.35e-03\n",
      "i=18, a0=9.800e-01, a1=5.112e-01, rx=4.39e-04, ry=5.97e-01, rz=9.77e-04, nubar=6.60e-04\n",
      "i=19, a0=9.800e-01, a1=4.837e-01, rx=4.39e-04, ry=3.71e-01, rz=9.77e-04, nubar=3.41e-04\n",
      "i=20, a0=9.800e-01, a1=3.917e-01, rx=3.17e-04, ry=2.63e-01, rz=9.77e-04, nubar=2.07e-04\n",
      "i=21, a0=9.800e-01, a1=4.135e-01, rx=2.93e-04, ry=1.88e-01, rz=9.77e-04, nubar=1.22e-04\n",
      "i=22, a0=9.800e-01, a1=4.957e-01, rx=2.93e-04, ry=7.03e-02, rz=4.88e-04, nubar=6.13e-05\n",
      "dt =  0.45094895362854004 , bchofail =  False\n",
      "\n",
      "0.445401668548584, t1-t0=0.21114611625671387, t2-t1=0.23425555229187012, t3-t2=0.251802921295166\n",
      "\n",
      "times: 0.0009989738464355469 0.06038808822631836 0.15590739250183105\n",
      "i=0, a0=-1.000e+05, a1=-1.000e+05, rx=2.00e-04, ry=9.32e-02, rz=8.53e-04, nubar=6.13e-05\n",
      "i=1, a0=4.728e-01, a1=4.894e-01, rx=1.04e-04, ry=4.83e-02, rz=4.42e-04, nubar=3.18e-05\n",
      "i=2, a0=5.131e-01, a1=6.059e-01, rx=4.15e-05, ry=1.93e-02, rz=1.77e-04, nubar=1.27e-05\n",
      "i=3, a0=5.060e-01, a1=5.058e-01, rx=2.08e-05, ry=9.68e-03, rz=8.87e-05, nubar=6.37e-06\n",
      "i=4, a0=3.247e-01, a1=7.443e-01, rx=5.96e-06, ry=2.77e-03, rz=2.54e-05, nubar=1.83e-06\n",
      "i=5, a0=3.791e-01, a1=9.329e-01, rx=5.65e-07, ry=2.63e-04, rz=2.41e-06, nubar=1.73e-07\n",
      "i=6, a0=6.768e-01, a1=8.063e-01, rx=1.10e-07, ry=5.14e-05, rz=4.71e-07, nubar=3.38e-08\n",
      "i=7, a0=6.244e-01, a1=8.947e-01, rx=1.20e-08, ry=5.60e-06, rz=5.13e-08, nubar=3.68e-09\n",
      "i=8, a0=7.224e-01, a1=8.876e-01, rx=1.36e-09, ry=6.35e-07, rz=5.82e-09, nubar=4.18e-10\n",
      "i=9, a0=7.697e-01, a1=9.688e-01, rx=4.33e-11, ry=2.02e-08, rz=1.86e-10, nubar=1.33e-11\n",
      "i=10, a0=9.469e-01, a1=9.821e-01, rx=7.73e-13, ry=3.75e-10, rz=3.64e-12, nubar=2.37e-13\n",
      "i=11, a0=9.865e-01, a1=9.870e-01, rx=9.99e-15, ry=6.25e-12, rz=1.82e-12, nubar=3.09e-15\n",
      "i=12, a0=9.958e-01, a1=9.893e-01, rx=8.88e-16, ry=8.73e-11, rz=9.09e-13, nubar=3.33e-17\n",
      "dt =  0.7749669551849365 , bchofail =  False\n",
      "unclpM=1.6e-07, exchpM=1.1e-02, stabpM=1.8e-09, pairspM=1.5e+05, dv10^6=1.0111e+01, nexq=0.0, nstq=0.0, nsta=4.0,cn=2.15e+08\n",
      "\n",
      "0.7604448795318604, t1-t0=0.4983539581298828, t2-t1=0.26209092140197754, t3-t2=0.18120312690734863\n",
      "\n",
      "\n",
      "Total time from both =  1.2259159088134766 \n",
      "\n",
      "5 largest and 5 smallest prices:\n",
      "[ 59.16695926  64.11174459  70.35931813  76.88122904  79.70069088\n",
      " 112.02139597 113.20859514 115.60034249 119.98600638 130.62827695]\n",
      "nthreads =  2 , user_api =  blas\n",
      "After execution: mkl.get_max_threads()=2\n"
     ]
    }
   ],
   "source": [
    "##### @ftimer()    \n",
    "#@torch.compile(backend='inductor') # does not work on Windows yet, for pytorch 2.0.0 and 2.0.1!\n",
    "@fthrds(nthreads=NUM_THREADS, user_api='blas')\n",
    "def test_model():\n",
    "    \n",
    "    c_tiny = Assumptions(N=5, M=50, num_size_indexes=2, num_industry_indexes=2,\n",
    "                    std_num_orders_asset=1.0, std_order_size=1.5, \n",
    "                    avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0)\n",
    "    \n",
    "    c_base = Assumptions(N=500, M=10**6, exch_epsilon=1.00e-4, stab_max_qv=1.00e-8)\n",
    "\n",
    "    c_warmup = Assumptions(N=10, M=10**3)\n",
    "\n",
    "    c_hard = Assumptions(N=500, M=5000, \n",
    "                    exch_epsilon=1.00e-6, exch_phpl_frac=100.0, \n",
    "                    stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, \n",
    "                    num_size_indexes=5, num_industry_indexes=10, \n",
    "                    fracMA=0.20, subfracMX=0.70, \n",
    "                    market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, \n",
    "                    ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, \n",
    "                    std_num_orders_asset=3.0, std_order_size=3.5, \n",
    "                    std_limit_price=0.1, limit_bias=0.3, \n",
    "                    avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0,\n",
    "                    fraction_buy_orders_asset=0.050000,\n",
    "                    dv_single_asset_orders=10000000.00, \n",
    "                    index_prices=100.00, mean_asset_price=100.00, std_asset_price=0.00)\n",
    "\n",
    "    c_harder = Assumptions(N=1000, M=10**6, \n",
    "                    exch_epsilon=1.00e-10, exch_phpl_frac=100.0, \n",
    "                    stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, \n",
    "                    num_size_indexes=50, num_industry_indexes=100, \n",
    "                    fracMA=0.20, subfracMX=0.70, \n",
    "                    market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, \n",
    "                    ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, \n",
    "                    std_num_orders_asset=3.0, std_order_size=3.5, \n",
    "                    std_limit_price=0.1, limit_bias=0.3, \n",
    "                    avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0,\n",
    "                    fraction_buy_orders_asset=0.010000,\n",
    "                    dv_single_asset_orders=10000000.00, \n",
    "                    index_prices=100.00, mean_asset_price=100.00, std_asset_price=0.00)\n",
    "\n",
    "    c_many_assets = Assumptions(N=500, M=10**6, \n",
    "                    exch_epsilon=1.00e-4, exch_phpl_frac=100.0, \n",
    "                    stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, \n",
    "                    num_size_indexes=50, num_industry_indexes=100, \n",
    "                    fracMA=0.20, subfracMX=0.70, \n",
    "                    market_index_share=0.20, size_index_subshare=0.3, ew_mkt_index_subshare=0.30, \n",
    "                    ew_size_index_subsubshare=0.50, ew_industry_index_subsubshare=0.50, ew_size_index_alpha=0.0, \n",
    "                    std_num_orders_asset=3.0, std_order_size=2.0, \n",
    "                    std_limit_price=0.1, limit_bias=0.3, \n",
    "                    avg_ph_minus_pl_bp=10.0, std_ph_minus_pl=2.0,\n",
    "                    fraction_buy_orders_asset=0.50000,\n",
    "                    dv_single_asset_orders=10000000.00, \n",
    "                    index_prices=100.00, mean_asset_price=100.00, std_asset_price=0.00)\n",
    "\n",
    "    #c = Assumptions(exch_epsilon=1.00e+1, stab_max_qv=5.0)\n",
    "    c = c_base\n",
    "    #c = c_tiny\n",
    "    #c = c_hard\n",
    "    #c = c_harder\n",
    "    #c = c_many_assets\n",
    "    \n",
    "    #print(\"c_warmup = \\n\", c_warmup)\n",
    "    #print(\"c = \\n\", c)\n",
    "    \n",
    "    bk = OrderBook(c, nseed=NSEED0 + 11 * 2**25 + 7)\n",
    "    #bk2 = OrderBook(c, nseed=NSEED0 + 1234)\n",
    "    bk2 = None\n",
    "\n",
    "    # Using float32, solution is less accurate but faster by 25 percent for 5K orders, 2X for 50K orders.\n",
    "\n",
    "    options64 = {'bk_sparsity' : {'A0' : 1, 'A0s' : 1, 'B1' : 1, 'B2' : 2, 'Bs' : 9, 'Bd' : 99},\n",
    "                 \"b_time_function_calls\" : False, \"b_use_fWqW\" : True, 'b_use_torch_dictionaries' : True, \n",
    "                 'maxiter' : 200, 'miniter' : 3, \n",
    "                 'dtype' : torch.float64, 'device' : 'cuda', 'bjit' : False,\n",
    "                       'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "               'initialize_with_midpoint' : True, 'initial_nubar_midpoint' : 1.00e+8,\n",
    "               'initial_z' : 1.00e-0, 'initial_s' : 1.00e-0,\n",
    "                   'xtol' : 1.00e-1, 'ytol' : 1.00e-1, 'ztol' : 1.00e-1, 'stol' : 1.00e-15,\n",
    "                   'eta_over_sigma' : 0.2, 'sigma_exponent' : 4, 'sigma_fac' : 0.20, 'afac' : 1.00,\n",
    "                   'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "                   'one_fac' : 1.00, 'max_alpha' : 1.00, 'alpha_fac' : 0.99, \n",
    "                   'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.100,\n",
    "                   'max_num_regeps1' : 10, 'max_num_regeps2' : 10,\n",
    "                   'regeps0' : 1.00e-12, 'regeps0factor' : 100.00, 'regeps0mod' : 1,  'regeps_add_factor' : 1.00e1,\n",
    "                   'regeps1' : 1.00e-11, 'regeps1factor' : 100.00, 'regeps2' : 1.00e-8,\n",
    "                   'print_time' : True, 'print_overall_time' : True, \n",
    "                        'print_volume_each_iteration' : False, 'print_summary_each_iteration' : True, \n",
    "                         'print_mkt_results' : True, \n",
    "                       'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                     'print_cholesky_regularizations' : True\n",
    "                  }\n",
    "\n",
    "    options64_jit = dict(options64, **{'bjit' : False})\n",
    "\n",
    "    options32={\"b_time_function_calls\" : False, \"b_use_fWqW\" : False, 'b_use_torch_dictionaries' : False,\n",
    "             'maxiter' : 50, 'miniter' : 3, \n",
    "               'dtype' : torch.float32, 'device' : 'cuda', 'bjit' : False,\n",
    "               'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "               'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e+8,\n",
    "               'initial_z' : 1.00, 'initial_s' : 1.00,\n",
    "             'xtol' : 1.00e-1, 'ytol' : 1.00e-1, 'ztol' : 1.00e-1, 'stol' : 1.00e-3,    \n",
    "              'eta_over_sigma' : 0.00, 'sigma_exponent' : 3, 'sigma_fac' : 0.00, 'afac' : 0.98,\n",
    "               'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "               'one_fac' : 0.98, 'max_alpha' : 0.98, 'alpha_fac' : 0.98, \n",
    "               'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.200,\n",
    "               'max_num_regeps1' : 10, 'max_num_regeps2' : 10,\n",
    "                 'regeps0' : 1.00e-12, 'regeps0factor' : 100.00, 'regeps0mod' : 1,  'regeps_add_factor' : 1.00e1,\n",
    "                 'regeps1' : 1.00e-11, 'regeps1factor' : 100.00, 'regeps2' : 1.00e-8,\n",
    "                 'print_time' : True, 'print_overall_time' : True, \n",
    "                 'print_volume_each_iteration' : False, 'print_summary_each_iteration' : True, \n",
    "                 'print_mkt_results' : False, \n",
    "                 'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                 'print_cholesky_regularizations' : True\n",
    "              }\n",
    "    \n",
    "    options32_jit = dict(options32, **{'bjit' : True})\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    #print(\"options64_jit = \", options64_jit)\n",
    "    \n",
    "    options64_warmup = {\"b_time_function_calls\" : False, \"b_use_fWqW\" : False, 'b_use_torch_dictionaries' : False, \n",
    "                        'maxiter' : 50, 'miniter' : 0, \n",
    "                        'dtype' : torch.float64, 'device' : 'cuda', 'bjit' : False,\n",
    "               'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "               'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e+8,\n",
    "               'initial_z' : 1.00, 'initial_s' : 1.00,\n",
    "                   'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-16,\n",
    "                  'eta_over_sigma' : 0.00, 'sigma_exponent' : 3, 'sigma_fac' : 0.00, 'afac' : 0.99,\n",
    "                   'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "                   'one_fac' : 0.99, 'max_alpha' : 0.99, 'alpha_fac' : 0.99, \n",
    "                   'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.200,\n",
    "                   'max_num_regeps1' : 10, 'max_num_regeps2' : 10,\n",
    "                   'regeps0' : 1.00e-17, 'regeps0factor' : 100.00, 'regeps0mod' : 3,  'regeps_add_factor' : 1000.00,\n",
    "                   'regeps1' : 1.00e-16, 'regeps1factor' : 100.00, 'regeps2' : 1.00e-8,\n",
    "                   'print_time' : True, 'print_overall_time' : True, \n",
    "                        'print_volume_each_iteration' : False, 'print_summary_each_iteration' : False, \n",
    "                         'print_mkt_results' : False, \n",
    "                       'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                     'print_cholesky_regularizations' : True\n",
    "                  }\n",
    "    \n",
    "    b_test_warmup = False\n",
    "    if b_test_warmup == True:\n",
    "        \n",
    "        print(\"test warmup\\n\")\n",
    "        \n",
    "        bk_warmup = OrderBook(c_warmup, nseed=NSEED0 + 11 * 2**25 + 7)\n",
    "        \n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, options=options32)\n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, KKT_inputs=KKT_results, options=options64)\n",
    "        sim_stats, KKT_results, mkt_stats = solve_qp(bk_warmup, options=options64_warmup)\n",
    "\n",
    "        #print(\"5 largest and 5 smallest prices:\")\n",
    "        #print( np.sort(KKT_results['p'])[np.r_[0:5, -5:0]] )\n",
    "        print(\"\\nWARMUP FINISHED--Run this cell multiple times to obtain times which exclude torch.jit compile times\\n\")\n",
    "    \n",
    "    b_test_solve_1_pass_jit = True\n",
    "    if b_test_solve_1_pass_jit == True:\n",
    "        \n",
    "        print(\"test solve 1 pass jit\\n\")\n",
    "        \n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, options=options32)\n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, KKT_inputs=KKT_results, options=options64)\n",
    "        \n",
    "        # options64_jit uses jit compiler. The 'with' statement tells jit compiler to optimize or not:\n",
    "        # First run seems to warm up gpu; second run seems to recompile first run; third run might optimized second.\n",
    "        # Therefore, best execution time is achieved on third and subsequent runs.\n",
    "        with torch.jit.optimized_execution(True):\n",
    "            for _ in range(1):\n",
    "                sim_stats, KKT_results, mkt_stats = solve_qp(bk, options=options64_jit)\n",
    "\n",
    "        print(\"5 largest and 5 smallest prices:\")\n",
    "        print( np.sort(KKT_results['p'])[np.r_[0:5, -5:0]] )\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    b_test_solve_1_pass = True\n",
    "    if b_test_solve_1_pass == True:\n",
    "\n",
    "        print(\"test solve 1 pass no jit unless explicitly set as option\\n\")\n",
    "        \n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, options=options32)\n",
    "        #sim_stats, KKT_results, mkt_stats = solve_qp(bk, KKT_inputs=KKT_results, options=options64)\n",
    "\n",
    "        print(bk.c)\n",
    "        \n",
    "        print(options64)\n",
    "        \n",
    "        sim_stats, KKT_results, mkt_stats = solve_qp(bk, options=options64)\n",
    "\n",
    "        print(\"5 largest and 5 smallest prices:\")\n",
    "        print( np.sort(KKT_results['p'])[np.r_[0:5, -5:0]] )\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    b_test_solve_2_pass = True\n",
    "    if b_test_solve_2_pass == True:\n",
    "        #try:\n",
    "\n",
    "        print(\"test solve 2 pass\\n\")\n",
    "        \n",
    "        sim_stats32, KKT_results32, mkt_stats32, sim_stats64, KKT_results64, mkt_stats64, = solve_qp2(\n",
    "            bk, options32=options32, options64=options64, bk2=bk2)\n",
    "\n",
    "        print(\"\\nTotal time from both = \", sim_stats32['dt'] + sim_stats64['dt'], \"\\n\")\n",
    "\n",
    "        print(\"5 largest and 5 smallest prices:\")\n",
    "        print( np.sort(KKT_results64['p'])[np.r_[0:5, -5:0]] )\n",
    "\n",
    "        #except:\n",
    "\n",
    "        #print(\"solve_pq2 failed.\")\n",
    "\n",
    "    #print(\"\\nsim_stats:\")\n",
    "    #display(sim_stats)\n",
    "    #print(\"KKT_results:\")\n",
    "    #display(KKT_results)\n",
    "    #print(\"mkt_stats:\")\n",
    "    #display(mkt_stats)\n",
    "    #for p in sorted(KKT_results['p']):\n",
    "    #    print(f\"{p:.2f}\", end=\", \")\n",
    "    \n",
    "    #def f():\n",
    "    #    return solve_qp(bk, \n",
    "    #                options={'print_time' : False, 'print_iteration_results' : False, 'print_mkt_results' : False})\n",
    "\n",
    "    #%timeit f() \n",
    "    #%timeit f() \n",
    "    #%timeit f() \n",
    "    #%timeit f() \n",
    "\n",
    "torch.cuda.empty_cache()    \n",
    "    \n",
    "test_model()    \n",
    "    \n",
    "#with threadpoolctl.threadpool_limits(limits=2, user_api='blas'):\n",
    "#    test_model()    \n",
    "\n",
    "b_use_cProfile = False\n",
    "if b_use_cProfile == True:\n",
    "    with threadpoolctl.threadpool_limits(limits=2, user_api='blas'):\n",
    "        with cProfile.Profile(subcalls=False, builtins=False) as pr:\n",
    "            test_model()\n",
    "            ps = pstats.Stats(pr).strip_dirs().sort_stats('cumtime')\n",
    "            ps.print_stats(40)\n",
    "            print(f\"During execution: {mkl.get_max_threads()=}\")\n",
    "\n",
    "b_use_torch_profiler = False\n",
    "if b_use_torch_profiler == True:\n",
    "    with torch.profiler.profile(\n",
    "       activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]) as prof:\n",
    "           test_model()\n",
    "    prof_output = profres = prof.key_averages()\n",
    "    df = pd.DataFrame({e.key:e.__dict__ for e in prof_output}).T\n",
    "    vns = ['count', 'cpu_time_total', 'cuda_time_total', 'self_cpu_time_total', 'self_cuda_time_total' ]\n",
    "    print(df[vns].sum() / 1000000.00)\n",
    "    display(df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(\n",
    "                           ['cuda_time_total', 'cpu_time_total'], ascending=False))    \n",
    "\n",
    "\n",
    "#display(df)\n",
    "\n",
    "#profres = prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1)\n",
    "#print(f\"{type(profres)=}\")\n",
    "#print(profres)        \n",
    "        \n",
    "        \n",
    "print(f\"After execution: {mkl.get_max_threads()=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assumptions(N=500, M=100000, exch_liq_model='mina', exch_epsilon=0.01, exch_phpl_frac=100.0, stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, fracMA=0.5, subfracMX=0.5, num_size_indexes=5, num_industry_indexes=10, market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, std_num_orders_asset=1.7, std_order_size=1.5, dv_single_asset_orders=10000000.0, std_limit_price=0.1, limit_bias=0.3, avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0, index_prices=100.0, mean_asset_price=100.0, std_asset_price=0.0, invariance_exponent=0.3333333333333333, fraction_buy_orders_asset=0.5, Bs_M=0, Bs_Rmin=1, Bs_Rmax=5, Bs_Wscale=1.0, Bs_std_ph_dollars=1.0, Bd_M=0, Bd_Rmin=20, Bd_Rmax=50, Bd_Wscale=1.0, Bd_std_ph_dollars=1.0, fracMX=0.25, fracM2=0.25, MX=25000, M2=25000, MA=50000, M0=1000, M0s=0, M1=75000, Mall=101000, NX=32, NR=532, ew_mkt_index_share=0.05, vw_mkt_index_share=0.75, industry_index_subshare=0.5, ew_size_index_share=0.024999999999999994, vw_size_index_share=0.07499999999999998, ew_industry_index_share=0.024999999999999994, vw_industry_index_share=0.07499999999999998)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Assumptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(\n",
    "    ['cuda_time_total', 'cpu_time_total'], ascending=False))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(df[['key', 'cpu_time_total', 'cuda_time_total', 'count', 'node_id', 'is_async', 'is_remote',  'self_cpu_time_total', 'self_cuda_time_total', 'input_shapes', 'stack', 'scope', 'cpu_memory_usage',\n",
    "       'cuda_memory_usage', 'self_cpu_memory_usage', 'self_cuda_memory_usage', 'cpu_children', 'cpu_parent', 'device_type', 'is_legacy', 'flops']].sort_values('cpu_time_total'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(profres)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({e.key:e.__dict__ for e in prof.key_averages()}).T\n",
    "df[['count', 'cpu_time_total', 'cuda_time_total']].sort_values(['cuda_time_total', 'cpu_time_total'], ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(Assumptions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations class\n",
    "\n",
    "The next cell defines the Simulations class. The class contains dictionaries of parameter settings which can be used to generate different kinds of simulations. The parameter settings can be referred to by string names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Simulations:\n",
    "\n",
    "    def __init__(self, name_prefix='sim'):\n",
    "\n",
    "        # dictionary of dictionaries defining a dictionary of parameter settings for each difficulty level:\n",
    "        # To implement simulations with different parameter settings, add a new dictionary here:\n",
    "\n",
    "        self.name_prefix= name_prefix\n",
    "        \n",
    "        # These are options for the quadratic programming algorithm:\n",
    "        self.options = {'b_use_torch_dictionaries' : False, 'maxiter' : 200, 'miniter' : 3,\n",
    "                        'dtype' : torch.float64, \n",
    "                        'device' : 'cuda' if B_USE_GPU == True else 'cpu',\n",
    "                        'bjit': False, \n",
    "                       'b_solve_dollars' : True,  'num_polish_cho_solve' : 0,\n",
    "                       'initialize_with_midpoint' : False, 'initial_nubar_midpoint' : 1.00e8,\n",
    "                       'initial_z' : 1.00e-0, 'initial_s' : 1.00e-0,\n",
    "                       'xtol' : 1.00e-2, 'ytol' : 1.00e-2, 'ztol' : 1.00e-2, 'stol' : 1.00e-15,\n",
    "                       'eta_over_sigma' : 0.2, 'sigma_exponent' : 4, 'sigma_fac' : 0.20, 'afac' : 1.00,\n",
    "                       'gamma' : 1.00, 'nubarfactor' : 0.00,\n",
    "                       'one_fac' : 1.00, 'max_alpha' : 1.00, 'alpha_fac' : 0.99, \n",
    "                       'max_num_trunc' : 10, 'alpha_trunc_factor' : 0.100,\n",
    "                       'max_num_regeps1' : 10, 'max_num_regeps2' : 10,\n",
    "                       'regeps0' : 1.00e-12, 'regeps0factor' : 100.00, 'regeps0mod' : 1,  'regeps_add_factor' : 1.00e1, \n",
    "                       'regeps1' : 1.00e-15, 'regeps1factor' : 10.00, 'regeps2' : 1.00e-8,\n",
    "                       'print_time' : False, 'print_overall_time' : False, \n",
    "                        'print_volume_each_iteration' : False, 'print_summary_each_iteration' : False, \n",
    "                         'print_mkt_results' : False, \n",
    "                       'print_trunc' : False, 'print_alpha_trunc_factor' : False,\n",
    "                       'print_cholesky_regularizations' : False\n",
    "                          }\n",
    "        \n",
    "        self.dd_difficulty = {\n",
    "                'base' : {},\n",
    "                'base_no_stab' :{'stab_max_qv' : 0.00},\n",
    "                'base_small_epsilon' : {'exch_epsilon' : 1.00e-16},\n",
    "                'base_mina' : {'exch_liq_model' : 'mina'},\n",
    "                'base_pete' : {'exch_liq_model' : 'pete'},\n",
    "                'base_eric' : {'exch_liq_model' : 'eric'},\n",
    "                'low' : {'fracMA' : 0.05, 'subfracMX' : 0.05, 'num_size_indexes' : 2, 'num_industry_indexes' : 2,\n",
    "                         'market_index_share' : 0.05, 'size_index_subshare' : 0.05, \n",
    "                         'ew_mkt_index_subshare' : 0.05,\n",
    "                         'ew_size_index_subsubshare' : 0.05, 'ew_industry_index_subsubshare' : 0.05,\n",
    "                         'avg_ph_minus_pl_bp' : 0.01, 'std_ph_minus_pl' : 0.10, 'std_order_size' : 0.10, \n",
    "                          'std_num_orders_asset' : 0.10, \n",
    "                         'std_limit_price' : 0.01, 'limit_bias' : 0.01, \n",
    "                         'std_asset_price' : 0.0001, 'fraction_buy_orders_asset' : 0.10},\n",
    "                'high' : {'fracMA' : 0.95, 'subfracMX' : 0.95, 'num_size_indexes' : 50, 'num_industry_indexes' : 50,\n",
    "                         'market_index_share' : 0.95,  'size_index_subshare' : 0.95, \n",
    "                          'ew_mkt_index_subshare' : 0.95,\n",
    "                          'ew_size_index_subsubshare' : 0.95, 'ew_industry_index_subsubshare' : 0.95, \n",
    "                         'avg_ph_minus_pl_bp' : 100.00, 'std_ph_minus_pl' : 3.00, 'std_order_size' : 3.00, \n",
    "                          'std_num_orders_asset' : 3.00, 'std_limit_price' : 1.00, 'limit_bias' : 1.00, \n",
    "                          'std_asset_price' : 3.00, 'fraction_buy_orders_asset' : 0.95},\n",
    "                'hard' : {'fracMA' : 0.05, 'subfracMX' : 0.95, 'num_size_indexes' : 50, 'num_industry_indexes' : 50,\n",
    "                         'market_index_share' : 0.95,   'ew_mkt_index_subshare' : 0.95,\n",
    "                          'ew_size_index_subsubshare' : 0.95, 'ew_industry_index_subsubshare' : 0.95, \n",
    "                         'avg_ph_minus_pl_bp' : 0.01, 'std_ph_minus_pl' : 3.00, 'std_order_size' : 3.00, \n",
    "                          'std_num_orders_asset' : 0.10, 'std_limit_price' : 0.01, 'limit_bias' : 0.10, \n",
    "                          'std_asset_price' : 3.00, 'fraction_buy_orders_asset' : 0.95},\n",
    "                'hard_tiny' : {'fracMA' : 0.10, 'subfracMX' : 0.90, 'num_size_indexes' : 2, 'num_industry_indexes' : 2,\n",
    "                         'market_index_share' : 0.95, \n",
    "                         #'ew_size_index_subsubshare' : 0.50, 'ew_industry_index_subsubshare' : 0.50, \n",
    "                         'avg_ph_minus_pl_bp' : 0.10, 'std_ph_minus_pl' : 4.00, 'std_order_size' : 3.00, \n",
    "                          'std_num_orders_asset' : 3.00, 'std_limit_price' : 1.00, 'std_asset_price' : 3.00, \n",
    "                         'fraction_buy_orders_asset' : 0.10},\n",
    "                }\n",
    "        \n",
    "        self.dd_difficulty['high_no_stab'] = {**self.dd_difficulty['high'], \n",
    "                                                    **self.dd_difficulty['base_no_stab']}\n",
    "        \n",
    "        self.dd_difficulty['low_no_stab'] = {**self.dd_difficulty['low'], \n",
    "                                                    **self.dd_difficulty['base_no_stab']}\n",
    "\n",
    "        self.dd_difficulty['base_small'] = {'N' : 100, 'M' : 5000}\n",
    "        \n",
    "        self.dd_difficulty['high_small'] = {**self.dd_difficulty['high'], \n",
    "                                                    **self.dd_difficulty['base_small']}\n",
    "        \n",
    "        self.dd_difficulty['easy_small'] = {**self.dd_difficulty['low'], \n",
    "                                                    **self.dd_difficulty['base_small']}\n",
    "        \n",
    "        self.dd_difficulty['high_small_epsilon'] = {**self.dd_difficulty['high'], \n",
    "                                                    **{'exch_epsilon' : 1.0e-16}}\n",
    "\n",
    "        # dictionary of dictionaries defing size parameters for each size setting:\n",
    "        # These settings override the settings in dd_difficulty.\n",
    "        # To implemant different size settings, add a new dictionary here.\n",
    "        self.dvd_change_few = {\n",
    "                'none' : [dict()],\n",
    "                 'tiny' : [{'N' : 10, 'M' : 10000}],\n",
    "                 'small' :  [{'N' : 500, 'M' : 30000}],\n",
    "                 'medium' : [{'N' : 1000, 'M' : 100000}],\n",
    "                 'large' : [{'N' : 3000, 'M' : 1000000}],\n",
    "                'epsilon' : [{'exch_epsilon' : x} for x in [1.00e-16, 1.00e-4, 1.00e+8]]\n",
    "                  }\n",
    "\n",
    "        # Dictionary of list of dictionaries defining changes to make in parameter settings:\n",
    "        # For each dictionary in a list, the parameter setting override the settings in dd_difficulty and dvd_change_few,\n",
    "        # then run simulations for each dictionary in the list.\n",
    "        \n",
    "        dbase = dataclasses.asdict(Assumptions())\n",
    "        \n",
    "        self.dvd_change_many = {\n",
    "            'none' : [dict()],\n",
    "            'epsilon_mina' : [{'exch_epsilon' : x} for x in [1.00e-16, 1.00e-8, \n",
    "                  1.00e-6, 1.00e-4, 1.00e-0, 1.00e+4, 1.00e+8]],\n",
    "            'f_ex_liq' : [{'exch_epsilon' : x} for x in [1.00e-20, 1.00e-12, 1.00e-10, 1.00e-8, \n",
    "                  1.00e-6, 1.00e-4, 1.00e-2, 1.00e-0, 1.00e+2, 1.00e+4, 1.00e+6, 1.00e+8, 1.00e+10, 1.00e+12, 1.00e+15]],\n",
    "            'max_v_fr' : [{'exch_phpl_frac' : x} for x in [1.00e-1, 1.00e-0, 1.00e+1, 1.00e+2, 1.00e+3, 1.00e6]],\n",
    "            'max_v_fr_small' : [{'exch_phpl_frac' : x} for x in [1.00e-0, 1.00e+2]],\n",
    "            'high1by1' : ([{vn : self.dd_difficulty['high_small_epsilon'][vn]} \n",
    "                               for vn in self.dd_difficulty['high_small_epsilon']]),\n",
    "            'hard1by1tiny' : [{vn : self.dd_difficulty['hard_tiny'][vn]} for vn in self.dd_difficulty['hard_tiny']],\n",
    "            'low1by1' : [{vn : self.dd_difficulty['low'][vn]} for vn in self.dd_difficulty['low']],\n",
    "            'base1by1' : [{vn : dbase[vn]} for vn in self.dd_difficulty['hard']],\n",
    "                                }    \n",
    "\n",
    "        self.dvd_change_many['high_and_easy'] = (self.dvd_change_many['high1by1'] \n",
    "                                                 + self.dvd_change_many['low1by1'])\n",
    "        self.dvd_change_many['hard_tiny_and_easy'] = (self.dvd_change_many['hard1by1tiny'] \n",
    "                                                 + self.dvd_change_many['low1by1'])\n",
    "\n",
    "        both_fracs = []\n",
    "        for x in self.dvd_change_many['f_ex_liq']:\n",
    "            for y in self.dvd_change_many['max_v_fr']:\n",
    "                both_fracs.append({**x, **y})\n",
    "        self.dvd_change_many['both_fracs'] = both_fracs\n",
    "\n",
    "        both_fracs_small = []\n",
    "        for x in self.dvd_change_many['epsilon_mina']:\n",
    "            for y in self.dvd_change_many['max_v_fr_small']:\n",
    "                both_fracs_small.append({**x, **y})\n",
    "        self.dvd_change_many['epsilon2_mina'] = both_fracs_small\n",
    "        \n",
    "        self.dvd_change_many['eric'] = []\n",
    "        for n in [500, 1000, 3000]:\n",
    "            for m in [30000, 100000, 1000000]:\n",
    "                self.dvd_change_many['eric'].append({'N' : n, 'M' : m})\n",
    "        \n",
    "        self.dvd_change_many['eric_small'] = []\n",
    "        for n in [500, 1000]:\n",
    "            for m in [30000, 100000]:\n",
    "                self.dvd_change_many['eric_small'].append({'N' : n, 'M' : m})\n",
    "\n",
    "        #for dd in [dd_difficulty, dvd_change_few, dvd_one_change]:\n",
    "        #    #print(dd, \"\\n\")\n",
    "        #    for d in dd:\n",
    "        #        print(d, \" = \", dd[d], \"\\n\")\n",
    "\n",
    "        self.fp_csv = None  # filename for most recent simulation results\n",
    "        self.d_csv = {}  # List of filenames for saved comprehensive simulation results\n",
    "        self.fp_latex_table = None # filename for most recent latex table\n",
    "        self.d_latex_table = {}  # List of filenames for saved tables\n",
    "\n",
    "    ########################################\n",
    "\n",
    "    def __call__(self, nreps, difficulty, change_few, change_many, nseed0, name_suffix=None, num_print=NUM_PRINT):    \n",
    "        \"\"\"\n",
    "        Perform simulations for different sets of parameter values:\n",
    "\n",
    "        Usage:\n",
    "        \n",
    "        nreps = 5\n",
    "        difficulty = ['high', 'low', 'hard_tiny']\n",
    "        change_few = ['tiny', 'small']\n",
    "        change_many = ['low1by1', 'high1by1']\n",
    "        sim = Simulations()\n",
    "        nseed = 1234\n",
    "        df = sim(nreps, difficulty, change_few, change_many, 1234)\n",
    "\n",
    "        In this example, suppose (perhaps counterfactual) 'low1by1' has 10 dictionaries of settings \n",
    "        and 'high1by1' has 5 dictionaries of settings.\n",
    "        The total number of simulations for each rep is 3 x 2 x (10 + 5) = 90.\n",
    "        All 90 simulations use the same seed for each rep. \n",
    "        This makes orders the same if relevant parameters are not changed.\n",
    "        The string names of dictionaries in the lists difficulty, size, and changes must be defined in __init__(self).\n",
    "        If different parameter settings are required, __init__(self) should be modified \n",
    "        by adding new parameter settings with new string names. \n",
    "        Alternatively, new cases may be added on the fly.\n",
    "        \n",
    "        With nreps = 5, the function call simulates 90 * 5 = 450 order books \n",
    "        and calculates market clearing prices and quantities.\n",
    "        Two rows of data are printed for each order book and call to solve_qp().\n",
    "        Inputs and results of all simulations are put into a dataframe df, \n",
    "        which is optionally saved to disk as a csv file.\n",
    "        The most useful summary statistics are displayed.\n",
    "        \n",
    "        For each dictionary in difficulty, each dictionary in size, and each dictionary in changes,\n",
    "        assumptions are generated by modifying difficulty based on size, then modifying the result base on changes.\n",
    "        The names difficulty, size, and changes are merely suggestive; size can modify any parameters, as can changes. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print(\"nreps = \", nreps)\n",
    "        print(\"difficulty = \", difficulty)\n",
    "        print(\"change_few = \", change_few)\n",
    "        print(\"change_many = \", change_many)\n",
    "\n",
    "        # Put output in a list of dictionaries, with one dictionary of output results for each simulation: \n",
    "        list_of_dicts = []\n",
    "\n",
    "        # Looping over nreps first mixes up the simulations so less distorted by other things happening on computer:\n",
    "        b_print_assumptions_once = True\n",
    "        for i in tqdm.tqdm(range(nreps)):\n",
    "            print_counter = 0\n",
    "            b_print_output = i < num_print or i >= nreps - num_print\n",
    "            if b_print_output:\n",
    "                print(\"\\ni = \", i)\n",
    "            for diff in difficulty:\n",
    "                if b_print_output:\n",
    "                    print(\"difficulty = \", diff, \" = \", self.dd_difficulty[diff])\n",
    "                for cf in change_few:\n",
    "                    for sz in self.dvd_change_few[cf]: \n",
    "                        #print(\"change_few = \", sz, \" = \", self.dd_change_few[sz])\n",
    "                        if b_print_output:\n",
    "                            print(\"change_few = \", sz)\n",
    "                        bfirst = True\n",
    "                        for chngs in change_many:\n",
    "                            #print(dvd_change_many[chngs])\n",
    "                            for d in self.dvd_change_many[chngs]:\n",
    "                                # The dictionary dall contains the simulation parameters actually used.\n",
    "                                # It is constructed by starting with self.dd_difficulty[diff],\n",
    "                                # replacing parameters with parameters in self.dvd_change_few[cf],\n",
    "                                # then replacing parameters with parameters in d, \n",
    "                                # which is a dictionary in self.dvd_change_many[chngs]\n",
    "                                #dall = {**self.dd_difficulty[diff], **self.dvd_change_few[cf], **d}\n",
    "                                dall = {**self.dd_difficulty[diff], **sz, **d}\n",
    "                                if b_print_output:\n",
    "                                    print(\"self.dd_difficulty[diff]= \", self.dd_difficulty[diff])\n",
    "                                    print(\"sz = \", sz)\n",
    "                                    print (\"d = \", d)\n",
    "                                # Define a new instance of assumption class, \n",
    "                                # which uses the same seed for each parameter setting in dall\n",
    "                                # print(\"dall = \", dall)\n",
    "                                c = Assumptions(**dall)\n",
    "                                # print(\"asdf = \", c)\n",
    "                                if b_print_output and b_print_assumptions_once == True:\n",
    "                                    b_print_assumptions_once = False\n",
    "                                    print(\"Assumptions = \", c, \"\\n\")\n",
    "                                if b_print_output and bfirst == True:\n",
    "                                    if b_print_output:\n",
    "                                        print(i, diff, sz)\n",
    "\n",
    "                                    #for vn in d.keys():\n",
    "                                    #        print(f\"{vn}, \", end = \"\")\n",
    "                                    #print(\"\")\n",
    "\n",
    "                                bfirst = False\n",
    "                                if b_print_output:\n",
    "                                    print(\"changes = \", chngs, \" = \", d)\n",
    "                                b_print_output = False\n",
    "\n",
    "                                #for vn in d.keys():\n",
    "                                #    #print(f\"{vn} = {d[vn] : .2e}\", end = \", \")\n",
    "                                #    print(f\"{d[vn] : .2e}\", end = \", \")\n",
    "\n",
    "                                nseed = nseed0 + i * (2**25 + 1)\n",
    "                                bk = OrderBook(c, nseed)\n",
    "                                sim_stats, KKT_results , mkt_stats = solve_qp(bk, options=self.options)\n",
    "\n",
    "                                sim_stats['nseed'] = nseed\n",
    "                                sim_stats['i'] = i\n",
    "                                sim_stats['difficulty'] = diff\n",
    "                                sim_stats['ch_few'] = cf\n",
    "                                sim_stats['ch_many'] = chngs\n",
    "                                dl = list(d)\n",
    "                                sim_stats['num_changes'] = len(chngs)\n",
    "                                #assert len(dl) == 1, \"PKError: Dictionary should have only one parameter value!\"\n",
    "                                #sim_stats['ch_vn0'] = '.'\n",
    "                                #sim_stats['ch_vn1'] = '.'\n",
    "                                #sim_stats['ch_value0'] = np.nan\n",
    "                                #sim_stats['ch_value1'] = np.nan\n",
    "                                for j in range(2):\n",
    "                                    try: \n",
    "                                        vn = dl[j]\n",
    "                                        #print(vn)\n",
    "                                        sim_stats['ch_vn' + str(j)] = vn\n",
    "                                        #print('success 2')\n",
    "                                        sim_stats['ch_value' + str(j)] = d[vn]\n",
    "                                        #print('success 3')\n",
    "                                    except: \n",
    "                                        sim_stats['ch_vn' + str(j)] = 'none'\n",
    "                                        sim_stats['ch_value' + str(j)] = np.nan\n",
    "\n",
    "                                #sim_stats['change_parameter'] = vn\n",
    "                                #sim_stats['change_value'] = d[vn]\n",
    "\n",
    "                                dc = dataclasses.asdict(c)\n",
    "                                output = {**sim_stats, **mkt_stats, **dc, **self.options}\n",
    "\n",
    "                                # Assert that there are no name clashes in dictionaries:\n",
    "                                # Alternatively, the dictionaries could be defined with distinct prefixes\n",
    "                                if i == 0:\n",
    "                                    #print(\"\\nsim_stats:\" , sim_stats.keys())\n",
    "                                    #print(\"\\nmkt_stats:\" , mkt_stats.keys())\n",
    "                                    #print(\"\\ndc:\" , dc.keys())\n",
    "                                    #print(\"\\noptions:\" , self.options.keys(), \"\\n\")\n",
    "                                    #print(\"xxx\", sim_stats.keys() & mkt_stats.keys(), \"\\n\")\n",
    "\n",
    "                                    assert (sim_stats.keys() & mkt_stats.keys()) == set(), \"PKError: Keys should be unique.\"\n",
    "                                    assert (sim_stats.keys() & dc.keys()) == set(), \"PKError: Keys should be unique.\"\n",
    "                                    assert (sim_stats.keys() & self.options.keys()) == set(), \"PKError: Keys should be unique.\"\n",
    "                                    assert (mkt_stats.keys() & dc.keys()) == set(), \"PKError: Keys should be unique.\"\n",
    "                                    assert (mkt_stats.keys() & self.options.keys()) == set(), \"PKError: Keys should be unique.\"\n",
    "                                    assert dc.keys() & self.options.keys() == set(), \"PKError: Keys should be unique.\"\n",
    "\n",
    "                                #stats_to_print =[vn]\n",
    "                                stats_to_print =list(d)\n",
    "\n",
    "                                # if stats_to_print != []:\n",
    "                                # b_num_print = True\n",
    "                                # num_print is the number of i's that are printed, and the number of results for each i\n",
    "                                if (i < num_print or i >= nreps - num_print) and print_counter < num_print:\n",
    "                                    print(f\"dt={output['dt']:7.4}\", end=\", \")\n",
    "                                    print(f\"ucpM={output['unclpM']:.2e}\", end=\", \")\n",
    "                                    print(f\"expM={output['exchpM']:.2e}\", end= \", \")\n",
    "                                    print(f\" it={output['niter']}\", end=\", \")\n",
    "                                    print(f\"f={output['bchofail']}\", end=\", \")\n",
    "                                    print(f\"ch={output['num_cholesky_regularizations']}\", end=\", \")\n",
    "                                    print(f\"pm={output['pmean_pct']: .2f}\", end=\", \")\n",
    "                                    print(f\"pstd={output['pstd_pct'] : .2f}\", end=\", \")\n",
    "                                    print(f\"exq={output['num_exch_full']}\", end=\", \")\n",
    "                                    print(f\"stq={output['num_stab_full']}\", end=\", \")\n",
    "                                    print(f\"stac={output['num_stab_active']}\", end=\"\")\n",
    "                                    print(\"\")\n",
    "                                    print_counter += 1\n",
    "\n",
    "                                #print(f\"{KKT_results['y']=}\")  # Prices as fraction of p0\n",
    "                                \n",
    "                                #if i==0:\n",
    "                                #    for k in output:\n",
    "                                #        print(k, type(output[k]))\n",
    "\n",
    "                                list_of_dicts.append(output)    \n",
    "\n",
    "        # Transpose the list of one dictionary per simulation into a dictionary of one list per simulation variable:                    \n",
    "        #data = transpose_list_of_dictionaries(list_of_dicts)\n",
    "        #df_sim = pd.DataFrame(data)\n",
    "        df_sim = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "        # The dataframe df has complete simulation data.  Define vns as most useful variable names to display:\n",
    "        # vns = ['i', 'dt', 'unclpM', 'exchpM', 'niter', 'bchofail', 'num_cholesky_regularizations'] + stats_to_print\n",
    "        #display(df[vns].columns)\n",
    "        #display(self.df_sim[vns].head())\n",
    "        #display(self.df_sim[vns].tail())\n",
    "\n",
    "        ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "\n",
    "        if name_suffix != None:\n",
    "            self.fp_sim_csv = CSV_PATH + self.name_prefix + \"_\" + name_suffix + \"_\" + ts + \".csv\"  \n",
    "            df_sim.to_csv(self.fp_sim_csv, index=False)\n",
    "            self.d_csv['name_suffix' + \"_\" + ts] = self.fp_sim_csv  # Dictionary of filenames for all saved simulations\n",
    "            print(\"Simulation data save to \", self.fp_sim_csv)\n",
    "\n",
    "        ks = set()    \n",
    "        for cf in change_few:\n",
    "            for sz in self.dvd_change_few[cf]:\n",
    "                #ks = ks | set(self.dd_change_few[sz].keys())\n",
    "                ks = ks | set(sz.keys())\n",
    "            \n",
    "        #print(\"xxx ks = \", type(ks), ks)    \n",
    "\n",
    "        self.ts = ts\n",
    "        self.ks = ks    \n",
    "        self.difficulty = difficulty\n",
    "        self.change_few = change_few\n",
    "        self.change_many = change_many\n",
    "        self.nseed0 = nseed0\n",
    "        self.name_suffix = name_suffix\n",
    "        self.df_sim = df_sim\n",
    "\n",
    "        self.dfg = self.make_table(tbl_name=self.name_suffix)    \n",
    "        \n",
    "        return self.df_sim\n",
    "\n",
    "    ########################################\n",
    "\n",
    "    def make_table(self, tbl_name=None):\n",
    "\n",
    "        ks = self.ks\n",
    "        \n",
    "        #print(\"ks = \", type(ks), ks)\n",
    "        \n",
    "        df = self.df_sim\n",
    "\n",
    "        dfm = df.copy()\n",
    "\n",
    "        pd.options.display.float_format = '{:.2e}'.format\n",
    "        \n",
    "        # Define new variables here, except for ones for which mean will be calculated:\n",
    "\n",
    "        dfm['dt_med'] = dfm['dt']\n",
    "        dfm['dt_std'] = dfm['dt']\n",
    "        dfm['niter_med'] = dfm['niter']\n",
    "        dfm['niter_max'] = dfm['niter']\n",
    "        dfm['p'] = dfm['pmean_pct']\n",
    "        dfm['p_std'] = dfm['pstd_pct']\n",
    "        dfm['count'] = np.ones_like(dfm['dt'].to_numpy())\n",
    "        dfm['dt_max'] = dfm['dt']\n",
    "        dfm['dt_min'] = dfm['dt']\n",
    "        dfm['unclpM_max'] = dfm['unclpM']\n",
    "        dfm['nchreg'] = dfm['num_cholesky_regularizations']\n",
    "        dfm['exchpM_std'] = dfm['exchpM']\n",
    "        dfm['exchpM_med'] = dfm['exchpM']\n",
    "        dfm['exchpM_max'] = dfm['exchpM']\n",
    "        dfm['exchpM_min'] = dfm['exchpM']\n",
    "        dfm['condnum_med'] = dfm['cond_num']\n",
    "\n",
    "        vns = ['difficulty', 'ch_few', 'ch_many', 'ch_vn0', 'ch_value0']         \n",
    "\n",
    "        # Add keys from ks = dd_change_few (default) as specific columns:\n",
    "        vns = vns + list(ks)\n",
    "\n",
    "        #vns = vns + ['ch_vn0', 'ch_value0',\n",
    "        #       'dt', 'std_dt', 'niter', 'unclpM', 'exchpM', 'stabpM',\n",
    "        #       'pmean_pct', 'pstd_pct', \n",
    "        #       'num_exch_full', 'num_stab_full', 'num_stab_active', 'count',\n",
    "        #       'max_dt', 'max_iter', 'max_unclpM', 'bchofail', 'bmaxiter', \n",
    "        #       'n_bad_p', 'nchreg', 'dvM', 'cond_num']\n",
    "\n",
    "        #vns = ['difficulty', 'size', 'changes', 'ch_vn0', 'ch_value0', 'ch_vn1', 'ch_value1', \n",
    "        #       'dt', 'std_dt', 'niter', 'unclpM', 'exchpM',\n",
    "        #       'pmean_pct', 'pstd_pct', 'num_exch_full']\n",
    "\n",
    "        stats = {'dt_med' : 'median', \n",
    "                 'dt_std' : 'std',\n",
    "                 'niter_med' : 'median',\n",
    "                 'niter_max' : 'max',\n",
    "                 'unclpM' : 'mean',\n",
    "                 'exchpM' : 'mean',\n",
    "                 'stabpM' : 'mean',\n",
    "                 'p' : 'mean',\n",
    "                 'p_std' : 'mean',\n",
    "                 'count' : 'sum',\n",
    "                 'num_exch_full' : 'mean',\n",
    "                 'num_stab_full' : 'mean',\n",
    "                 'num_stab_active' : 'mean',\n",
    "                 'bchofail' :'mean',\n",
    "                 'bmaxiter' : 'mean',\n",
    "                 'niter' : 'mean',\n",
    "                 'unclpM_max' : 'max',\n",
    "                 'n_bad_p' : 'mean',\n",
    "                 'nchreg' : 'mean',\n",
    "                 'dvM' : 'mean',\n",
    "                 'condnum_med' : 'median',\n",
    "                 'dt_max' : 'max',\n",
    "                 'dt_min' : 'min',\n",
    "                 'dt' : 'mean',\n",
    "                 'exchpM_max' : 'max',\n",
    "                 'exchpM_med' : 'median',\n",
    "                 'exchpM_min' : 'min',\n",
    "                 'exchpM_std' : 'std',\n",
    "                }\n",
    "\n",
    "        #print(\"vns = \", vns)\n",
    "        \n",
    "        vns = vns + list(stats)\n",
    "        \n",
    "        #print(\"vns = \", vns)\n",
    "\n",
    "        #print(dfm.columns)\n",
    "        \n",
    "        dfm = dfm[vns]\n",
    "        \n",
    "        #vnsgb = ['difficulty', 'size', 'changes', 'ch_vn0', 'ch_value0', 'ch_vn1', 'ch_value1']\n",
    "        vnsgb = ['difficulty', 'ch_few', 'ch_many'] + list(ks) + ['ch_vn0', 'ch_value0']\n",
    "        #vnsgb = ['size', 'difficulty', 'changes'] + list(ks) + ['ch_vn0', 'ch_value0']\n",
    "\n",
    "        #display(dfm[vns])\n",
    "\n",
    "        #print(\"vns = \", type(vns), vns)\n",
    "        #print(\"vnsgb = \", type(vnsgb), vnsgb)\n",
    "        #dftemp = dfm[vns]\n",
    "        #for vn in dftemp.columns:\n",
    "        #    print(vn, dftemp[vn].dtype)\n",
    "        #print(\"\\n\", dftemp, \"\\n\")    \n",
    "        \n",
    "        dfg = dfm[vns].groupby(vnsgb, dropna=False).agg(stats)\n",
    "\n",
    "        #display(dfg)\n",
    "\n",
    "        #dfg = dfg.sort_values(by=vnsgb)\n",
    "\n",
    "        #dfg.reset_index(inplace=True)\n",
    "\n",
    "        #dfg = dfg.sort_values('dt')\n",
    "\n",
    "        #try:\n",
    "        #    dfg['ch_value0'] = np.where(np.isinf(dfg['ch_value0']), np.nan, dfg['ch_value0'])\n",
    "        #except:\n",
    "        #    pass\n",
    "\n",
    "        #try:\n",
    "        #    dfg['ch_value1'] = np.where(np.isinf(dfg['ch_value1']), np.nan, dfg['ch_value1'])\n",
    "        #except:\n",
    "        #    pass\n",
    "\n",
    "        #dfg['iter_n'] = dfg['niter'].astype(int)\n",
    "        dfg['count'] = dfg['count'].astype(int)\n",
    "        #dfg['iter_max'] = dfg['max_iter'].astype(int)\n",
    "        dfg['niter_med'] = dfg['niter_med'].astype(int)\n",
    "\n",
    "        dfg = dfg.reset_index(drop=False)\n",
    "\n",
    "        #dfg = dfg.sort_values(['size', 'difficulty', 'ch_vn0', 'ch_value0', ])\n",
    "        #dfg = dfg.sort_values(['difficulty', 'ch_vn0', 'ch_value0', ])\n",
    "        #dfg = dfg.sort_values(['difficulty', 'ch_few', 'dt', ])\n",
    "        \n",
    "        # dfg_save = self.display_and_save_table(dfg=dfg, tbl_name=tbl_name)\n",
    "        \n",
    "        return dfg\n",
    "\n",
    "    ########################################\n",
    "    \n",
    "    def display_and_save_table(self, dfg=None, tbl_name=None, vns_keep=None, vns_drop=None, vns_sort=None):\n",
    "        \n",
    "        if dfg is None:\n",
    "            dfg = self.dfg\n",
    "\n",
    "        if vns_sort == None:\n",
    "            dfg = dfg.sort_values(['difficulty', 'ch_few', 'dt_med', ])\n",
    "        else:\n",
    "            dfg = dfg.sort_values(vns_sort)\n",
    "            \n",
    "        vns = list(dfg.columns)\n",
    "        if vns_keep is not None:\n",
    "            vns = vns_keep\n",
    "        if vns_drop is not None:\n",
    "            for vn in vns_drop:\n",
    "                if vn in vns:\n",
    "                    vns.remove(vn)\n",
    "        \n",
    "        dfg_save = dfg[vns].copy()\n",
    "        \n",
    "        self.dfg_save = dfg_save\n",
    "        \n",
    "        # Now defined as a global variable!\n",
    "        # The function format_pd implements different formatting for different values:    \n",
    "        # format_pd = (lambda s: \"{:}\".format(s) if type(s)==int \n",
    "        #        else \"{:.2e}\".format(s) if s < 0.00999999\n",
    "        #        else \"{:.2e}\".format(s) if s > 1000.00 \n",
    "        #        else \"{:.4f}\".format(s))\n",
    "        \n",
    "        #print(\"dfg_save.columns = \", dfg_save.columns)\n",
    "\n",
    "        #format_pd = (lambda  x:  \"{:}\".format(x) if type(x) == str\n",
    "        #     else \"{:}\".format(x) if (type(x)==int and abs(x) < 1000000)\n",
    "        #    else \"{:.2e}\".format(x) if abs(x) < 0.00999999\n",
    "        #    else \"{:.2e}\".format(x) if abs(x) >= 1000.00 \n",
    "        #    else \"{:.4f}\".format(x)) \n",
    "\n",
    "        \n",
    "        formatter=dict({vn : format_pd for vn in dfg_save.columns}, \n",
    "                            **{'dt' : \"{:.4f}\",\n",
    "                               'dt_std' : \"{:.4f}\",\n",
    "                               'unclpM' : \"{:.1e}\",\n",
    "                               'exchpM' : \"{:.1e}\",\n",
    "                               'stabpM' : \"{:.1e}\",\n",
    "                               'dt_max' : \"{:.4f}\",\n",
    "                               'difficulty' : None,\n",
    "                              })\n",
    "        \n",
    "        #print(\"formatter = \", formatter)\n",
    "        \n",
    "        dfgs = dfg_save.style.format(precision=2, na_rep='.', thousands=\"\", formatter=formatter)    \n",
    "\n",
    "        #dfgg.columns = [s.replace('_', '\\_') for s in dfgg.columns]\n",
    "        #dfgg['ch\\_vn0'] = dfgg['ch\\_vn0'].str.replace('_', '\\_')\n",
    "\n",
    "        if tbl_name != None and B_SAVE_RESULTS == True:\n",
    "\n",
    "            #path = \"C:/Users/akyle/ask/code/flow-trading-figures/\"\n",
    "            #ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "            #dfgs.to_latex(path + \"vary_parms_mina_latex_tbl_01_\" + ts + \".txt\", index=False)\n",
    "            fp = (LATEX_PATH + self.name_prefix + \"_\" + self.name_suffix + \"_\" + tbl_name + \"_\" \n",
    "                  + self.ts + \"_\" + RUN_TYPE + \".txt\")\n",
    "            s = dfgs.to_latex(buf=None, hrules=True)\n",
    "            s = s.replace('_', '\\_')\n",
    "            with open(fp, \"w+\") as f:\n",
    "                f.writelines(s)\n",
    "            self.latex_table = fp  # filename for most recent table\n",
    "            self.d_latex_table[tbl_name + \"_\" + self.ts] = fp  # filename for all tables\n",
    "            print(\"Latex table saved to \", fp)\n",
    "\n",
    "        display(dfgs)\n",
    "\n",
    "        self.dfgs = dfgs\n",
    "        self.dfg_save = dfg_save  # Not necessary, in self.__call__(...)\n",
    "        \n",
    "        return dfg_save\n",
    "\n",
    "    ########################################\n",
    "    \n",
    "    def print_dictionaries(self):\n",
    "        display(self.dd_difficulty)\n",
    "        display(self.dvd_change_few)\n",
    "        display(self.dvd_change_many)\n",
    "        \n",
    "#Simulations().print_dictionaries()        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell tests the Simulations class using predefined string names for difficulty, change_few, and change_many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreps =  3\n",
      "difficulty =  ['base']\n",
      "change_few =  ['small']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:02<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/temp_temp_2023-1204-2042.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  2.2633299827575684  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def test_simulations():\n",
    "\n",
    "    nreps = 11 if RUN_TYPE == 'workstation' else 11 if RUN_TYPE == 'laptop' else 3\n",
    "\n",
    "    difficulty = ['base']\n",
    "\n",
    "    change_few = ['small']\n",
    "\n",
    "    change_many = ['none']\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"temp\")\n",
    "\n",
    "    df = sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=\"temp\")\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim_test = test_simulations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_63cfb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63cfb_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_63cfb_level0_col1\" class=\"col_heading level0 col1\" >M</th>\n",
       "      <th id=\"T_63cfb_level0_col2\" class=\"col_heading level0 col2\" >ch_vn0</th>\n",
       "      <th id=\"T_63cfb_level0_col3\" class=\"col_heading level0 col3\" >ch_value0</th>\n",
       "      <th id=\"T_63cfb_level0_col4\" class=\"col_heading level0 col4\" >dt_med</th>\n",
       "      <th id=\"T_63cfb_level0_col5\" class=\"col_heading level0 col5\" >dt_std</th>\n",
       "      <th id=\"T_63cfb_level0_col6\" class=\"col_heading level0 col6\" >niter_med</th>\n",
       "      <th id=\"T_63cfb_level0_col7\" class=\"col_heading level0 col7\" >niter_max</th>\n",
       "      <th id=\"T_63cfb_level0_col8\" class=\"col_heading level0 col8\" >unclpM</th>\n",
       "      <th id=\"T_63cfb_level0_col9\" class=\"col_heading level0 col9\" >exchpM</th>\n",
       "      <th id=\"T_63cfb_level0_col10\" class=\"col_heading level0 col10\" >stabpM</th>\n",
       "      <th id=\"T_63cfb_level0_col11\" class=\"col_heading level0 col11\" >p</th>\n",
       "      <th id=\"T_63cfb_level0_col12\" class=\"col_heading level0 col12\" >p_std</th>\n",
       "      <th id=\"T_63cfb_level0_col13\" class=\"col_heading level0 col13\" >count</th>\n",
       "      <th id=\"T_63cfb_level0_col14\" class=\"col_heading level0 col14\" >num_exch_full</th>\n",
       "      <th id=\"T_63cfb_level0_col15\" class=\"col_heading level0 col15\" >num_stab_full</th>\n",
       "      <th id=\"T_63cfb_level0_col16\" class=\"col_heading level0 col16\" >num_stab_active</th>\n",
       "      <th id=\"T_63cfb_level0_col17\" class=\"col_heading level0 col17\" >bchofail</th>\n",
       "      <th id=\"T_63cfb_level0_col18\" class=\"col_heading level0 col18\" >bmaxiter</th>\n",
       "      <th id=\"T_63cfb_level0_col19\" class=\"col_heading level0 col19\" >niter</th>\n",
       "      <th id=\"T_63cfb_level0_col20\" class=\"col_heading level0 col20\" >unclpM_max</th>\n",
       "      <th id=\"T_63cfb_level0_col21\" class=\"col_heading level0 col21\" >n_bad_p</th>\n",
       "      <th id=\"T_63cfb_level0_col22\" class=\"col_heading level0 col22\" >nchreg</th>\n",
       "      <th id=\"T_63cfb_level0_col23\" class=\"col_heading level0 col23\" >dvM</th>\n",
       "      <th id=\"T_63cfb_level0_col24\" class=\"col_heading level0 col24\" >condnum_med</th>\n",
       "      <th id=\"T_63cfb_level0_col25\" class=\"col_heading level0 col25\" >dt_max</th>\n",
       "      <th id=\"T_63cfb_level0_col26\" class=\"col_heading level0 col26\" >dt_min</th>\n",
       "      <th id=\"T_63cfb_level0_col27\" class=\"col_heading level0 col27\" >dt</th>\n",
       "      <th id=\"T_63cfb_level0_col28\" class=\"col_heading level0 col28\" >exchpM_max</th>\n",
       "      <th id=\"T_63cfb_level0_col29\" class=\"col_heading level0 col29\" >exchpM_med</th>\n",
       "      <th id=\"T_63cfb_level0_col30\" class=\"col_heading level0 col30\" >exchpM_min</th>\n",
       "      <th id=\"T_63cfb_level0_col31\" class=\"col_heading level0 col31\" >exchpM_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63cfb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_63cfb_row0_col0\" class=\"data row0 col0\" >500</td>\n",
       "      <td id=\"T_63cfb_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_63cfb_row0_col2\" class=\"data row0 col2\" >none</td>\n",
       "      <td id=\"T_63cfb_row0_col3\" class=\"data row0 col3\" >.</td>\n",
       "      <td id=\"T_63cfb_row0_col4\" class=\"data row0 col4\" >0.3871</td>\n",
       "      <td id=\"T_63cfb_row0_col5\" class=\"data row0 col5\" >0.0437</td>\n",
       "      <td id=\"T_63cfb_row0_col6\" class=\"data row0 col6\" >30</td>\n",
       "      <td id=\"T_63cfb_row0_col7\" class=\"data row0 col7\" >32</td>\n",
       "      <td id=\"T_63cfb_row0_col8\" class=\"data row0 col8\" >3.8e-06</td>\n",
       "      <td id=\"T_63cfb_row0_col9\" class=\"data row0 col9\" >7.2e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col10\" class=\"data row0 col10\" >0.0e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col11\" class=\"data row0 col11\" >99.1338</td>\n",
       "      <td id=\"T_63cfb_row0_col12\" class=\"data row0 col12\" >27.7398</td>\n",
       "      <td id=\"T_63cfb_row0_col13\" class=\"data row0 col13\" >3</td>\n",
       "      <td id=\"T_63cfb_row0_col14\" class=\"data row0 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col15\" class=\"data row0 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col16\" class=\"data row0 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col17\" class=\"data row0 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col18\" class=\"data row0 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col19\" class=\"data row0 col19\" >30.6667</td>\n",
       "      <td id=\"T_63cfb_row0_col20\" class=\"data row0 col20\" >6.71e-06</td>\n",
       "      <td id=\"T_63cfb_row0_col21\" class=\"data row0 col21\" >11.0000</td>\n",
       "      <td id=\"T_63cfb_row0_col22\" class=\"data row0 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_63cfb_row0_col23\" class=\"data row0 col23\" >83.3515</td>\n",
       "      <td id=\"T_63cfb_row0_col24\" class=\"data row0 col24\" >1.27e+11</td>\n",
       "      <td id=\"T_63cfb_row0_col25\" class=\"data row0 col25\" >0.4210</td>\n",
       "      <td id=\"T_63cfb_row0_col26\" class=\"data row0 col26\" >0.3343</td>\n",
       "      <td id=\"T_63cfb_row0_col27\" class=\"data row0 col27\" >0.3808</td>\n",
       "      <td id=\"T_63cfb_row0_col28\" class=\"data row0 col28\" >8.8120</td>\n",
       "      <td id=\"T_63cfb_row0_col29\" class=\"data row0 col29\" >6.6679</td>\n",
       "      <td id=\"T_63cfb_row0_col30\" class=\"data row0 col30\" >6.0927</td>\n",
       "      <td id=\"T_63cfb_row0_col31\" class=\"data row0 col31\" >1.4331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf43fa490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_df9d7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df9d7_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_df9d7_level0_col1\" class=\"col_heading level0 col1\" >M</th>\n",
       "      <th id=\"T_df9d7_level0_col2\" class=\"col_heading level0 col2\" >ch_vn0</th>\n",
       "      <th id=\"T_df9d7_level0_col3\" class=\"col_heading level0 col3\" >ch_value0</th>\n",
       "      <th id=\"T_df9d7_level0_col4\" class=\"col_heading level0 col4\" >dt_med</th>\n",
       "      <th id=\"T_df9d7_level0_col5\" class=\"col_heading level0 col5\" >dt_std</th>\n",
       "      <th id=\"T_df9d7_level0_col6\" class=\"col_heading level0 col6\" >niter_med</th>\n",
       "      <th id=\"T_df9d7_level0_col7\" class=\"col_heading level0 col7\" >niter_max</th>\n",
       "      <th id=\"T_df9d7_level0_col8\" class=\"col_heading level0 col8\" >unclpM</th>\n",
       "      <th id=\"T_df9d7_level0_col9\" class=\"col_heading level0 col9\" >exchpM</th>\n",
       "      <th id=\"T_df9d7_level0_col10\" class=\"col_heading level0 col10\" >stabpM</th>\n",
       "      <th id=\"T_df9d7_level0_col11\" class=\"col_heading level0 col11\" >p</th>\n",
       "      <th id=\"T_df9d7_level0_col12\" class=\"col_heading level0 col12\" >p_std</th>\n",
       "      <th id=\"T_df9d7_level0_col13\" class=\"col_heading level0 col13\" >count</th>\n",
       "      <th id=\"T_df9d7_level0_col14\" class=\"col_heading level0 col14\" >num_exch_full</th>\n",
       "      <th id=\"T_df9d7_level0_col15\" class=\"col_heading level0 col15\" >num_stab_full</th>\n",
       "      <th id=\"T_df9d7_level0_col16\" class=\"col_heading level0 col16\" >num_stab_active</th>\n",
       "      <th id=\"T_df9d7_level0_col17\" class=\"col_heading level0 col17\" >bchofail</th>\n",
       "      <th id=\"T_df9d7_level0_col18\" class=\"col_heading level0 col18\" >bmaxiter</th>\n",
       "      <th id=\"T_df9d7_level0_col19\" class=\"col_heading level0 col19\" >niter</th>\n",
       "      <th id=\"T_df9d7_level0_col20\" class=\"col_heading level0 col20\" >unclpM_max</th>\n",
       "      <th id=\"T_df9d7_level0_col21\" class=\"col_heading level0 col21\" >n_bad_p</th>\n",
       "      <th id=\"T_df9d7_level0_col22\" class=\"col_heading level0 col22\" >nchreg</th>\n",
       "      <th id=\"T_df9d7_level0_col23\" class=\"col_heading level0 col23\" >dvM</th>\n",
       "      <th id=\"T_df9d7_level0_col24\" class=\"col_heading level0 col24\" >condnum_med</th>\n",
       "      <th id=\"T_df9d7_level0_col25\" class=\"col_heading level0 col25\" >dt_max</th>\n",
       "      <th id=\"T_df9d7_level0_col26\" class=\"col_heading level0 col26\" >dt_min</th>\n",
       "      <th id=\"T_df9d7_level0_col27\" class=\"col_heading level0 col27\" >dt</th>\n",
       "      <th id=\"T_df9d7_level0_col28\" class=\"col_heading level0 col28\" >exchpM_max</th>\n",
       "      <th id=\"T_df9d7_level0_col29\" class=\"col_heading level0 col29\" >exchpM_med</th>\n",
       "      <th id=\"T_df9d7_level0_col30\" class=\"col_heading level0 col30\" >exchpM_min</th>\n",
       "      <th id=\"T_df9d7_level0_col31\" class=\"col_heading level0 col31\" >exchpM_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df9d7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_df9d7_row0_col0\" class=\"data row0 col0\" >500</td>\n",
       "      <td id=\"T_df9d7_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_df9d7_row0_col2\" class=\"data row0 col2\" >none</td>\n",
       "      <td id=\"T_df9d7_row0_col3\" class=\"data row0 col3\" >.</td>\n",
       "      <td id=\"T_df9d7_row0_col4\" class=\"data row0 col4\" >0.3871</td>\n",
       "      <td id=\"T_df9d7_row0_col5\" class=\"data row0 col5\" >0.0437</td>\n",
       "      <td id=\"T_df9d7_row0_col6\" class=\"data row0 col6\" >30</td>\n",
       "      <td id=\"T_df9d7_row0_col7\" class=\"data row0 col7\" >32</td>\n",
       "      <td id=\"T_df9d7_row0_col8\" class=\"data row0 col8\" >3.8e-06</td>\n",
       "      <td id=\"T_df9d7_row0_col9\" class=\"data row0 col9\" >7.2e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col10\" class=\"data row0 col10\" >0.0e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col11\" class=\"data row0 col11\" >99.1338</td>\n",
       "      <td id=\"T_df9d7_row0_col12\" class=\"data row0 col12\" >27.7398</td>\n",
       "      <td id=\"T_df9d7_row0_col13\" class=\"data row0 col13\" >3</td>\n",
       "      <td id=\"T_df9d7_row0_col14\" class=\"data row0 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col15\" class=\"data row0 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col16\" class=\"data row0 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col17\" class=\"data row0 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col18\" class=\"data row0 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col19\" class=\"data row0 col19\" >30.6667</td>\n",
       "      <td id=\"T_df9d7_row0_col20\" class=\"data row0 col20\" >6.71e-06</td>\n",
       "      <td id=\"T_df9d7_row0_col21\" class=\"data row0 col21\" >11.0000</td>\n",
       "      <td id=\"T_df9d7_row0_col22\" class=\"data row0 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_df9d7_row0_col23\" class=\"data row0 col23\" >83.3515</td>\n",
       "      <td id=\"T_df9d7_row0_col24\" class=\"data row0 col24\" >1.27e+11</td>\n",
       "      <td id=\"T_df9d7_row0_col25\" class=\"data row0 col25\" >0.4210</td>\n",
       "      <td id=\"T_df9d7_row0_col26\" class=\"data row0 col26\" >0.3343</td>\n",
       "      <td id=\"T_df9d7_row0_col27\" class=\"data row0 col27\" >0.3808</td>\n",
       "      <td id=\"T_df9d7_row0_col28\" class=\"data row0 col28\" >8.8120</td>\n",
       "      <td id=\"T_df9d7_row0_col29\" class=\"data row0 col29\" >6.6679</td>\n",
       "      <td id=\"T_df9d7_row0_col30\" class=\"data row0 col30\" >6.0927</td>\n",
       "      <td id=\"T_df9d7_row0_col31\" class=\"data row0 col31\" >1.4331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dde29e2c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  0.18014240264892578  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def make_table_test(sim_test):\n",
    "\n",
    "    #print(sim_test.dfg.columns)\n",
    "\n",
    "    vns_drop = ['difficulty', 'ch_few', 'ch_many']\n",
    "    vns_keep = [vn for vn in sim_test.dfg.columns if vn not in vns_drop]\n",
    "\n",
    "    #print(vns_keep)\n",
    "\n",
    "    dfg1 = sim_test.display_and_save_table(dfg=None, tbl_name=\"tblA\", vns_keep=vns_keep, vns_drop=None, vns_sort=None)\n",
    "\n",
    "    dfg2 = sim_test.display_and_save_table(dfg=None, tbl_name=\"tblB\", vns_keep=None, vns_drop=vns_drop, vns_sort=None)\n",
    "\n",
    "    return dfg1,dfg2\n",
    "\n",
    "dfg1_test, dfg2_test = make_table_test(sim_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ntext cell tests the Assumptions class using bespoke settings for changes to variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreps =  5\n",
      "difficulty =  ['test_base']\n",
      "change_few =  ['test_few']\n",
      "change_many =  ['test_many']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:11<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  11.41538405418396  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def test_simulations_bespoke():\n",
    "\n",
    "    nreps = 5\n",
    "\n",
    "    sim = Simulations()\n",
    "\n",
    "    sim.dd_difficulty['test_base'] = {'N' : 10, 'M' : 1000}\n",
    "    sim.dvd_change_few['test_few'] = [{'exch_epsilon' : x} for x in [1.00e-99, 1.00e-6, 1.00e+8]]\n",
    "    sim.dvd_change_many['test_many'] = [{'exch_phpl_frac' : 1.00e-2}, {'fracMA' : 0.99}]\n",
    "\n",
    "    difficulty = ['test_base']\n",
    "    change_few = ['test_few']\n",
    "    change_many = ['test_many']\n",
    "\n",
    "    nseed0 = 1234\n",
    "\n",
    "    sim = sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=nseed0)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim_test_bespoke = test_simulations_bespoke()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumptions(N=500, M=100000, exch_liq_model='mina', exch_epsilon=0.01, exch_phpl_frac=100.0, stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, fracMA=0.5, subfracMX=0.5, num_size_indexes=5, num_industry_indexes=10, market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, std_num_orders_asset=1.7, std_order_size=1.5, dv_single_asset_orders=10000000.0, std_limit_price=0.1, limit_bias=0.3, avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0, index_prices=100.0, mean_asset_price=100.0, std_asset_price=0.0, invariance_exponent=0.3333333333333333, fraction_buy_orders_asset=0.5, Bs_M=0, Bs_Rmin=1, Bs_Rmax=5, Bs_Wscale=1.0, Bs_std_ph_dollars=1.0, Bd_M=0, Bd_Rmin=20, Bd_Rmax=50, Bd_Wscale=1.0, Bd_std_ph_dollars=1.0, fracMX=0.25, fracM2=0.25, MX=25000, M2=25000, MA=50000, M0=1000, M0s=0, M1=75000, Mall=101000, NX=32, NR=532, ew_mkt_index_share=0.05, vw_mkt_index_share=0.75, industry_index_subshare=0.5, ew_size_index_share=0.024999999999999994, vw_size_index_share=0.07499999999999998, ew_industry_index_share=0.024999999999999994, vw_industry_index_share=0.07499999999999998)\n"
     ]
    }
   ],
   "source": [
    "print(Assumptions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function make_assumptions_table\n",
    "\n",
    "The function *make_assumptions_table* prints a nicely formatted table of Assumptions for base, hard, and easy cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_71e01\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71e01_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_71e01_level0_col1\" class=\"col_heading level0 col1\" >Base</th>\n",
       "      <th id=\"T_71e01_level0_col2\" class=\"col_heading level0 col2\" >Low</th>\n",
       "      <th id=\"T_71e01_level0_col3\" class=\"col_heading level0 col3\" >High</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Parameter</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row0\" class=\"row_heading level0 row0\" >$$N$$</th>\n",
       "      <td id=\"T_71e01_row0_col0\" class=\"data row0 col0\" >Number of assets</td>\n",
       "      <td id=\"T_71e01_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_71e01_row0_col2\" class=\"data row0 col2\" >500</td>\n",
       "      <td id=\"T_71e01_row0_col3\" class=\"data row0 col3\" >500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row1\" class=\"row_heading level0 row1\" >$$M$$</th>\n",
       "      <td id=\"T_71e01_row1_col0\" class=\"data row1 col0\" >Number of orders</td>\n",
       "      <td id=\"T_71e01_row1_col1\" class=\"data row1 col1\" >100000</td>\n",
       "      <td id=\"T_71e01_row1_col2\" class=\"data row1 col2\" >100000</td>\n",
       "      <td id=\"T_71e01_row1_col3\" class=\"data row1 col3\" >100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row2\" class=\"row_heading level0 row2\" >$$exch\\_epsilon$$</th>\n",
       "      <td id=\"T_71e01_row2_col0\" class=\"data row2 col0\" >Slope of exchange's demand schedule (shares traded per dollar price change at \\$100/share)</td>\n",
       "      <td id=\"T_71e01_row2_col1\" class=\"data row2 col1\" >0.0100</td>\n",
       "      <td id=\"T_71e01_row2_col2\" class=\"data row2 col2\" >0.0100</td>\n",
       "      <td id=\"T_71e01_row2_col3\" class=\"data row2 col3\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row3\" class=\"row_heading level0 row3\" >$$exch\\_phpl\\_frac$$</th>\n",
       "      <td id=\"T_71e01_row3_col0\" class=\"data row3 col0\" >Exchange $p_H - p_L$ as fraction of $p_0$</td>\n",
       "      <td id=\"T_71e01_row3_col1\" class=\"data row3 col1\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row3_col2\" class=\"data row3 col2\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row3_col3\" class=\"data row3 col3\" >100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row4\" class=\"row_heading level0 row4\" >$$stab\\_max\\_qv$$</th>\n",
       "      <td id=\"T_71e01_row4_col0\" class=\"data row4 col0\" >Stabilizing order max q as multiple of v</td>\n",
       "      <td id=\"T_71e01_row4_col1\" class=\"data row4 col1\" >0.00e+00</td>\n",
       "      <td id=\"T_71e01_row4_col2\" class=\"data row4 col2\" >0.00e+00</td>\n",
       "      <td id=\"T_71e01_row4_col3\" class=\"data row4 col3\" >0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row5\" class=\"row_heading level0 row5\" >$$stab\\_ph\\_frac$$</th>\n",
       "      <td id=\"T_71e01_row5_col0\" class=\"data row5 col0\" >Fraction of $p_0$ where buying starts</td>\n",
       "      <td id=\"T_71e01_row5_col1\" class=\"data row5 col1\" >0.7000</td>\n",
       "      <td id=\"T_71e01_row5_col2\" class=\"data row5 col2\" >0.7000</td>\n",
       "      <td id=\"T_71e01_row5_col3\" class=\"data row5 col3\" >0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row6\" class=\"row_heading level0 row6\" >$$stab\\_pl\\_frac$$</th>\n",
       "      <td id=\"T_71e01_row6_col0\" class=\"data row6 col0\" >Fraction of $p_0$ where buying stops</td>\n",
       "      <td id=\"T_71e01_row6_col1\" class=\"data row6 col1\" >0.2000</td>\n",
       "      <td id=\"T_71e01_row6_col2\" class=\"data row6 col2\" >0.2000</td>\n",
       "      <td id=\"T_71e01_row6_col3\" class=\"data row6 col3\" >0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row7\" class=\"row_heading level0 row7\" >$$fracMA$$</th>\n",
       "      <td id=\"T_71e01_row7_col0\" class=\"data row7 col0\" >Fraction of orders for individual assets</td>\n",
       "      <td id=\"T_71e01_row7_col1\" class=\"data row7 col1\" >0.5000</td>\n",
       "      <td id=\"T_71e01_row7_col2\" class=\"data row7 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row7_col3\" class=\"data row7 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row8\" class=\"row_heading level0 row8\" >$$subfracMX$$</th>\n",
       "      <td id=\"T_71e01_row8_col0\" class=\"data row8 col0\" >Fraction of orders for indexes among orders for portfolios</td>\n",
       "      <td id=\"T_71e01_row8_col1\" class=\"data row8 col1\" >0.5000</td>\n",
       "      <td id=\"T_71e01_row8_col2\" class=\"data row8 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row8_col3\" class=\"data row8 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row9\" class=\"row_heading level0 row9\" >$$num\\_size\\_indexes$$</th>\n",
       "      <td id=\"T_71e01_row9_col0\" class=\"data row9 col0\" >Number of size indexes</td>\n",
       "      <td id=\"T_71e01_row9_col1\" class=\"data row9 col1\" >5</td>\n",
       "      <td id=\"T_71e01_row9_col2\" class=\"data row9 col2\" >2</td>\n",
       "      <td id=\"T_71e01_row9_col3\" class=\"data row9 col3\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row10\" class=\"row_heading level0 row10\" >$$num\\_industry\\_indexes$$</th>\n",
       "      <td id=\"T_71e01_row10_col0\" class=\"data row10 col0\" >Number of industry indexes</td>\n",
       "      <td id=\"T_71e01_row10_col1\" class=\"data row10 col1\" >10</td>\n",
       "      <td id=\"T_71e01_row10_col2\" class=\"data row10 col2\" >2</td>\n",
       "      <td id=\"T_71e01_row10_col3\" class=\"data row10 col3\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row11\" class=\"row_heading level0 row11\" >$$market\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row11_col0\" class=\"data row11 col0\" >Probability an index order is a market index order</td>\n",
       "      <td id=\"T_71e01_row11_col1\" class=\"data row11 col1\" >0.8000</td>\n",
       "      <td id=\"T_71e01_row11_col2\" class=\"data row11 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row11_col3\" class=\"data row11 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row12\" class=\"row_heading level0 row12\" >$$size\\_index\\_subshare$$</th>\n",
       "      <td id=\"T_71e01_row12_col0\" class=\"data row12 col0\" >Probability a size or industry index order is a size index order</td>\n",
       "      <td id=\"T_71e01_row12_col1\" class=\"data row12 col1\" >0.5000</td>\n",
       "      <td id=\"T_71e01_row12_col2\" class=\"data row12 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row12_col3\" class=\"data row12 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row13\" class=\"row_heading level0 row13\" >$$ew\\_mkt\\_index\\_subshare$$</th>\n",
       "      <td id=\"T_71e01_row13_col0\" class=\"data row13 col0\" >Probability a mkt index order is an EW mkt index order</td>\n",
       "      <td id=\"T_71e01_row13_col1\" class=\"data row13 col1\" >0.0625</td>\n",
       "      <td id=\"T_71e01_row13_col2\" class=\"data row13 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row13_col3\" class=\"data row13 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row14\" class=\"row_heading level0 row14\" >$$ew\\_size\\_index\\_subsubshare$$</th>\n",
       "      <td id=\"T_71e01_row14_col0\" class=\"data row14 col0\" >Probability a size index order is an EW size index order</td>\n",
       "      <td id=\"T_71e01_row14_col1\" class=\"data row14 col1\" >0.2500</td>\n",
       "      <td id=\"T_71e01_row14_col2\" class=\"data row14 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row14_col3\" class=\"data row14 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row15\" class=\"row_heading level0 row15\" >$$ew\\_industry\\_index\\_subsubshare$$</th>\n",
       "      <td id=\"T_71e01_row15_col0\" class=\"data row15 col0\" >Probability an industry index order is an EW industry index order</td>\n",
       "      <td id=\"T_71e01_row15_col1\" class=\"data row15 col1\" >0.2500</td>\n",
       "      <td id=\"T_71e01_row15_col2\" class=\"data row15 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row15_col3\" class=\"data row15 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row16\" class=\"row_heading level0 row16\" >$$std\\_num\\_orders\\_asset$$</th>\n",
       "      <td id=\"T_71e01_row16_col0\" class=\"data row16 col0\" >Standard deviation of expected number of orders across assets</td>\n",
       "      <td id=\"T_71e01_row16_col1\" class=\"data row16 col1\" >1.7000</td>\n",
       "      <td id=\"T_71e01_row16_col2\" class=\"data row16 col2\" >0.1000</td>\n",
       "      <td id=\"T_71e01_row16_col3\" class=\"data row16 col3\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row17\" class=\"row_heading level0 row17\" >$$std\\_order\\_size$$</th>\n",
       "      <td id=\"T_71e01_row17_col0\" class=\"data row17 col0\" >Standard deviation of order size given asset</td>\n",
       "      <td id=\"T_71e01_row17_col1\" class=\"data row17 col1\" >1.5000</td>\n",
       "      <td id=\"T_71e01_row17_col2\" class=\"data row17 col2\" >0.1000</td>\n",
       "      <td id=\"T_71e01_row17_col3\" class=\"data row17 col3\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row18\" class=\"row_heading level0 row18\" >$$dv\\_single\\_asset\\_orders$$</th>\n",
       "      <td id=\"T_71e01_row18_col0\" class=\"data row18 col0\" >Expect total dollar volume of orders for individual assets</td>\n",
       "      <td id=\"T_71e01_row18_col1\" class=\"data row18 col1\" >1.00e+07</td>\n",
       "      <td id=\"T_71e01_row18_col2\" class=\"data row18 col2\" >1.00e+07</td>\n",
       "      <td id=\"T_71e01_row18_col3\" class=\"data row18 col3\" >1.00e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row19\" class=\"row_heading level0 row19\" >$$std\\_limit\\_price$$</th>\n",
       "      <td id=\"T_71e01_row19_col0\" class=\"data row19 col0\" >Standard deviation of upper limit price as fraction of initial price</td>\n",
       "      <td id=\"T_71e01_row19_col1\" class=\"data row19 col1\" >0.1000</td>\n",
       "      <td id=\"T_71e01_row19_col2\" class=\"data row19 col2\" >0.0100</td>\n",
       "      <td id=\"T_71e01_row19_col3\" class=\"data row19 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row20\" class=\"row_heading level0 row20\" >$$limit\\_bias$$</th>\n",
       "      <td id=\"T_71e01_row20_col0\" class=\"data row20 col0\" >Mean deviation of upper limit price as fraction of initial price standard deviation</td>\n",
       "      <td id=\"T_71e01_row20_col1\" class=\"data row20 col1\" >0.3000</td>\n",
       "      <td id=\"T_71e01_row20_col2\" class=\"data row20 col2\" >0.0100</td>\n",
       "      <td id=\"T_71e01_row20_col3\" class=\"data row20 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row21\" class=\"row_heading level0 row21\" >$$avg\\_ph\\_minus\\_pl\\_bp$$</th>\n",
       "      <td id=\"T_71e01_row21_col0\" class=\"data row21 col0\" >Mean difference between upper and lower limit prices (basis points)</td>\n",
       "      <td id=\"T_71e01_row21_col1\" class=\"data row21 col1\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row21_col2\" class=\"data row21 col2\" >0.0100</td>\n",
       "      <td id=\"T_71e01_row21_col3\" class=\"data row21 col3\" >100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row22\" class=\"row_heading level0 row22\" >$$std\\_ph\\_minus\\_pl$$</th>\n",
       "      <td id=\"T_71e01_row22_col0\" class=\"data row22 col0\" >Standard deviation of difference between upper and lower limit prices</td>\n",
       "      <td id=\"T_71e01_row22_col1\" class=\"data row22 col1\" >2.0000</td>\n",
       "      <td id=\"T_71e01_row22_col2\" class=\"data row22 col2\" >0.1000</td>\n",
       "      <td id=\"T_71e01_row22_col3\" class=\"data row22 col3\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row23\" class=\"row_heading level0 row23\" >$$index\\_prices$$</th>\n",
       "      <td id=\"T_71e01_row23_col0\" class=\"data row23 col0\" >Mean index price</td>\n",
       "      <td id=\"T_71e01_row23_col1\" class=\"data row23 col1\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row23_col2\" class=\"data row23 col2\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row23_col3\" class=\"data row23 col3\" >100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row24\" class=\"row_heading level0 row24\" >$$mean\\_asset\\_price$$</th>\n",
       "      <td id=\"T_71e01_row24_col0\" class=\"data row24 col0\" >Mean asset price</td>\n",
       "      <td id=\"T_71e01_row24_col1\" class=\"data row24 col1\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row24_col2\" class=\"data row24 col2\" >100.0000</td>\n",
       "      <td id=\"T_71e01_row24_col3\" class=\"data row24 col3\" >100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row25\" class=\"row_heading level0 row25\" >$$std\\_asset\\_price$$</th>\n",
       "      <td id=\"T_71e01_row25_col0\" class=\"data row25 col0\" >St.dev of mean asset prices across assets</td>\n",
       "      <td id=\"T_71e01_row25_col1\" class=\"data row25 col1\" >0.00e+00</td>\n",
       "      <td id=\"T_71e01_row25_col2\" class=\"data row25 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_71e01_row25_col3\" class=\"data row25 col3\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row26\" class=\"row_heading level0 row26\" >$$invariance\\_exponent$$</th>\n",
       "      <td id=\"T_71e01_row26_col0\" class=\"data row26 col0\" >Invariance exponent</td>\n",
       "      <td id=\"T_71e01_row26_col1\" class=\"data row26 col1\" >0.3333</td>\n",
       "      <td id=\"T_71e01_row26_col2\" class=\"data row26 col2\" >0.3333</td>\n",
       "      <td id=\"T_71e01_row26_col3\" class=\"data row26 col3\" >0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row27\" class=\"row_heading level0 row27\" >$$fraction\\_buy\\_orders\\_asset$$</th>\n",
       "      <td id=\"T_71e01_row27_col0\" class=\"data row27 col0\" >Fraction buy orders for indexes and assets</td>\n",
       "      <td id=\"T_71e01_row27_col1\" class=\"data row27 col1\" >0.5000</td>\n",
       "      <td id=\"T_71e01_row27_col2\" class=\"data row27 col2\" >0.1000</td>\n",
       "      <td id=\"T_71e01_row27_col3\" class=\"data row27 col3\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row28\" class=\"row_heading level0 row28\" >$$Bs\\_M$$</th>\n",
       "      <td id=\"T_71e01_row28_col0\" class=\"data row28 col0\" >Number of orders for sparse portfolios of registered assets</td>\n",
       "      <td id=\"T_71e01_row28_col1\" class=\"data row28 col1\" >0</td>\n",
       "      <td id=\"T_71e01_row28_col2\" class=\"data row28 col2\" >0</td>\n",
       "      <td id=\"T_71e01_row28_col3\" class=\"data row28 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row29\" class=\"row_heading level0 row29\" >$$Bs\\_Rmin$$</th>\n",
       "      <td id=\"T_71e01_row29_col0\" class=\"data row29 col0\" >Minimum number of registered assets in sparse order</td>\n",
       "      <td id=\"T_71e01_row29_col1\" class=\"data row29 col1\" >1</td>\n",
       "      <td id=\"T_71e01_row29_col2\" class=\"data row29 col2\" >1</td>\n",
       "      <td id=\"T_71e01_row29_col3\" class=\"data row29 col3\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row30\" class=\"row_heading level0 row30\" >$$Bs\\_Rmax$$</th>\n",
       "      <td id=\"T_71e01_row30_col0\" class=\"data row30 col0\" >Maximum number of registered assets in sparse order</td>\n",
       "      <td id=\"T_71e01_row30_col1\" class=\"data row30 col1\" >5</td>\n",
       "      <td id=\"T_71e01_row30_col2\" class=\"data row30 col2\" >5</td>\n",
       "      <td id=\"T_71e01_row30_col3\" class=\"data row30 col3\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row31\" class=\"row_heading level0 row31\" >$$Bs\\_Wscale$$</th>\n",
       "      <td id=\"T_71e01_row31_col0\" class=\"data row31 col0\" >Scaling factor for size of sparse orders</td>\n",
       "      <td id=\"T_71e01_row31_col1\" class=\"data row31 col1\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row31_col2\" class=\"data row31 col2\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row31_col3\" class=\"data row31 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row32\" class=\"row_heading level0 row32\" >$$Bs\\_std\\_ph\\_dollars$$</th>\n",
       "      <td id=\"T_71e01_row32_col0\" class=\"data row32 col0\" >Std dev of ph minus value based on p0 for sparse order</td>\n",
       "      <td id=\"T_71e01_row32_col1\" class=\"data row32 col1\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row32_col2\" class=\"data row32 col2\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row32_col3\" class=\"data row32 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row33\" class=\"row_heading level0 row33\" >$$Bd\\_M$$</th>\n",
       "      <td id=\"T_71e01_row33_col0\" class=\"data row33 col0\" >Number of orders for dense portfolios of registered assets</td>\n",
       "      <td id=\"T_71e01_row33_col1\" class=\"data row33 col1\" >0</td>\n",
       "      <td id=\"T_71e01_row33_col2\" class=\"data row33 col2\" >0</td>\n",
       "      <td id=\"T_71e01_row33_col3\" class=\"data row33 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row34\" class=\"row_heading level0 row34\" >$$Bd\\_Rmin$$</th>\n",
       "      <td id=\"T_71e01_row34_col0\" class=\"data row34 col0\" >Minimum number of registered assets in dense order</td>\n",
       "      <td id=\"T_71e01_row34_col1\" class=\"data row34 col1\" >20</td>\n",
       "      <td id=\"T_71e01_row34_col2\" class=\"data row34 col2\" >20</td>\n",
       "      <td id=\"T_71e01_row34_col3\" class=\"data row34 col3\" >20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row35\" class=\"row_heading level0 row35\" >$$Bd\\_Rmax$$</th>\n",
       "      <td id=\"T_71e01_row35_col0\" class=\"data row35 col0\" >Maximum number of registered assets in dense order</td>\n",
       "      <td id=\"T_71e01_row35_col1\" class=\"data row35 col1\" >50</td>\n",
       "      <td id=\"T_71e01_row35_col2\" class=\"data row35 col2\" >50</td>\n",
       "      <td id=\"T_71e01_row35_col3\" class=\"data row35 col3\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row36\" class=\"row_heading level0 row36\" >$$Bd\\_Wscale$$</th>\n",
       "      <td id=\"T_71e01_row36_col0\" class=\"data row36 col0\" >Scaling factor for size of dense orders</td>\n",
       "      <td id=\"T_71e01_row36_col1\" class=\"data row36 col1\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row36_col2\" class=\"data row36 col2\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row36_col3\" class=\"data row36 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row37\" class=\"row_heading level0 row37\" >$$Bd\\_std\\_ph\\_dollars$$</th>\n",
       "      <td id=\"T_71e01_row37_col0\" class=\"data row37 col0\" >Std dev of ph minus value based on p0 for dense order</td>\n",
       "      <td id=\"T_71e01_row37_col1\" class=\"data row37 col1\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row37_col2\" class=\"data row37 col2\" >1.0000</td>\n",
       "      <td id=\"T_71e01_row37_col3\" class=\"data row37 col3\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row38\" class=\"row_heading level0 row38\" >$$ew\\_mkt\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row38_col0\" class=\"data row38 col0\" >Probability an index order is for the equally-weighted market index</td>\n",
       "      <td id=\"T_71e01_row38_col1\" class=\"data row38 col1\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row38_col2\" class=\"data row38 col2\" >0.0500</td>\n",
       "      <td id=\"T_71e01_row38_col3\" class=\"data row38 col3\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row39\" class=\"row_heading level0 row39\" >$$vw\\_mkt\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row39_col0\" class=\"data row39 col0\" >Probability an index order is for the value-weighted market index</td>\n",
       "      <td id=\"T_71e01_row39_col1\" class=\"data row39 col1\" >0.7500</td>\n",
       "      <td id=\"T_71e01_row39_col2\" class=\"data row39 col2\" >0.7500</td>\n",
       "      <td id=\"T_71e01_row39_col3\" class=\"data row39 col3\" >0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row40\" class=\"row_heading level0 row40\" >$$ew\\_size\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row40_col0\" class=\"data row40 col0\" >Probability an index order is for an equally-weighted size index</td>\n",
       "      <td id=\"T_71e01_row40_col1\" class=\"data row40 col1\" >0.0250</td>\n",
       "      <td id=\"T_71e01_row40_col2\" class=\"data row40 col2\" >0.0250</td>\n",
       "      <td id=\"T_71e01_row40_col3\" class=\"data row40 col3\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row41\" class=\"row_heading level0 row41\" >$$vw\\_size\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row41_col0\" class=\"data row41 col0\" >Probability an index order is for a value-weighted size index</td>\n",
       "      <td id=\"T_71e01_row41_col1\" class=\"data row41 col1\" >0.0750</td>\n",
       "      <td id=\"T_71e01_row41_col2\" class=\"data row41 col2\" >0.0750</td>\n",
       "      <td id=\"T_71e01_row41_col3\" class=\"data row41 col3\" >0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row42\" class=\"row_heading level0 row42\" >$$ew\\_industry\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row42_col0\" class=\"data row42 col0\" >Probability an index order is for an equally-weighted industry index</td>\n",
       "      <td id=\"T_71e01_row42_col1\" class=\"data row42 col1\" >0.0250</td>\n",
       "      <td id=\"T_71e01_row42_col2\" class=\"data row42 col2\" >0.0250</td>\n",
       "      <td id=\"T_71e01_row42_col3\" class=\"data row42 col3\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71e01_level0_row43\" class=\"row_heading level0 row43\" >$$vw\\_industry\\_index\\_share$$</th>\n",
       "      <td id=\"T_71e01_row43_col0\" class=\"data row43 col0\" >Probability an index order is for a value-weighted industry index</td>\n",
       "      <td id=\"T_71e01_row43_col1\" class=\"data row43 col1\" >0.0750</td>\n",
       "      <td id=\"T_71e01_row43_col2\" class=\"data row43 col2\" >0.0750</td>\n",
       "      <td id=\"T_71e01_row43_col3\" class=\"data row43 col3\" >0.0750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf1e4e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a1edf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a1edf_level0_col0\" class=\"col_heading level0 col0\" >Base</th>\n",
       "      <th id=\"T_a1edf_level0_col1\" class=\"col_heading level0 col1\" >Low</th>\n",
       "      <th id=\"T_a1edf_level0_col2\" class=\"col_heading level0 col2\" >High</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Description</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row0\" class=\"row_heading level0 row0\" >Number of assets</th>\n",
       "      <td id=\"T_a1edf_row0_col0\" class=\"data row0 col0\" >500</td>\n",
       "      <td id=\"T_a1edf_row0_col1\" class=\"data row0 col1\" >.</td>\n",
       "      <td id=\"T_a1edf_row0_col2\" class=\"data row0 col2\" >.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row1\" class=\"row_heading level0 row1\" >Number of orders</th>\n",
       "      <td id=\"T_a1edf_row1_col0\" class=\"data row1 col0\" >100000</td>\n",
       "      <td id=\"T_a1edf_row1_col1\" class=\"data row1 col1\" >.</td>\n",
       "      <td id=\"T_a1edf_row1_col2\" class=\"data row1 col2\" >.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row2\" class=\"row_heading level0 row2\" >Slope of exchange's demand schedule (shares traded per dollar price change at \\$100/share)</th>\n",
       "      <td id=\"T_a1edf_row2_col0\" class=\"data row2 col0\" >0.0100</td>\n",
       "      <td id=\"T_a1edf_row2_col1\" class=\"data row2 col1\" >.</td>\n",
       "      <td id=\"T_a1edf_row2_col2\" class=\"data row2 col2\" >.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row3\" class=\"row_heading level0 row3\" >Fraction of orders for individual assets</th>\n",
       "      <td id=\"T_a1edf_row3_col0\" class=\"data row3 col0\" >0.5000</td>\n",
       "      <td id=\"T_a1edf_row3_col1\" class=\"data row3 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row3_col2\" class=\"data row3 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row4\" class=\"row_heading level0 row4\" >Fraction of orders for indexes among orders for portfolios</th>\n",
       "      <td id=\"T_a1edf_row4_col0\" class=\"data row4 col0\" >0.5000</td>\n",
       "      <td id=\"T_a1edf_row4_col1\" class=\"data row4 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row4_col2\" class=\"data row4 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row5\" class=\"row_heading level0 row5\" >Number of size indexes</th>\n",
       "      <td id=\"T_a1edf_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_a1edf_row5_col1\" class=\"data row5 col1\" >2</td>\n",
       "      <td id=\"T_a1edf_row5_col2\" class=\"data row5 col2\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row6\" class=\"row_heading level0 row6\" >Number of industry indexes</th>\n",
       "      <td id=\"T_a1edf_row6_col0\" class=\"data row6 col0\" >10</td>\n",
       "      <td id=\"T_a1edf_row6_col1\" class=\"data row6 col1\" >2</td>\n",
       "      <td id=\"T_a1edf_row6_col2\" class=\"data row6 col2\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row7\" class=\"row_heading level0 row7\" >Probability an index order is a market index order</th>\n",
       "      <td id=\"T_a1edf_row7_col0\" class=\"data row7 col0\" >0.8000</td>\n",
       "      <td id=\"T_a1edf_row7_col1\" class=\"data row7 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row7_col2\" class=\"data row7 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row8\" class=\"row_heading level0 row8\" >Probability a size or industry index order is a size index order</th>\n",
       "      <td id=\"T_a1edf_row8_col0\" class=\"data row8 col0\" >0.5000</td>\n",
       "      <td id=\"T_a1edf_row8_col1\" class=\"data row8 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row8_col2\" class=\"data row8 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row9\" class=\"row_heading level0 row9\" >Probability a mkt index order is an EW mkt index order</th>\n",
       "      <td id=\"T_a1edf_row9_col0\" class=\"data row9 col0\" >0.0625</td>\n",
       "      <td id=\"T_a1edf_row9_col1\" class=\"data row9 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row9_col2\" class=\"data row9 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row10\" class=\"row_heading level0 row10\" >Probability a size index order is an EW size index order</th>\n",
       "      <td id=\"T_a1edf_row10_col0\" class=\"data row10 col0\" >0.2500</td>\n",
       "      <td id=\"T_a1edf_row10_col1\" class=\"data row10 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row10_col2\" class=\"data row10 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row11\" class=\"row_heading level0 row11\" >Probability an industry index order is an EW industry index order</th>\n",
       "      <td id=\"T_a1edf_row11_col0\" class=\"data row11 col0\" >0.2500</td>\n",
       "      <td id=\"T_a1edf_row11_col1\" class=\"data row11 col1\" >0.0500</td>\n",
       "      <td id=\"T_a1edf_row11_col2\" class=\"data row11 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row12\" class=\"row_heading level0 row12\" >Standard deviation of expected number of orders across assets</th>\n",
       "      <td id=\"T_a1edf_row12_col0\" class=\"data row12 col0\" >1.7000</td>\n",
       "      <td id=\"T_a1edf_row12_col1\" class=\"data row12 col1\" >0.1000</td>\n",
       "      <td id=\"T_a1edf_row12_col2\" class=\"data row12 col2\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row13\" class=\"row_heading level0 row13\" >Standard deviation of order size given asset</th>\n",
       "      <td id=\"T_a1edf_row13_col0\" class=\"data row13 col0\" >1.5000</td>\n",
       "      <td id=\"T_a1edf_row13_col1\" class=\"data row13 col1\" >0.1000</td>\n",
       "      <td id=\"T_a1edf_row13_col2\" class=\"data row13 col2\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row14\" class=\"row_heading level0 row14\" >Standard deviation of upper limit price as fraction of initial price</th>\n",
       "      <td id=\"T_a1edf_row14_col0\" class=\"data row14 col0\" >0.1000</td>\n",
       "      <td id=\"T_a1edf_row14_col1\" class=\"data row14 col1\" >0.0100</td>\n",
       "      <td id=\"T_a1edf_row14_col2\" class=\"data row14 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row15\" class=\"row_heading level0 row15\" >Mean deviation of upper limit price as fraction of initial price standard deviation</th>\n",
       "      <td id=\"T_a1edf_row15_col0\" class=\"data row15 col0\" >0.3000</td>\n",
       "      <td id=\"T_a1edf_row15_col1\" class=\"data row15 col1\" >0.0100</td>\n",
       "      <td id=\"T_a1edf_row15_col2\" class=\"data row15 col2\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row16\" class=\"row_heading level0 row16\" >Mean difference between upper and lower limit prices (basis points)</th>\n",
       "      <td id=\"T_a1edf_row16_col0\" class=\"data row16 col0\" >1.0000</td>\n",
       "      <td id=\"T_a1edf_row16_col1\" class=\"data row16 col1\" >0.0100</td>\n",
       "      <td id=\"T_a1edf_row16_col2\" class=\"data row16 col2\" >100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row17\" class=\"row_heading level0 row17\" >Standard deviation of difference between upper and lower limit prices</th>\n",
       "      <td id=\"T_a1edf_row17_col0\" class=\"data row17 col0\" >2.0000</td>\n",
       "      <td id=\"T_a1edf_row17_col1\" class=\"data row17 col1\" >0.1000</td>\n",
       "      <td id=\"T_a1edf_row17_col2\" class=\"data row17 col2\" >3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1edf_level0_row18\" class=\"row_heading level0 row18\" >Fraction buy orders for indexes and assets</th>\n",
       "      <td id=\"T_a1edf_row18_col0\" class=\"data row18 col0\" >0.5000</td>\n",
       "      <td id=\"T_a1edf_row18_col1\" class=\"data row18 col1\" >0.1000</td>\n",
       "      <td id=\"T_a1edf_row18_col2\" class=\"data row18 col2\" >0.9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf46c2310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.03482508659362793  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_assumptions_table():\n",
    "    \n",
    "    c = Assumptions()\n",
    "    df = c.make_documentation_table()\n",
    "    df = df.set_index('Parameter')\n",
    "\n",
    "    # Even though no simulations are performed, \n",
    "    # we need instance of Simulations to get parameter values defined for hard and easy cases:\n",
    "    sim = Simulations()\n",
    "\n",
    "    # Add column of hard parameter values by changing base values one by one:\n",
    "    dhard = sim.dd_difficulty['high']\n",
    "    df['High'] = df['Base'].copy()\n",
    "    for k, v in dhard.items():\n",
    "        df.loc[k, 'High'] = v\n",
    "\n",
    "    # Add column of easy parameter values by changin base values one by one:\n",
    "    deasy = sim.dd_difficulty['low']\n",
    "    df['Low'] = df['Base'].copy()\n",
    "    for k, v in deasy.items():\n",
    "        df.loc[k, 'Low'] = v\n",
    "\n",
    "    # Format parameter names for latex, either as math or non-math:    \n",
    "\n",
    "    df = df.reset_index()\n",
    "    vns = ['Parameter', 'Description', 'Base', 'Low', 'High']\n",
    "    df = df[vns]\n",
    "\n",
    "    b_put_parameter_names_in_math_mode = True if RUN_TYPE == 'workstation' else True if RUN_TYPE == 'laptop' else True\n",
    "    if b_put_parameter_names_in_math_mode == True:\n",
    "        # The next line will save the latex file with variable names in math italics,\n",
    "        # but it will display incorrectly due to an apparent bug in pandas:\n",
    "        df['Parameter'] = '$$' + df['Parameter'].str.replace('_', '\\_') + '$$'\n",
    "        #df['Parameter'] = '$$' + df['Parameter'] + '$$'\n",
    "    else:\n",
    "        # The next line will save the latex file with variable names in non-math regular font,\n",
    "        # but it will display the backslash that latex needs to escape the underscore character:\n",
    "        #df['Parameter'] = df['Parameter'].str.replace('_', '\\_')\n",
    "        pass\n",
    "        \n",
    "    df = df.set_index(['Parameter'])\n",
    "\n",
    "    # Format printing of parameter values so extreme values are in scientific notation\n",
    "    \n",
    "    # The function format_pd implements different formatting for different values:    \n",
    "    #format_pd = (lambda s: \"{:}\".format(s) if type(s)==int \n",
    "    #        else \"{:.2e}\".format(s) if s < 0.00999999\n",
    "    #        else \"{:.2e}\".format(s) if s > 100.00 \n",
    "    #        else \"{:.4f}\".format(s))\n",
    "\n",
    "    dfs = df.style.format(precision=2, na_rep='.', thousands=\"\", \n",
    "                formatter={#'Parameter' : \"\\\\emph{{{}}}\",\n",
    "                            'Base' : format_pd,\n",
    "                           'High' : format_pd,\n",
    "                           'Low' : format_pd,\n",
    "                          })    \n",
    "    \n",
    "    if B_SAVE_RESULTS == True:\n",
    "        ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "        #dfs.to_latex(LATEX_PATH + \"assumptions_table_latex_tbl_\" + ts + \"_\" + RUN_TYPE + \".txt\", hrules=True)\n",
    "        fp = LATEX_PATH + \"assumptions_table_latex_tbl_\" + ts + \"_\" + RUN_TYPE + \".txt\"\n",
    "        s = dfs.to_latex(buf=None, hrules=True)\n",
    "        s = s.replace('_', '\\_')\n",
    "        s = s.replace('\\\\_', '\\_')\n",
    "        with open(fp, \"w+\") as f:\n",
    "            f.writelines(s)\n",
    "\n",
    "    # There seems to be a pandas error in displaying the table correctly; \n",
    "    # the width of the column of parameter names is messed up.    \n",
    "    display(dfs)\n",
    "\n",
    "    df_no_names = df.copy()\n",
    "    \n",
    "    d = {'$$N$$' : 100, '$$M$$' : 200, \n",
    "                    '$$exch\\_epsilon$$' : 300, '$$exch\\_phpl\\_frac$$' : 9999, \n",
    "                    '$$stab\\_max\\_qv$$' : 9999, '$$stab\\_ph\\_frac$$' : 9999, '$$stab\\_pl\\_frac$$' : 9999, \n",
    "                    '$$fracMA$$' : 400, '$$subfracMX$$' : 410, \n",
    "                    '$$num\\_size\\_indexes$$' : 500, '$$num\\_industry\\_indexes$$' : 510, \n",
    "                     \n",
    "                     '$$market\\_index\\_share$$' : 600, \n",
    "                     '$$size\\_index\\_subshare$$' : 610, \n",
    "                     '$$ew\\_mkt\\_index\\_subshare$$' : 620,\n",
    "                     '$$ew\\_size\\_index\\_subsubshare$$' : 630,\n",
    "                     '$$ew\\_industry\\_index\\_subsubshare$$' : 640,\n",
    "         \n",
    "                    #'$$ew\\_index\\_subshare$$' : 9999, '$$ew\\_size\\_index\\_subsubshare$$' : 9999, \n",
    "                    #'$$ew\\_industry\\_index\\_subsubshare$$' : 9999,\n",
    "                    #'$$ew\\_mkt\\_index\\_share$$' : 610, '$$vw\\_mkt\\_index\\_share$$' : 600,\n",
    "                    #'$$ew\\_size\\_index\\_share$$' :630, '$$vw\\_size\\_index\\_share$$' : 620, \n",
    "                    #'$$ew\\_industry\\_index\\_share$$' :650, '$$vw\\_industry\\_index\\_share$$' : 640\n",
    "                    \n",
    "                    '$$std\\_num\\_orders\\_asset$$' : 700, '$$std\\_order\\_size$$' : 710,\n",
    "                    #'$$dv\\_single\\_asset\\_orders$$' : 800,\n",
    "                    '$$std\\_limit\\_price$$' : 900, '$$limit\\_bias$$' : 910, \n",
    "                    '$$avg\\_ph\\_minus\\_pl\\_bp$$' : 920, '$$std\\_ph\\_minus\\_pl$$' : 930, \n",
    "                    '$$index\\_prices$$' : 9999, '$$mean\\_asset\\_price$$' : 9999, '$$std\\_asset\\_price$$' : 9999, \n",
    "                    '$$invariance\\_exponent$$' : 9999, \n",
    "                    '$$fraction\\_buy\\_orders\\_asset$$' :1500, \n",
    "                    }\n",
    "         \n",
    "    df['sort_order'] = 9999\n",
    "    for k in d:\n",
    "        df_no_names.loc[k, 'sort_order'] = d[k]\n",
    "    \n",
    "    df_no_names = df_no_names.sort_values(['sort_order'])\n",
    "\n",
    "    vns_no_hl_data = ['$$N$$', '$$M$$', '$$exch\\_epsilon$$', \n",
    "                    '$$ew\\_mkt\\_index\\_share$$', '$$vw\\_mkt\\_index\\_share$$',\n",
    "                    '$$ew\\_size\\_index\\_share$$', '$$vw\\_size\\_index\\_share$$', \n",
    "                    '$$ew\\_industry\\_index\\_share$$', '$$vw\\_industry\\_index\\_share$$']\n",
    "    \n",
    "    for vn in vns_no_hl_data:\n",
    "        df_no_names.loc[vn, 'Low'] = np.nan\n",
    "        df_no_names.loc[vn, 'High'] = np.nan\n",
    "    \n",
    "    df_no_names = df_no_names.reset_index(drop=True)\n",
    "    df_no_names = df_no_names.set_index('Description')\n",
    "        \n",
    "    vns = ['Base', 'Low', 'High']  # 'Description' is the index!\n",
    "    bkeep = df_no_names['sort_order'] < 9000\n",
    "    df_no_names = df_no_names.loc[bkeep, vns]\n",
    "    \n",
    "    dfs_no_names = df_no_names.style.format(precision=4, na_rep='.', thousands=\"\", \n",
    "                formatter={#'Parameter' : \"\\\\emph{{{}}}\",\n",
    "                            'Base' : format_pd,\n",
    "                           'High' : format_pd,\n",
    "                           'Low' : format_pd,\n",
    "                          })    \n",
    "    \n",
    "\n",
    "    if B_SAVE_RESULTS == True:\n",
    "        ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "        #dfs.to_latex(LATEX_PATH + \"parameter_table_no_names_latex_tbl_01_\" + ts + \".txt\", hrules=True)\n",
    "        fp = LATEX_PATH + \"assumptions_table_no_names_latex_tbl_\" + ts + \"_\" + RUN_TYPE + \".txt\"\n",
    "        s = dfs_no_names.to_latex(buf=None, hrules=True)\n",
    "        s = s.replace('_', '\\_')\n",
    "        with open(fp, \"w+\") as f:\n",
    "            f.writelines(s)\n",
    "        \n",
    "    display(dfs_no_names)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_assumptions_table = make_assumptions_table()\n",
    "\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 1: the baseline scenario \n",
    "\n",
    "1. Number of assets = 500, number of orders = 100,000 (PK changed default Assumptions to N=500, M=100000.)\n",
    "2. Would add numbers for result 4 in the same table (1000 assets and 3000 assets, 500,000 orders and 1,000,000 orders) (PK: David to consider 3 x 3 = 27 cases. Might take several hours to do 101 reps.)\n",
    "3. All with the baseline parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreps =  3\n",
      "difficulty =  ['base']\n",
      "change_few =  ['mina1test']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i =  0\n",
      "difficulty =  base  =  {}\n",
      "change_few =  {'N': 10, 'M': 20}\n",
      "self.dd_difficulty[diff]=  {}\n",
      "sz =  {'N': 10, 'M': 20}\n",
      "d =  {}\n",
      "Assumptions =  Assumptions(N=10, M=20, exch_liq_model='mina', exch_epsilon=0.01, exch_phpl_frac=100.0, stab_max_qv=0.0, stab_ph_frac=0.7, stab_pl_frac=0.2, fracMA=0.5, subfracMX=0.5, num_size_indexes=5, num_industry_indexes=10, market_index_share=0.8, size_index_subshare=0.5, ew_mkt_index_subshare=0.0625, ew_size_index_subsubshare=0.25, ew_industry_index_subsubshare=0.25, ew_size_index_alpha=0.0, std_num_orders_asset=1.7, std_order_size=1.5, dv_single_asset_orders=10000000.0, std_limit_price=0.1, limit_bias=0.3, avg_ph_minus_pl_bp=1.0, std_ph_minus_pl=2.0, index_prices=100.0, mean_asset_price=100.0, std_asset_price=0.0, invariance_exponent=0.3333333333333333, fraction_buy_orders_asset=0.5, Bs_M=0, Bs_Rmin=1, Bs_Rmax=5, Bs_Wscale=1.0, Bs_std_ph_dollars=1.0, Bd_M=0, Bd_Rmin=20, Bd_Rmax=50, Bd_Wscale=1.0, Bd_std_ph_dollars=1.0, fracMX=0.25, fracM2=0.25, MX=5, M2=5, MA=10, M0=20, M0s=0, M1=15, Mall=40, NX=32, NR=42, ew_mkt_index_share=0.05, vw_mkt_index_share=0.75, industry_index_subshare=0.5, ew_size_index_share=0.024999999999999994, vw_size_index_share=0.07499999999999998, ew_industry_index_share=0.024999999999999994, vw_industry_index_share=0.07499999999999998) \n",
      "\n",
      "0 base {'N': 10, 'M': 20}\n",
      "changes =  none  =  {}\n",
      "dt= 0.2564, ucpM=1.21e-04, expM=3.15e-01,  it=26, f=False, ch=0, pm= 96.78, pstd= 4.79, exq=0, stq=0, stac=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                            | 2/3 [00:24<00:12, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i =  2\n",
      "difficulty =  base  =  {}\n",
      "change_few =  {'N': 10, 'M': 20}\n",
      "self.dd_difficulty[diff]=  {}\n",
      "sz =  {'N': 10, 'M': 20}\n",
      "d =  {}\n",
      "2 base {'N': 10, 'M': 20}\n",
      "changes =  none  =  {}\n",
      "dt= 0.2071, ucpM=1.40e-04, expM=2.36e+01,  it=24, f=False, ch=0, pm= 90.28, pstd= 150.72, exq=0, stq=0, stac=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:35<00:00, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/sim1_RZtest_2023-1204-2043.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  35.5911169052124  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate1():\n",
    "\n",
    "    sim = Simulations(name_prefix=\"sim1\")\n",
    "        # These are options for the quadratic programming algorithm:\n",
    "\n",
    "    nreps = 101 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "\n",
    "    #sim.dd_difficulty['test_base'] = {'N' : 10, 'M' : 1000}\n",
    "    difficulty = ['base'] \n",
    "\n",
    "    sim.dvd_change_few['mina1dm'] = [{'N' : n, 'M' : m} for n in [10, 500, 1000, 2000, 3000] \n",
    "                    for m in [20, 100000,  500000, 1000000, 2000000, 4000000]]\n",
    "    sim.dvd_change_few['mina1pk'] = [{'N' : n, 'M' : m} for n in [10, 500, 1000, 2000] \n",
    "                                     for m in [20, 100000, 500000, 1000000, 2000000]]\n",
    "    sim.dvd_change_few['mina1test'] = [{'N' : n, 'M' : m} for n in [10, 500, 1000] for m in [20, 100000, 1000000]]\n",
    "\n",
    "    change_few = (['mina1dm'] if RUN_TYPE == 'workstation' \n",
    "            else ['mina1pk'] if RUN_TYPE == 'laptop' \n",
    "            else ['mina1test'])\n",
    "\n",
    "    #sim.dvd_change_many['test_many'] = [{'exch_phpl_frac' : 1.00e-1}, {'fracMA' : 0.99}]\n",
    "    change_many = ['none']\n",
    "    \n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            num_print=1, name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim1 = simulate1()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_88d0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88d0a_level0_col0\" class=\"col_heading level0 col0\" >difficulty</th>\n",
       "      <th id=\"T_88d0a_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_88d0a_level0_col2\" class=\"col_heading level0 col2\" >M</th>\n",
       "      <th id=\"T_88d0a_level0_col3\" class=\"col_heading level0 col3\" >dt_med</th>\n",
       "      <th id=\"T_88d0a_level0_col4\" class=\"col_heading level0 col4\" >dt_std</th>\n",
       "      <th id=\"T_88d0a_level0_col5\" class=\"col_heading level0 col5\" >niter_med</th>\n",
       "      <th id=\"T_88d0a_level0_col6\" class=\"col_heading level0 col6\" >niter_max</th>\n",
       "      <th id=\"T_88d0a_level0_col7\" class=\"col_heading level0 col7\" >unclpM</th>\n",
       "      <th id=\"T_88d0a_level0_col8\" class=\"col_heading level0 col8\" >exchpM</th>\n",
       "      <th id=\"T_88d0a_level0_col9\" class=\"col_heading level0 col9\" >stabpM</th>\n",
       "      <th id=\"T_88d0a_level0_col10\" class=\"col_heading level0 col10\" >p</th>\n",
       "      <th id=\"T_88d0a_level0_col11\" class=\"col_heading level0 col11\" >p_std</th>\n",
       "      <th id=\"T_88d0a_level0_col12\" class=\"col_heading level0 col12\" >count</th>\n",
       "      <th id=\"T_88d0a_level0_col13\" class=\"col_heading level0 col13\" >num_exch_full</th>\n",
       "      <th id=\"T_88d0a_level0_col14\" class=\"col_heading level0 col14\" >num_stab_full</th>\n",
       "      <th id=\"T_88d0a_level0_col15\" class=\"col_heading level0 col15\" >num_stab_active</th>\n",
       "      <th id=\"T_88d0a_level0_col16\" class=\"col_heading level0 col16\" >bchofail</th>\n",
       "      <th id=\"T_88d0a_level0_col17\" class=\"col_heading level0 col17\" >bmaxiter</th>\n",
       "      <th id=\"T_88d0a_level0_col18\" class=\"col_heading level0 col18\" >niter</th>\n",
       "      <th id=\"T_88d0a_level0_col19\" class=\"col_heading level0 col19\" >unclpM_max</th>\n",
       "      <th id=\"T_88d0a_level0_col20\" class=\"col_heading level0 col20\" >n_bad_p</th>\n",
       "      <th id=\"T_88d0a_level0_col21\" class=\"col_heading level0 col21\" >nchreg</th>\n",
       "      <th id=\"T_88d0a_level0_col22\" class=\"col_heading level0 col22\" >dvM</th>\n",
       "      <th id=\"T_88d0a_level0_col23\" class=\"col_heading level0 col23\" >condnum_med</th>\n",
       "      <th id=\"T_88d0a_level0_col24\" class=\"col_heading level0 col24\" >dt_max</th>\n",
       "      <th id=\"T_88d0a_level0_col25\" class=\"col_heading level0 col25\" >dt_min</th>\n",
       "      <th id=\"T_88d0a_level0_col26\" class=\"col_heading level0 col26\" >dt</th>\n",
       "      <th id=\"T_88d0a_level0_col27\" class=\"col_heading level0 col27\" >exchpM_max</th>\n",
       "      <th id=\"T_88d0a_level0_col28\" class=\"col_heading level0 col28\" >exchpM_med</th>\n",
       "      <th id=\"T_88d0a_level0_col29\" class=\"col_heading level0 col29\" >exchpM_min</th>\n",
       "      <th id=\"T_88d0a_level0_col30\" class=\"col_heading level0 col30\" >exchpM_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88d0a_row0_col0\" class=\"data row0 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row0_col1\" class=\"data row0 col1\" >10</td>\n",
       "      <td id=\"T_88d0a_row0_col2\" class=\"data row0 col2\" >20</td>\n",
       "      <td id=\"T_88d0a_row0_col3\" class=\"data row0 col3\" >0.2478</td>\n",
       "      <td id=\"T_88d0a_row0_col4\" class=\"data row0 col4\" >0.0264</td>\n",
       "      <td id=\"T_88d0a_row0_col5\" class=\"data row0 col5\" >24</td>\n",
       "      <td id=\"T_88d0a_row0_col6\" class=\"data row0 col6\" >26</td>\n",
       "      <td id=\"T_88d0a_row0_col7\" class=\"data row0 col7\" >8.8e-05</td>\n",
       "      <td id=\"T_88d0a_row0_col8\" class=\"data row0 col8\" >8.1e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col9\" class=\"data row0 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col10\" class=\"data row0 col10\" >88.7419</td>\n",
       "      <td id=\"T_88d0a_row0_col11\" class=\"data row0 col11\" >55.9934</td>\n",
       "      <td id=\"T_88d0a_row0_col12\" class=\"data row0 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row0_col13\" class=\"data row0 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col14\" class=\"data row0 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col15\" class=\"data row0 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col16\" class=\"data row0 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col17\" class=\"data row0 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col18\" class=\"data row0 col18\" >24.6667</td>\n",
       "      <td id=\"T_88d0a_row0_col19\" class=\"data row0 col19\" >1.40e-04</td>\n",
       "      <td id=\"T_88d0a_row0_col20\" class=\"data row0 col20\" >2.0000</td>\n",
       "      <td id=\"T_88d0a_row0_col21\" class=\"data row0 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row0_col22\" class=\"data row0 col22\" >36.3858</td>\n",
       "      <td id=\"T_88d0a_row0_col23\" class=\"data row0 col23\" >4.84e+11</td>\n",
       "      <td id=\"T_88d0a_row0_col24\" class=\"data row0 col24\" >0.2564</td>\n",
       "      <td id=\"T_88d0a_row0_col25\" class=\"data row0 col25\" >0.2071</td>\n",
       "      <td id=\"T_88d0a_row0_col26\" class=\"data row0 col26\" >0.2371</td>\n",
       "      <td id=\"T_88d0a_row0_col27\" class=\"data row0 col27\" >23.6017</td>\n",
       "      <td id=\"T_88d0a_row0_col28\" class=\"data row0 col28\" >0.3152</td>\n",
       "      <td id=\"T_88d0a_row0_col29\" class=\"data row0 col29\" >0.2398</td>\n",
       "      <td id=\"T_88d0a_row0_col30\" class=\"data row0 col30\" >13.4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_88d0a_row1_col0\" class=\"data row1 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "      <td id=\"T_88d0a_row1_col2\" class=\"data row1 col2\" >100000</td>\n",
       "      <td id=\"T_88d0a_row1_col3\" class=\"data row1 col3\" >0.2806</td>\n",
       "      <td id=\"T_88d0a_row1_col4\" class=\"data row1 col4\" >0.0754</td>\n",
       "      <td id=\"T_88d0a_row1_col5\" class=\"data row1 col5\" >22</td>\n",
       "      <td id=\"T_88d0a_row1_col6\" class=\"data row1 col6\" >25</td>\n",
       "      <td id=\"T_88d0a_row1_col7\" class=\"data row1 col7\" >5.7e-08</td>\n",
       "      <td id=\"T_88d0a_row1_col8\" class=\"data row1 col8\" >1.6e-02</td>\n",
       "      <td id=\"T_88d0a_row1_col9\" class=\"data row1 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col10\" class=\"data row1 col10\" >99.1216</td>\n",
       "      <td id=\"T_88d0a_row1_col11\" class=\"data row1 col11\" >0.5929</td>\n",
       "      <td id=\"T_88d0a_row1_col12\" class=\"data row1 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row1_col13\" class=\"data row1 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col14\" class=\"data row1 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col15\" class=\"data row1 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col16\" class=\"data row1 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col17\" class=\"data row1 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col18\" class=\"data row1 col18\" >22.6667</td>\n",
       "      <td id=\"T_88d0a_row1_col19\" class=\"data row1 col19\" >1.32e-07</td>\n",
       "      <td id=\"T_88d0a_row1_col20\" class=\"data row1 col20\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col21\" class=\"data row1 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row1_col22\" class=\"data row1 col22\" >57.4836</td>\n",
       "      <td id=\"T_88d0a_row1_col23\" class=\"data row1 col23\" >1.42e+03</td>\n",
       "      <td id=\"T_88d0a_row1_col24\" class=\"data row1 col24\" >0.3789</td>\n",
       "      <td id=\"T_88d0a_row1_col25\" class=\"data row1 col25\" >0.2307</td>\n",
       "      <td id=\"T_88d0a_row1_col26\" class=\"data row1 col26\" >0.2967</td>\n",
       "      <td id=\"T_88d0a_row1_col27\" class=\"data row1 col27\" >0.0210</td>\n",
       "      <td id=\"T_88d0a_row1_col28\" class=\"data row1 col28\" >0.0175</td>\n",
       "      <td id=\"T_88d0a_row1_col29\" class=\"data row1 col29\" >0.0100</td>\n",
       "      <td id=\"T_88d0a_row1_col30\" class=\"data row1 col30\" >5.60e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_88d0a_row2_col0\" class=\"data row2 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row2_col1\" class=\"data row2 col1\" >10</td>\n",
       "      <td id=\"T_88d0a_row2_col2\" class=\"data row2 col2\" >1000000</td>\n",
       "      <td id=\"T_88d0a_row2_col3\" class=\"data row2 col3\" >0.6323</td>\n",
       "      <td id=\"T_88d0a_row2_col4\" class=\"data row2 col4\" >0.0385</td>\n",
       "      <td id=\"T_88d0a_row2_col5\" class=\"data row2 col5\" >22</td>\n",
       "      <td id=\"T_88d0a_row2_col6\" class=\"data row2 col6\" >27</td>\n",
       "      <td id=\"T_88d0a_row2_col7\" class=\"data row2 col7\" >1.6e-04</td>\n",
       "      <td id=\"T_88d0a_row2_col8\" class=\"data row2 col8\" >1.7e-02</td>\n",
       "      <td id=\"T_88d0a_row2_col9\" class=\"data row2 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col10\" class=\"data row2 col10\" >99.0742</td>\n",
       "      <td id=\"T_88d0a_row2_col11\" class=\"data row2 col11\" >0.2913</td>\n",
       "      <td id=\"T_88d0a_row2_col12\" class=\"data row2 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row2_col13\" class=\"data row2 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col14\" class=\"data row2 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col15\" class=\"data row2 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col16\" class=\"data row2 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col17\" class=\"data row2 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col18\" class=\"data row2 col18\" >23.0000</td>\n",
       "      <td id=\"T_88d0a_row2_col19\" class=\"data row2 col19\" >4.21e-04</td>\n",
       "      <td id=\"T_88d0a_row2_col20\" class=\"data row2 col20\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col21\" class=\"data row2 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row2_col22\" class=\"data row2 col22\" >57.4333</td>\n",
       "      <td id=\"T_88d0a_row2_col23\" class=\"data row2 col23\" >2.80e+03</td>\n",
       "      <td id=\"T_88d0a_row2_col24\" class=\"data row2 col24\" >0.6946</td>\n",
       "      <td id=\"T_88d0a_row2_col25\" class=\"data row2 col25\" >0.6242</td>\n",
       "      <td id=\"T_88d0a_row2_col26\" class=\"data row2 col26\" >0.6504</td>\n",
       "      <td id=\"T_88d0a_row2_col27\" class=\"data row2 col27\" >0.0290</td>\n",
       "      <td id=\"T_88d0a_row2_col28\" class=\"data row2 col28\" >0.0106</td>\n",
       "      <td id=\"T_88d0a_row2_col29\" class=\"data row2 col29\" >0.0106</td>\n",
       "      <td id=\"T_88d0a_row2_col30\" class=\"data row2 col30\" >0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_88d0a_row3_col0\" class=\"data row3 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row3_col1\" class=\"data row3 col1\" >500</td>\n",
       "      <td id=\"T_88d0a_row3_col2\" class=\"data row3 col2\" >20</td>\n",
       "      <td id=\"T_88d0a_row3_col3\" class=\"data row3 col3\" >0.3232</td>\n",
       "      <td id=\"T_88d0a_row3_col4\" class=\"data row3 col4\" >0.1644</td>\n",
       "      <td id=\"T_88d0a_row3_col5\" class=\"data row3 col5\" >31</td>\n",
       "      <td id=\"T_88d0a_row3_col6\" class=\"data row3 col6\" >32</td>\n",
       "      <td id=\"T_88d0a_row3_col7\" class=\"data row3 col7\" >1.8e-03</td>\n",
       "      <td id=\"T_88d0a_row3_col8\" class=\"data row3 col8\" >2.1e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col9\" class=\"data row3 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col10\" class=\"data row3 col10\" >100.0104</td>\n",
       "      <td id=\"T_88d0a_row3_col11\" class=\"data row3 col11\" >1.5925</td>\n",
       "      <td id=\"T_88d0a_row3_col12\" class=\"data row3 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row3_col13\" class=\"data row3 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col14\" class=\"data row3 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col15\" class=\"data row3 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col16\" class=\"data row3 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col17\" class=\"data row3 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col18\" class=\"data row3 col18\" >29.6667</td>\n",
       "      <td id=\"T_88d0a_row3_col19\" class=\"data row3 col19\" >4.97e-03</td>\n",
       "      <td id=\"T_88d0a_row3_col20\" class=\"data row3 col20\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col21\" class=\"data row3 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row3_col22\" class=\"data row3 col22\" >11.6763</td>\n",
       "      <td id=\"T_88d0a_row3_col23\" class=\"data row3 col23\" >4.95e+11</td>\n",
       "      <td id=\"T_88d0a_row3_col24\" class=\"data row3 col24\" >0.5807</td>\n",
       "      <td id=\"T_88d0a_row3_col25\" class=\"data row3 col25\" >0.2749</td>\n",
       "      <td id=\"T_88d0a_row3_col26\" class=\"data row3 col26\" >0.3930</td>\n",
       "      <td id=\"T_88d0a_row3_col27\" class=\"data row3 col27\" >3.8182</td>\n",
       "      <td id=\"T_88d0a_row3_col28\" class=\"data row3 col28\" >1.9893</td>\n",
       "      <td id=\"T_88d0a_row3_col29\" class=\"data row3 col29\" >0.6399</td>\n",
       "      <td id=\"T_88d0a_row3_col30\" class=\"data row3 col30\" >1.5952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_88d0a_row4_col0\" class=\"data row4 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row4_col1\" class=\"data row4 col1\" >500</td>\n",
       "      <td id=\"T_88d0a_row4_col2\" class=\"data row4 col2\" >100000</td>\n",
       "      <td id=\"T_88d0a_row4_col3\" class=\"data row4 col3\" >0.3474</td>\n",
       "      <td id=\"T_88d0a_row4_col4\" class=\"data row4 col4\" >0.0245</td>\n",
       "      <td id=\"T_88d0a_row4_col5\" class=\"data row4 col5\" >32</td>\n",
       "      <td id=\"T_88d0a_row4_col6\" class=\"data row4 col6\" >33</td>\n",
       "      <td id=\"T_88d0a_row4_col7\" class=\"data row4 col7\" >7.7e-07</td>\n",
       "      <td id=\"T_88d0a_row4_col8\" class=\"data row4 col8\" >3.4e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col9\" class=\"data row4 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col10\" class=\"data row4 col10\" >99.8053</td>\n",
       "      <td id=\"T_88d0a_row4_col11\" class=\"data row4 col11\" >10.4702</td>\n",
       "      <td id=\"T_88d0a_row4_col12\" class=\"data row4 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row4_col13\" class=\"data row4 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col14\" class=\"data row4 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col15\" class=\"data row4 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col16\" class=\"data row4 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col17\" class=\"data row4 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col18\" class=\"data row4 col18\" >32.0000</td>\n",
       "      <td id=\"T_88d0a_row4_col19\" class=\"data row4 col19\" >1.20e-06</td>\n",
       "      <td id=\"T_88d0a_row4_col20\" class=\"data row4 col20\" >0.6667</td>\n",
       "      <td id=\"T_88d0a_row4_col21\" class=\"data row4 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row4_col22\" class=\"data row4 col22\" >84.7447</td>\n",
       "      <td id=\"T_88d0a_row4_col23\" class=\"data row4 col23\" >6.22e+09</td>\n",
       "      <td id=\"T_88d0a_row4_col24\" class=\"data row4 col24\" >0.3823</td>\n",
       "      <td id=\"T_88d0a_row4_col25\" class=\"data row4 col25\" >0.3351</td>\n",
       "      <td id=\"T_88d0a_row4_col26\" class=\"data row4 col26\" >0.3549</td>\n",
       "      <td id=\"T_88d0a_row4_col27\" class=\"data row4 col27\" >3.7898</td>\n",
       "      <td id=\"T_88d0a_row4_col28\" class=\"data row4 col28\" >3.2754</td>\n",
       "      <td id=\"T_88d0a_row4_col29\" class=\"data row4 col29\" >3.2216</td>\n",
       "      <td id=\"T_88d0a_row4_col30\" class=\"data row4 col30\" >0.3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_88d0a_row5_col0\" class=\"data row5 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row5_col1\" class=\"data row5 col1\" >500</td>\n",
       "      <td id=\"T_88d0a_row5_col2\" class=\"data row5 col2\" >1000000</td>\n",
       "      <td id=\"T_88d0a_row5_col3\" class=\"data row5 col3\" >0.7347</td>\n",
       "      <td id=\"T_88d0a_row5_col4\" class=\"data row5 col4\" >0.0590</td>\n",
       "      <td id=\"T_88d0a_row5_col5\" class=\"data row5 col5\" >31</td>\n",
       "      <td id=\"T_88d0a_row5_col6\" class=\"data row5 col6\" >32</td>\n",
       "      <td id=\"T_88d0a_row5_col7\" class=\"data row5 col7\" >1.5e-04</td>\n",
       "      <td id=\"T_88d0a_row5_col8\" class=\"data row5 col8\" >1.4e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col9\" class=\"data row5 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col10\" class=\"data row5 col10\" >99.5688</td>\n",
       "      <td id=\"T_88d0a_row5_col11\" class=\"data row5 col11\" >4.5995</td>\n",
       "      <td id=\"T_88d0a_row5_col12\" class=\"data row5 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row5_col13\" class=\"data row5 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col14\" class=\"data row5 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col15\" class=\"data row5 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col16\" class=\"data row5 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col17\" class=\"data row5 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col18\" class=\"data row5 col18\" >31.3333</td>\n",
       "      <td id=\"T_88d0a_row5_col19\" class=\"data row5 col19\" >2.84e-04</td>\n",
       "      <td id=\"T_88d0a_row5_col20\" class=\"data row5 col20\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col21\" class=\"data row5 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row5_col22\" class=\"data row5 col22\" >85.3159</td>\n",
       "      <td id=\"T_88d0a_row5_col23\" class=\"data row5 col23\" >1.17e+09</td>\n",
       "      <td id=\"T_88d0a_row5_col24\" class=\"data row5 col24\" >0.7547</td>\n",
       "      <td id=\"T_88d0a_row5_col25\" class=\"data row5 col25\" >0.6441</td>\n",
       "      <td id=\"T_88d0a_row5_col26\" class=\"data row5 col26\" >0.7112</td>\n",
       "      <td id=\"T_88d0a_row5_col27\" class=\"data row5 col27\" >1.5756</td>\n",
       "      <td id=\"T_88d0a_row5_col28\" class=\"data row5 col28\" >1.4787</td>\n",
       "      <td id=\"T_88d0a_row5_col29\" class=\"data row5 col29\" >1.2129</td>\n",
       "      <td id=\"T_88d0a_row5_col30\" class=\"data row5 col30\" >0.1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_88d0a_row6_col0\" class=\"data row6 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row6_col1\" class=\"data row6 col1\" >1000</td>\n",
       "      <td id=\"T_88d0a_row6_col2\" class=\"data row6 col2\" >20</td>\n",
       "      <td id=\"T_88d0a_row6_col3\" class=\"data row6 col3\" >0.5234</td>\n",
       "      <td id=\"T_88d0a_row6_col4\" class=\"data row6 col4\" >0.1221</td>\n",
       "      <td id=\"T_88d0a_row6_col5\" class=\"data row6 col5\" >27</td>\n",
       "      <td id=\"T_88d0a_row6_col6\" class=\"data row6 col6\" >27</td>\n",
       "      <td id=\"T_88d0a_row6_col7\" class=\"data row6 col7\" >1.0e-02</td>\n",
       "      <td id=\"T_88d0a_row6_col8\" class=\"data row6 col8\" >8.3e+03</td>\n",
       "      <td id=\"T_88d0a_row6_col9\" class=\"data row6 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col10\" class=\"data row6 col10\" >114.4542</td>\n",
       "      <td id=\"T_88d0a_row6_col11\" class=\"data row6 col11\" >16.9527</td>\n",
       "      <td id=\"T_88d0a_row6_col12\" class=\"data row6 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row6_col13\" class=\"data row6 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col14\" class=\"data row6 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col15\" class=\"data row6 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col16\" class=\"data row6 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col17\" class=\"data row6 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col18\" class=\"data row6 col18\" >26.0000</td>\n",
       "      <td id=\"T_88d0a_row6_col19\" class=\"data row6 col19\" >0.0202</td>\n",
       "      <td id=\"T_88d0a_row6_col20\" class=\"data row6 col20\" >33.6667</td>\n",
       "      <td id=\"T_88d0a_row6_col21\" class=\"data row6 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row6_col22\" class=\"data row6 col22\" >8.0723</td>\n",
       "      <td id=\"T_88d0a_row6_col23\" class=\"data row6 col23\" >1.03e+11</td>\n",
       "      <td id=\"T_88d0a_row6_col24\" class=\"data row6 col24\" >0.5848</td>\n",
       "      <td id=\"T_88d0a_row6_col25\" class=\"data row6 col25\" >0.3494</td>\n",
       "      <td id=\"T_88d0a_row6_col26\" class=\"data row6 col26\" >0.4858</td>\n",
       "      <td id=\"T_88d0a_row6_col27\" class=\"data row6 col27\" >2.47e+04</td>\n",
       "      <td id=\"T_88d0a_row6_col28\" class=\"data row6 col28\" >64.1205</td>\n",
       "      <td id=\"T_88d0a_row6_col29\" class=\"data row6 col29\" >57.7861</td>\n",
       "      <td id=\"T_88d0a_row6_col30\" class=\"data row6 col30\" >1.42e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_88d0a_row7_col0\" class=\"data row7 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row7_col1\" class=\"data row7 col1\" >1000</td>\n",
       "      <td id=\"T_88d0a_row7_col2\" class=\"data row7 col2\" >100000</td>\n",
       "      <td id=\"T_88d0a_row7_col3\" class=\"data row7 col3\" >0.5311</td>\n",
       "      <td id=\"T_88d0a_row7_col4\" class=\"data row7 col4\" >0.1457</td>\n",
       "      <td id=\"T_88d0a_row7_col5\" class=\"data row7 col5\" >33</td>\n",
       "      <td id=\"T_88d0a_row7_col6\" class=\"data row7 col6\" >34</td>\n",
       "      <td id=\"T_88d0a_row7_col7\" class=\"data row7 col7\" >2.4e-05</td>\n",
       "      <td id=\"T_88d0a_row7_col8\" class=\"data row7 col8\" >6.2e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col9\" class=\"data row7 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col10\" class=\"data row7 col10\" >99.7901</td>\n",
       "      <td id=\"T_88d0a_row7_col11\" class=\"data row7 col11\" >11.8765</td>\n",
       "      <td id=\"T_88d0a_row7_col12\" class=\"data row7 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row7_col13\" class=\"data row7 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col14\" class=\"data row7 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col15\" class=\"data row7 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col16\" class=\"data row7 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col17\" class=\"data row7 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col18\" class=\"data row7 col18\" >32.6667</td>\n",
       "      <td id=\"T_88d0a_row7_col19\" class=\"data row7 col19\" >6.16e-05</td>\n",
       "      <td id=\"T_88d0a_row7_col20\" class=\"data row7 col20\" >0.6667</td>\n",
       "      <td id=\"T_88d0a_row7_col21\" class=\"data row7 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row7_col22\" class=\"data row7 col22\" >108.6762</td>\n",
       "      <td id=\"T_88d0a_row7_col23\" class=\"data row7 col23\" >1.23e+10</td>\n",
       "      <td id=\"T_88d0a_row7_col24\" class=\"data row7 col24\" >0.7660</td>\n",
       "      <td id=\"T_88d0a_row7_col25\" class=\"data row7 col25\" >0.4992</td>\n",
       "      <td id=\"T_88d0a_row7_col26\" class=\"data row7 col26\" >0.5988</td>\n",
       "      <td id=\"T_88d0a_row7_col27\" class=\"data row7 col27\" >6.5432</td>\n",
       "      <td id=\"T_88d0a_row7_col28\" class=\"data row7 col28\" >6.0990</td>\n",
       "      <td id=\"T_88d0a_row7_col29\" class=\"data row7 col29\" >5.8912</td>\n",
       "      <td id=\"T_88d0a_row7_col30\" class=\"data row7 col30\" >0.3331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88d0a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_88d0a_row8_col0\" class=\"data row8 col0\" >base</td>\n",
       "      <td id=\"T_88d0a_row8_col1\" class=\"data row8 col1\" >1000</td>\n",
       "      <td id=\"T_88d0a_row8_col2\" class=\"data row8 col2\" >1000000</td>\n",
       "      <td id=\"T_88d0a_row8_col3\" class=\"data row8 col3\" >1.2036</td>\n",
       "      <td id=\"T_88d0a_row8_col4\" class=\"data row8 col4\" >0.0846</td>\n",
       "      <td id=\"T_88d0a_row8_col5\" class=\"data row8 col5\" >34</td>\n",
       "      <td id=\"T_88d0a_row8_col6\" class=\"data row8 col6\" >36</td>\n",
       "      <td id=\"T_88d0a_row8_col7\" class=\"data row8 col7\" >6.6e-05</td>\n",
       "      <td id=\"T_88d0a_row8_col8\" class=\"data row8 col8\" >2.8e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col9\" class=\"data row8 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col10\" class=\"data row8 col10\" >99.4956</td>\n",
       "      <td id=\"T_88d0a_row8_col11\" class=\"data row8 col11\" >5.3458</td>\n",
       "      <td id=\"T_88d0a_row8_col12\" class=\"data row8 col12\" >3</td>\n",
       "      <td id=\"T_88d0a_row8_col13\" class=\"data row8 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col14\" class=\"data row8 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col15\" class=\"data row8 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col16\" class=\"data row8 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col17\" class=\"data row8 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col18\" class=\"data row8 col18\" >34.3333</td>\n",
       "      <td id=\"T_88d0a_row8_col19\" class=\"data row8 col19\" >1.84e-04</td>\n",
       "      <td id=\"T_88d0a_row8_col20\" class=\"data row8 col20\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col21\" class=\"data row8 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_88d0a_row8_col22\" class=\"data row8 col22\" >108.5650</td>\n",
       "      <td id=\"T_88d0a_row8_col23\" class=\"data row8 col23\" >2.31e+09</td>\n",
       "      <td id=\"T_88d0a_row8_col24\" class=\"data row8 col24\" >1.2570</td>\n",
       "      <td id=\"T_88d0a_row8_col25\" class=\"data row8 col25\" >1.0912</td>\n",
       "      <td id=\"T_88d0a_row8_col26\" class=\"data row8 col26\" >1.1840</td>\n",
       "      <td id=\"T_88d0a_row8_col27\" class=\"data row8 col27\" >2.9225</td>\n",
       "      <td id=\"T_88d0a_row8_col28\" class=\"data row8 col28\" >2.7736</td>\n",
       "      <td id=\"T_88d0a_row8_col29\" class=\"data row8 col29\" >2.6773</td>\n",
       "      <td id=\"T_88d0a_row8_col30\" class=\"data row8 col30\" >0.1236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf58c1450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.01386404037475586  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_table1(sim):\n",
    "\n",
    "    vns_drop = ['ch_few', 'ch_many', 'ch_vn0', 'ch_value0']\n",
    "    \n",
    "    vns_sort = []\n",
    "    \n",
    "    vns_sort = ['difficulty', 'N', 'M']\n",
    "\n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl1\", \n",
    "                                     vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg1 = make_table1(sim1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for vn in dir(sim1):\n",
    "    if vn[0] != '_':\n",
    "        print(vn, type(getattr(sim1, vn)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for vn in sim1.df_sim.columns:\n",
    "    print(vn, sim1.df_sim[vn].dtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    \n",
    "display(sim1.df_sim[['difficulty', 'i', 'dt', 'niter', 'N', 'M']].sort_values(['difficulty', 'N', 'i', 'M']))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puzzling result that computation time increases nonlinearly in M for N==3000\n",
    "\n",
    "The following table displays the computation times and number of iterations sorted by 'N', 'i', 'M', grouped so that distinct values of 'M' show up as separate columns.\n",
    "\n",
    "If computation time increases as a result of a cache issue, we should see a pattern of computation time increasing steeply around specific values of 'M'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>20</th>\n",
       "      <th>100000</th>\n",
       "      <th>1000000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficulty</th>\n",
       "      <th>N</th>\n",
       "      <th>i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">base</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>0</th>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.6323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">500</th>\n",
       "      <th>0</th>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.6441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1000</th>\n",
       "      <th>0</th>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>1.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.5311</td>\n",
       "      <td>1.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3494</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>1.2036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dt                \n",
       "M                 20      100000  1000000\n",
       "difficulty N    i                        \n",
       "base       10   0  0.2564  0.3789  0.6242\n",
       "                1  0.2478  0.2806  0.6946\n",
       "                2  0.2071  0.2307  0.6323\n",
       "           500  0  0.5807  0.3823  0.7347\n",
       "                1  0.3232  0.3351  0.7547\n",
       "                2  0.2749  0.3474  0.6441\n",
       "           1000 0  0.5848  0.7660  1.2570\n",
       "                1  0.5234  0.5311  1.0912\n",
       "                2  0.3494  0.4992  1.2036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def unstack_sim(sim):\n",
    "\n",
    "    pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "    dfu = (sim.df_sim[['difficulty', 'i', 'dt', 'N', 'M']].sort_values(['difficulty', 'N', 'i', 'M']).\n",
    "                groupby(['difficulty', 'N', 'i', 'M']).mean().unstack('M'))\n",
    "    \n",
    "    display(dfu) \n",
    "    \n",
    "unstack_sim(sim1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>i</th>\n",
       "      <th colspan=\"3\" halign=\"left\">dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>100000</th>\n",
       "      <th>1000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>0.6323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.6441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>1.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.5311</td>\n",
       "      <td>1.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>1.2036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      N  i     dt               \n",
       "M              20 100000 1000000\n",
       "0    10  0 0.2564 0.3789  0.6242\n",
       "1    10  1 0.2478 0.2806  0.6946\n",
       "2    10  2 0.2071 0.2307  0.6323\n",
       "3   500  0 0.5807 0.3823  0.7347\n",
       "4   500  1 0.3232 0.3351  0.7547\n",
       "5   500  2 0.2749 0.3474  0.6441\n",
       "6  1000  0 0.5848 0.7660  1.2570\n",
       "7  1000  1 0.5234 0.5311  1.0912\n",
       "8  1000  2 0.3494 0.4992  1.2036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_sim_times(sim):\n",
    "    \n",
    "    try:\n",
    "        dfux = (sim.df_sim[['i', 'dt', 'N', 'M']].sort_values(['N', 'i', 'M']).\n",
    "                    groupby(['N', 'i', 'M']).mean().unstack('M'))\n",
    "        dfur = dfux.reset_index()\n",
    "        display(dfur)\n",
    "        #print(dfur.columns)\n",
    "        b = (dfur[('N', '')] == (3000 if RUN_TYPE == 'workstation' else 1000))\n",
    "        df1000 = dfur[b]\n",
    "        del df1000[('N',)]\n",
    "        del df1000[('i',)]\n",
    "        #print(b)\n",
    "        #print(df1000)\n",
    "        df1000.plot(logy=True)\n",
    "    except:\n",
    "        print(\"plot_sim_times failed!\")\n",
    "        \n",
    "plot_sim_times(sim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 2: exchange trading\n",
    "\n",
    "1. Model can now handle zero exchange trading and zero stabilizing orders; does not crash.\n",
    "2. Baseline parameters with 500 assets and 100,000 orders.  \n",
    "3. Baseline exch_phpl_frac = 1.00, exch_epsilon = 1.00e-6, stab_max_qv = 0.10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreps =  3\n",
      "difficulty =  ['base_no_stab']\n",
      "change_few =  ['ch2test']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:23<00:00,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/sim2_RZtest_2023-1204-2043.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  24.128093957901  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate2():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim2\")\n",
    "\n",
    "    nreps = 51 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "\n",
    "    #sim.dd_difficulty['low'] = {'N' : 50, 'M' : 1000}\n",
    "\n",
    "    #sim.dd_difficulty['base_no_stab'] = {'stab_max_qv' : 0.00}\n",
    "    \n",
    "    #difficulty = ['base'] if RUN_TYPE == 'workstation' else ['base'] if RUN_TYPE == 'laptop' else ['base']\n",
    "\n",
    "    difficulty = ['base_no_stab'] \n",
    "\n",
    "    #sim.dvd_change_few['ch2'] = [{'exch_epsilon' : eps} for eps in [\n",
    "    #    1.0e-99, 1.00e-12, 1.00e-8, 1.00e-6, 1.00e-4, 1.00e-0, 1.00e4, 1.00e8, 1.00e12]]\n",
    "\n",
    "    sim.dvd_change_few['ch2test'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl} \n",
    "        for eps in [1.00e-5, 1.00e-4, 1.00e-3] \n",
    "        for phpl in [1.00, 10.00, 100.00]]\n",
    "\n",
    "    sim.dvd_change_few['ch2DM'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl} \n",
    "        for eps in [0.00, 1.0e-99, 1.00e-5, 1.00e-4, 1.00e-3, 1.00e-2, 1.00e-1, 1.00e-0, 1.00e+1, 1.00e4, 1.00e8]\n",
    "        for phpl in [1.00, 10.00, 100.00]]\n",
    "\n",
    "    sim.dvd_change_few['ch2PK'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl} \n",
    "        for eps in [0.00, 1.0e-99, 1.00e-5, 1.00e-4, 1.00e-3, 1.00e-2, 1.00e-1, 1.00e-0, 1.00e+1, 1.00e4, 1.00e8]\n",
    "        for phpl in [1.00, 10.00, 100.00]]\n",
    "\n",
    "    change_few = ['ch2DM'] if RUN_TYPE == 'workstation' else ['ch2PK'] if RUN_TYPE == 'laptop' else ['ch2test'] \n",
    "\n",
    "    change_many = ['none']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim2 = simulate2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ba898\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ba898_level0_col0\" class=\"col_heading level0 col0\" >difficulty</th>\n",
       "      <th id=\"T_ba898_level0_col1\" class=\"col_heading level0 col1\" >exch_phpl_frac</th>\n",
       "      <th id=\"T_ba898_level0_col2\" class=\"col_heading level0 col2\" >exch_epsilon</th>\n",
       "      <th id=\"T_ba898_level0_col3\" class=\"col_heading level0 col3\" >dt_med</th>\n",
       "      <th id=\"T_ba898_level0_col4\" class=\"col_heading level0 col4\" >dt_std</th>\n",
       "      <th id=\"T_ba898_level0_col5\" class=\"col_heading level0 col5\" >niter_med</th>\n",
       "      <th id=\"T_ba898_level0_col6\" class=\"col_heading level0 col6\" >niter_max</th>\n",
       "      <th id=\"T_ba898_level0_col7\" class=\"col_heading level0 col7\" >unclpM</th>\n",
       "      <th id=\"T_ba898_level0_col8\" class=\"col_heading level0 col8\" >exchpM</th>\n",
       "      <th id=\"T_ba898_level0_col9\" class=\"col_heading level0 col9\" >stabpM</th>\n",
       "      <th id=\"T_ba898_level0_col10\" class=\"col_heading level0 col10\" >p</th>\n",
       "      <th id=\"T_ba898_level0_col11\" class=\"col_heading level0 col11\" >p_std</th>\n",
       "      <th id=\"T_ba898_level0_col12\" class=\"col_heading level0 col12\" >count</th>\n",
       "      <th id=\"T_ba898_level0_col13\" class=\"col_heading level0 col13\" >num_exch_full</th>\n",
       "      <th id=\"T_ba898_level0_col14\" class=\"col_heading level0 col14\" >num_stab_full</th>\n",
       "      <th id=\"T_ba898_level0_col15\" class=\"col_heading level0 col15\" >num_stab_active</th>\n",
       "      <th id=\"T_ba898_level0_col16\" class=\"col_heading level0 col16\" >bchofail</th>\n",
       "      <th id=\"T_ba898_level0_col17\" class=\"col_heading level0 col17\" >bmaxiter</th>\n",
       "      <th id=\"T_ba898_level0_col18\" class=\"col_heading level0 col18\" >niter</th>\n",
       "      <th id=\"T_ba898_level0_col19\" class=\"col_heading level0 col19\" >unclpM_max</th>\n",
       "      <th id=\"T_ba898_level0_col20\" class=\"col_heading level0 col20\" >n_bad_p</th>\n",
       "      <th id=\"T_ba898_level0_col21\" class=\"col_heading level0 col21\" >nchreg</th>\n",
       "      <th id=\"T_ba898_level0_col22\" class=\"col_heading level0 col22\" >dvM</th>\n",
       "      <th id=\"T_ba898_level0_col23\" class=\"col_heading level0 col23\" >condnum_med</th>\n",
       "      <th id=\"T_ba898_level0_col24\" class=\"col_heading level0 col24\" >dt_max</th>\n",
       "      <th id=\"T_ba898_level0_col25\" class=\"col_heading level0 col25\" >dt_min</th>\n",
       "      <th id=\"T_ba898_level0_col26\" class=\"col_heading level0 col26\" >dt</th>\n",
       "      <th id=\"T_ba898_level0_col27\" class=\"col_heading level0 col27\" >exchpM_max</th>\n",
       "      <th id=\"T_ba898_level0_col28\" class=\"col_heading level0 col28\" >exchpM_med</th>\n",
       "      <th id=\"T_ba898_level0_col29\" class=\"col_heading level0 col29\" >exchpM_min</th>\n",
       "      <th id=\"T_ba898_level0_col30\" class=\"col_heading level0 col30\" >exchpM_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ba898_row0_col0\" class=\"data row0 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row0_col1\" class=\"data row0 col1\" >1.0000</td>\n",
       "      <td id=\"T_ba898_row0_col2\" class=\"data row0 col2\" >1.00e-05</td>\n",
       "      <td id=\"T_ba898_row0_col3\" class=\"data row0 col3\" >0.4280</td>\n",
       "      <td id=\"T_ba898_row0_col4\" class=\"data row0 col4\" >0.2576</td>\n",
       "      <td id=\"T_ba898_row0_col5\" class=\"data row0 col5\" >33</td>\n",
       "      <td id=\"T_ba898_row0_col6\" class=\"data row0 col6\" >34</td>\n",
       "      <td id=\"T_ba898_row0_col7\" class=\"data row0 col7\" >4.3e-06</td>\n",
       "      <td id=\"T_ba898_row0_col8\" class=\"data row0 col8\" >5.0e-03</td>\n",
       "      <td id=\"T_ba898_row0_col9\" class=\"data row0 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row0_col10\" class=\"data row0 col10\" >99.8076</td>\n",
       "      <td id=\"T_ba898_row0_col11\" class=\"data row0 col11\" >3.52e+04</td>\n",
       "      <td id=\"T_ba898_row0_col12\" class=\"data row0 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row0_col13\" class=\"data row0 col13\" >17.6667</td>\n",
       "      <td id=\"T_ba898_row0_col14\" class=\"data row0 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row0_col15\" class=\"data row0 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row0_col16\" class=\"data row0 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row0_col17\" class=\"data row0 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row0_col18\" class=\"data row0 col18\" >33.0000</td>\n",
       "      <td id=\"T_ba898_row0_col19\" class=\"data row0 col19\" >1.17e-05</td>\n",
       "      <td id=\"T_ba898_row0_col20\" class=\"data row0 col20\" >17.6667</td>\n",
       "      <td id=\"T_ba898_row0_col21\" class=\"data row0 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row0_col22\" class=\"data row0 col22\" >84.8286</td>\n",
       "      <td id=\"T_ba898_row0_col23\" class=\"data row0 col23\" >4.78e+15</td>\n",
       "      <td id=\"T_ba898_row0_col24\" class=\"data row0 col24\" >0.8558</td>\n",
       "      <td id=\"T_ba898_row0_col25\" class=\"data row0 col25\" >0.3933</td>\n",
       "      <td id=\"T_ba898_row0_col26\" class=\"data row0 col26\" >0.5590</td>\n",
       "      <td id=\"T_ba898_row0_col27\" class=\"data row0 col27\" >5.36e-03</td>\n",
       "      <td id=\"T_ba898_row0_col28\" class=\"data row0 col28\" >4.89e-03</td>\n",
       "      <td id=\"T_ba898_row0_col29\" class=\"data row0 col29\" >4.86e-03</td>\n",
       "      <td id=\"T_ba898_row0_col30\" class=\"data row0 col30\" >2.81e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_ba898_row1_col0\" class=\"data row1 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row1_col1\" class=\"data row1 col1\" >10.0000</td>\n",
       "      <td id=\"T_ba898_row1_col2\" class=\"data row1 col2\" >1.00e-05</td>\n",
       "      <td id=\"T_ba898_row1_col3\" class=\"data row1 col3\" >0.3840</td>\n",
       "      <td id=\"T_ba898_row1_col4\" class=\"data row1 col4\" >0.0593</td>\n",
       "      <td id=\"T_ba898_row1_col5\" class=\"data row1 col5\" >33</td>\n",
       "      <td id=\"T_ba898_row1_col6\" class=\"data row1 col6\" >33</td>\n",
       "      <td id=\"T_ba898_row1_col7\" class=\"data row1 col7\" >1.1e-06</td>\n",
       "      <td id=\"T_ba898_row1_col8\" class=\"data row1 col8\" >2.2e-02</td>\n",
       "      <td id=\"T_ba898_row1_col9\" class=\"data row1 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row1_col10\" class=\"data row1 col10\" >99.8121</td>\n",
       "      <td id=\"T_ba898_row1_col11\" class=\"data row1 col11\" >1.21e+04</td>\n",
       "      <td id=\"T_ba898_row1_col12\" class=\"data row1 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row1_col13\" class=\"data row1 col13\" >10.6667</td>\n",
       "      <td id=\"T_ba898_row1_col14\" class=\"data row1 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row1_col15\" class=\"data row1 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row1_col16\" class=\"data row1 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row1_col17\" class=\"data row1 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row1_col18\" class=\"data row1 col18\" >32.6667</td>\n",
       "      <td id=\"T_ba898_row1_col19\" class=\"data row1 col19\" >1.45e-06</td>\n",
       "      <td id=\"T_ba898_row1_col20\" class=\"data row1 col20\" >22.6667</td>\n",
       "      <td id=\"T_ba898_row1_col21\" class=\"data row1 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row1_col22\" class=\"data row1 col22\" >84.7808</td>\n",
       "      <td id=\"T_ba898_row1_col23\" class=\"data row1 col23\" >1.13e+15</td>\n",
       "      <td id=\"T_ba898_row1_col24\" class=\"data row1 col24\" >0.4804</td>\n",
       "      <td id=\"T_ba898_row1_col25\" class=\"data row1 col25\" >0.3723</td>\n",
       "      <td id=\"T_ba898_row1_col26\" class=\"data row1 col26\" >0.4122</td>\n",
       "      <td id=\"T_ba898_row1_col27\" class=\"data row1 col27\" >0.0243</td>\n",
       "      <td id=\"T_ba898_row1_col28\" class=\"data row1 col28\" >0.0206</td>\n",
       "      <td id=\"T_ba898_row1_col29\" class=\"data row1 col29\" >0.0199</td>\n",
       "      <td id=\"T_ba898_row1_col30\" class=\"data row1 col30\" >2.36e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "      <td id=\"T_ba898_row2_col0\" class=\"data row2 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row2_col1\" class=\"data row2 col1\" >100.0000</td>\n",
       "      <td id=\"T_ba898_row2_col2\" class=\"data row2 col2\" >1.00e-05</td>\n",
       "      <td id=\"T_ba898_row2_col3\" class=\"data row2 col3\" >0.4982</td>\n",
       "      <td id=\"T_ba898_row2_col4\" class=\"data row2 col4\" >0.0784</td>\n",
       "      <td id=\"T_ba898_row2_col5\" class=\"data row2 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row2_col6\" class=\"data row2 col6\" >32</td>\n",
       "      <td id=\"T_ba898_row2_col7\" class=\"data row2 col7\" >8.7e-07</td>\n",
       "      <td id=\"T_ba898_row2_col8\" class=\"data row2 col8\" >6.3e-02</td>\n",
       "      <td id=\"T_ba898_row2_col9\" class=\"data row2 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row2_col10\" class=\"data row2 col10\" >99.8079</td>\n",
       "      <td id=\"T_ba898_row2_col11\" class=\"data row2 col11\" >5.83e+03</td>\n",
       "      <td id=\"T_ba898_row2_col12\" class=\"data row2 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row2_col13\" class=\"data row2 col13\" >1.3333</td>\n",
       "      <td id=\"T_ba898_row2_col14\" class=\"data row2 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row2_col15\" class=\"data row2 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row2_col16\" class=\"data row2 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row2_col17\" class=\"data row2 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row2_col18\" class=\"data row2 col18\" >31.0000</td>\n",
       "      <td id=\"T_ba898_row2_col19\" class=\"data row2 col19\" >9.58e-07</td>\n",
       "      <td id=\"T_ba898_row2_col20\" class=\"data row2 col20\" >20.3333</td>\n",
       "      <td id=\"T_ba898_row2_col21\" class=\"data row2 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row2_col22\" class=\"data row2 col22\" >84.8009</td>\n",
       "      <td id=\"T_ba898_row2_col23\" class=\"data row2 col23\" >1.38e+13</td>\n",
       "      <td id=\"T_ba898_row2_col24\" class=\"data row2 col24\" >0.5628</td>\n",
       "      <td id=\"T_ba898_row2_col25\" class=\"data row2 col25\" >0.4068</td>\n",
       "      <td id=\"T_ba898_row2_col26\" class=\"data row2 col26\" >0.4893</td>\n",
       "      <td id=\"T_ba898_row2_col27\" class=\"data row2 col27\" >0.0816</td>\n",
       "      <td id=\"T_ba898_row2_col28\" class=\"data row2 col28\" >0.0641</td>\n",
       "      <td id=\"T_ba898_row2_col29\" class=\"data row2 col29\" >0.0426</td>\n",
       "      <td id=\"T_ba898_row2_col30\" class=\"data row2 col30\" >0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_ba898_row3_col0\" class=\"data row3 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row3_col1\" class=\"data row3 col1\" >1.0000</td>\n",
       "      <td id=\"T_ba898_row3_col2\" class=\"data row3 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_ba898_row3_col3\" class=\"data row3 col3\" >0.5071</td>\n",
       "      <td id=\"T_ba898_row3_col4\" class=\"data row3 col4\" >0.1056</td>\n",
       "      <td id=\"T_ba898_row3_col5\" class=\"data row3 col5\" >32</td>\n",
       "      <td id=\"T_ba898_row3_col6\" class=\"data row3 col6\" >33</td>\n",
       "      <td id=\"T_ba898_row3_col7\" class=\"data row3 col7\" >2.1e-05</td>\n",
       "      <td id=\"T_ba898_row3_col8\" class=\"data row3 col8\" >4.8e-02</td>\n",
       "      <td id=\"T_ba898_row3_col9\" class=\"data row3 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row3_col10\" class=\"data row3 col10\" >99.8121</td>\n",
       "      <td id=\"T_ba898_row3_col11\" class=\"data row3 col11\" >1.21e+04</td>\n",
       "      <td id=\"T_ba898_row3_col12\" class=\"data row3 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row3_col13\" class=\"data row3 col13\" >13.0000</td>\n",
       "      <td id=\"T_ba898_row3_col14\" class=\"data row3 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row3_col15\" class=\"data row3 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row3_col16\" class=\"data row3 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row3_col17\" class=\"data row3 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row3_col18\" class=\"data row3 col18\" >32.0000</td>\n",
       "      <td id=\"T_ba898_row3_col19\" class=\"data row3 col19\" >5.77e-05</td>\n",
       "      <td id=\"T_ba898_row3_col20\" class=\"data row3 col20\" >13.0000</td>\n",
       "      <td id=\"T_ba898_row3_col21\" class=\"data row3 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row3_col22\" class=\"data row3 col22\" >84.7819</td>\n",
       "      <td id=\"T_ba898_row3_col23\" class=\"data row3 col23\" >1.12e+15</td>\n",
       "      <td id=\"T_ba898_row3_col24\" class=\"data row3 col24\" >0.6453</td>\n",
       "      <td id=\"T_ba898_row3_col25\" class=\"data row3 col25\" >0.4379</td>\n",
       "      <td id=\"T_ba898_row3_col26\" class=\"data row3 col26\" >0.5301</td>\n",
       "      <td id=\"T_ba898_row3_col27\" class=\"data row3 col27\" >0.0520</td>\n",
       "      <td id=\"T_ba898_row3_col28\" class=\"data row3 col28\" >0.0465</td>\n",
       "      <td id=\"T_ba898_row3_col29\" class=\"data row3 col29\" >0.0462</td>\n",
       "      <td id=\"T_ba898_row3_col30\" class=\"data row3 col30\" >3.25e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ba898_row4_col0\" class=\"data row4 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row4_col1\" class=\"data row4 col1\" >10.0000</td>\n",
       "      <td id=\"T_ba898_row4_col2\" class=\"data row4 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_ba898_row4_col3\" class=\"data row4 col3\" >0.6102</td>\n",
       "      <td id=\"T_ba898_row4_col4\" class=\"data row4 col4\" >0.0663</td>\n",
       "      <td id=\"T_ba898_row4_col5\" class=\"data row4 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row4_col6\" class=\"data row4 col6\" >31</td>\n",
       "      <td id=\"T_ba898_row4_col7\" class=\"data row4 col7\" >7.6e-07</td>\n",
       "      <td id=\"T_ba898_row4_col8\" class=\"data row4 col8\" >1.0e-01</td>\n",
       "      <td id=\"T_ba898_row4_col9\" class=\"data row4 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row4_col10\" class=\"data row4 col10\" >99.8069</td>\n",
       "      <td id=\"T_ba898_row4_col11\" class=\"data row4 col11\" >5.70e+03</td>\n",
       "      <td id=\"T_ba898_row4_col12\" class=\"data row4 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row4_col13\" class=\"data row4 col13\" >2.6667</td>\n",
       "      <td id=\"T_ba898_row4_col14\" class=\"data row4 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row4_col15\" class=\"data row4 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row4_col16\" class=\"data row4 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row4_col17\" class=\"data row4 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row4_col18\" class=\"data row4 col18\" >30.6667</td>\n",
       "      <td id=\"T_ba898_row4_col19\" class=\"data row4 col19\" >8.92e-07</td>\n",
       "      <td id=\"T_ba898_row4_col20\" class=\"data row4 col20\" >12.6667</td>\n",
       "      <td id=\"T_ba898_row4_col21\" class=\"data row4 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row4_col22\" class=\"data row4 col22\" >84.7950</td>\n",
       "      <td id=\"T_ba898_row4_col23\" class=\"data row4 col23\" >3.77e+12</td>\n",
       "      <td id=\"T_ba898_row4_col24\" class=\"data row4 col24\" >0.6754</td>\n",
       "      <td id=\"T_ba898_row4_col25\" class=\"data row4 col25\" >0.5429</td>\n",
       "      <td id=\"T_ba898_row4_col26\" class=\"data row4 col26\" >0.6095</td>\n",
       "      <td id=\"T_ba898_row4_col27\" class=\"data row4 col27\" >0.1167</td>\n",
       "      <td id=\"T_ba898_row4_col28\" class=\"data row4 col28\" >0.0967</td>\n",
       "      <td id=\"T_ba898_row4_col29\" class=\"data row4 col29\" >0.0910</td>\n",
       "      <td id=\"T_ba898_row4_col30\" class=\"data row4 col30\" >0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row5\" class=\"row_heading level0 row5\" >7</th>\n",
       "      <td id=\"T_ba898_row5_col0\" class=\"data row5 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row5_col1\" class=\"data row5 col1\" >100.0000</td>\n",
       "      <td id=\"T_ba898_row5_col2\" class=\"data row5 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_ba898_row5_col3\" class=\"data row5 col3\" >0.6325</td>\n",
       "      <td id=\"T_ba898_row5_col4\" class=\"data row5 col4\" >0.1783</td>\n",
       "      <td id=\"T_ba898_row5_col5\" class=\"data row5 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row5_col6\" class=\"data row5 col6\" >31</td>\n",
       "      <td id=\"T_ba898_row5_col7\" class=\"data row5 col7\" >3.5e-06</td>\n",
       "      <td id=\"T_ba898_row5_col8\" class=\"data row5 col8\" >1.5e-01</td>\n",
       "      <td id=\"T_ba898_row5_col9\" class=\"data row5 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row5_col10\" class=\"data row5 col10\" >99.8124</td>\n",
       "      <td id=\"T_ba898_row5_col11\" class=\"data row5 col11\" >200.6865</td>\n",
       "      <td id=\"T_ba898_row5_col12\" class=\"data row5 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row5_col13\" class=\"data row5 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col14\" class=\"data row5 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col15\" class=\"data row5 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col16\" class=\"data row5 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col17\" class=\"data row5 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col18\" class=\"data row5 col18\" >30.3333</td>\n",
       "      <td id=\"T_ba898_row5_col19\" class=\"data row5 col19\" >9.50e-06</td>\n",
       "      <td id=\"T_ba898_row5_col20\" class=\"data row5 col20\" >15.3333</td>\n",
       "      <td id=\"T_ba898_row5_col21\" class=\"data row5 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row5_col22\" class=\"data row5 col22\" >84.7485</td>\n",
       "      <td id=\"T_ba898_row5_col23\" class=\"data row5 col23\" >6.22e+11</td>\n",
       "      <td id=\"T_ba898_row5_col24\" class=\"data row5 col24\" >0.7333</td>\n",
       "      <td id=\"T_ba898_row5_col25\" class=\"data row5 col25\" >0.3866</td>\n",
       "      <td id=\"T_ba898_row5_col26\" class=\"data row5 col26\" >0.5842</td>\n",
       "      <td id=\"T_ba898_row5_col27\" class=\"data row5 col27\" >0.2080</td>\n",
       "      <td id=\"T_ba898_row5_col28\" class=\"data row5 col28\" >0.1615</td>\n",
       "      <td id=\"T_ba898_row5_col29\" class=\"data row5 col29\" >0.0928</td>\n",
       "      <td id=\"T_ba898_row5_col30\" class=\"data row5 col30\" >0.0579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row6\" class=\"row_heading level0 row6\" >2</th>\n",
       "      <td id=\"T_ba898_row6_col0\" class=\"data row6 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_ba898_row6_col2\" class=\"data row6 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_ba898_row6_col3\" class=\"data row6 col3\" >0.5094</td>\n",
       "      <td id=\"T_ba898_row6_col4\" class=\"data row6 col4\" >0.1094</td>\n",
       "      <td id=\"T_ba898_row6_col5\" class=\"data row6 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row6_col6\" class=\"data row6 col6\" >31</td>\n",
       "      <td id=\"T_ba898_row6_col7\" class=\"data row6 col7\" >1.0e-05</td>\n",
       "      <td id=\"T_ba898_row6_col8\" class=\"data row6 col8\" >3.9e-01</td>\n",
       "      <td id=\"T_ba898_row6_col9\" class=\"data row6 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row6_col10\" class=\"data row6 col10\" >99.8069</td>\n",
       "      <td id=\"T_ba898_row6_col11\" class=\"data row6 col11\" >5.71e+03</td>\n",
       "      <td id=\"T_ba898_row6_col12\" class=\"data row6 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row6_col13\" class=\"data row6 col13\" >4.0000</td>\n",
       "      <td id=\"T_ba898_row6_col14\" class=\"data row6 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row6_col15\" class=\"data row6 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row6_col16\" class=\"data row6 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row6_col17\" class=\"data row6 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row6_col18\" class=\"data row6 col18\" >30.6667</td>\n",
       "      <td id=\"T_ba898_row6_col19\" class=\"data row6 col19\" >2.95e-05</td>\n",
       "      <td id=\"T_ba898_row6_col20\" class=\"data row6 col20\" >4.0000</td>\n",
       "      <td id=\"T_ba898_row6_col21\" class=\"data row6 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row6_col22\" class=\"data row6 col22\" >84.7956</td>\n",
       "      <td id=\"T_ba898_row6_col23\" class=\"data row6 col23\" >3.40e+12</td>\n",
       "      <td id=\"T_ba898_row6_col24\" class=\"data row6 col24\" >0.6507</td>\n",
       "      <td id=\"T_ba898_row6_col25\" class=\"data row6 col25\" >0.4354</td>\n",
       "      <td id=\"T_ba898_row6_col26\" class=\"data row6 col26\" >0.5318</td>\n",
       "      <td id=\"T_ba898_row6_col27\" class=\"data row6 col27\" >0.4065</td>\n",
       "      <td id=\"T_ba898_row6_col28\" class=\"data row6 col28\" >0.3864</td>\n",
       "      <td id=\"T_ba898_row6_col29\" class=\"data row6 col29\" >0.3813</td>\n",
       "      <td id=\"T_ba898_row6_col30\" class=\"data row6 col30\" >0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row7\" class=\"row_heading level0 row7\" >5</th>\n",
       "      <td id=\"T_ba898_row7_col0\" class=\"data row7 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row7_col1\" class=\"data row7 col1\" >10.0000</td>\n",
       "      <td id=\"T_ba898_row7_col2\" class=\"data row7 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_ba898_row7_col3\" class=\"data row7 col3\" >0.6345</td>\n",
       "      <td id=\"T_ba898_row7_col4\" class=\"data row7 col4\" >0.1311</td>\n",
       "      <td id=\"T_ba898_row7_col5\" class=\"data row7 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row7_col6\" class=\"data row7 col6\" >31</td>\n",
       "      <td id=\"T_ba898_row7_col7\" class=\"data row7 col7\" >7.9e-07</td>\n",
       "      <td id=\"T_ba898_row7_col8\" class=\"data row7 col8\" >4.7e-01</td>\n",
       "      <td id=\"T_ba898_row7_col9\" class=\"data row7 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row7_col10\" class=\"data row7 col10\" >99.8136</td>\n",
       "      <td id=\"T_ba898_row7_col11\" class=\"data row7 col11\" >27.8077</td>\n",
       "      <td id=\"T_ba898_row7_col12\" class=\"data row7 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row7_col13\" class=\"data row7 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col14\" class=\"data row7 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col15\" class=\"data row7 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col16\" class=\"data row7 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col17\" class=\"data row7 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col18\" class=\"data row7 col18\" >30.3333</td>\n",
       "      <td id=\"T_ba898_row7_col19\" class=\"data row7 col19\" >1.42e-06</td>\n",
       "      <td id=\"T_ba898_row7_col20\" class=\"data row7 col20\" >3.6667</td>\n",
       "      <td id=\"T_ba898_row7_col21\" class=\"data row7 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row7_col22\" class=\"data row7 col22\" >84.7421</td>\n",
       "      <td id=\"T_ba898_row7_col23\" class=\"data row7 col23\" >6.25e+10</td>\n",
       "      <td id=\"T_ba898_row7_col24\" class=\"data row7 col24\" >0.6527</td>\n",
       "      <td id=\"T_ba898_row7_col25\" class=\"data row7 col25\" >0.4171</td>\n",
       "      <td id=\"T_ba898_row7_col26\" class=\"data row7 col26\" >0.5681</td>\n",
       "      <td id=\"T_ba898_row7_col27\" class=\"data row7 col27\" >0.5159</td>\n",
       "      <td id=\"T_ba898_row7_col28\" class=\"data row7 col28\" >0.4956</td>\n",
       "      <td id=\"T_ba898_row7_col29\" class=\"data row7 col29\" >0.3850</td>\n",
       "      <td id=\"T_ba898_row7_col30\" class=\"data row7 col30\" >0.0705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba898_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ba898_row8_col0\" class=\"data row8 col0\" >base_no_stab</td>\n",
       "      <td id=\"T_ba898_row8_col1\" class=\"data row8 col1\" >100.0000</td>\n",
       "      <td id=\"T_ba898_row8_col2\" class=\"data row8 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_ba898_row8_col3\" class=\"data row8 col3\" >0.3964</td>\n",
       "      <td id=\"T_ba898_row8_col4\" class=\"data row8 col4\" >0.1557</td>\n",
       "      <td id=\"T_ba898_row8_col5\" class=\"data row8 col5\" >31</td>\n",
       "      <td id=\"T_ba898_row8_col6\" class=\"data row8 col6\" >32</td>\n",
       "      <td id=\"T_ba898_row8_col7\" class=\"data row8 col7\" >7.9e-07</td>\n",
       "      <td id=\"T_ba898_row8_col8\" class=\"data row8 col8\" >4.7e-01</td>\n",
       "      <td id=\"T_ba898_row8_col9\" class=\"data row8 col9\" >0.0e+00</td>\n",
       "      <td id=\"T_ba898_row8_col10\" class=\"data row8 col10\" >99.8136</td>\n",
       "      <td id=\"T_ba898_row8_col11\" class=\"data row8 col11\" >27.8077</td>\n",
       "      <td id=\"T_ba898_row8_col12\" class=\"data row8 col12\" >3</td>\n",
       "      <td id=\"T_ba898_row8_col13\" class=\"data row8 col13\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col14\" class=\"data row8 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col15\" class=\"data row8 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col16\" class=\"data row8 col16\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col17\" class=\"data row8 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col18\" class=\"data row8 col18\" >31.0000</td>\n",
       "      <td id=\"T_ba898_row8_col19\" class=\"data row8 col19\" >1.32e-06</td>\n",
       "      <td id=\"T_ba898_row8_col20\" class=\"data row8 col20\" >3.6667</td>\n",
       "      <td id=\"T_ba898_row8_col21\" class=\"data row8 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_ba898_row8_col22\" class=\"data row8 col22\" >84.7421</td>\n",
       "      <td id=\"T_ba898_row8_col23\" class=\"data row8 col23\" >6.25e+10</td>\n",
       "      <td id=\"T_ba898_row8_col24\" class=\"data row8 col24\" >0.6442</td>\n",
       "      <td id=\"T_ba898_row8_col25\" class=\"data row8 col25\" >0.3570</td>\n",
       "      <td id=\"T_ba898_row8_col26\" class=\"data row8 col26\" >0.4659</td>\n",
       "      <td id=\"T_ba898_row8_col27\" class=\"data row8 col27\" >0.5159</td>\n",
       "      <td id=\"T_ba898_row8_col28\" class=\"data row8 col28\" >0.4956</td>\n",
       "      <td id=\"T_ba898_row8_col29\" class=\"data row8 col29\" >0.3850</td>\n",
       "      <td id=\"T_ba898_row8_col30\" class=\"data row8 col30\" >0.0705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf4419fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.013803482055664062  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_table2(sim):\n",
    "\n",
    "    vns_drop = ['ch_few', 'ch_many', 'ch_vn0', 'ch_value0']\n",
    "    \n",
    "    vns_sort = ['difficulty', 'exch_epsilon']\n",
    "\n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl2\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg2 = make_table2(sim2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 3: stabilizing order\n",
    "\t\n",
    "1. Add stabilizing order and compare the stdev of prices with and without \n",
    "2. With the baseline parameters including 500 assets and 100,000 orders \n",
    "3. No stabilizing order everywhere else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nreps =  3\n",
      "difficulty =  ['base']\n",
      "change_few =  ['ch2test']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:20<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/sim3_RZtest_2023-1204-2044.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  20.409128427505493  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate3():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim3\")\n",
    "\n",
    "    nreps = 51 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "\n",
    "    #sim.dd_difficulty['stab'] = {'stab_max_qv' : 20.00, 'stab_ph_frac' : 0.70, 'stab_pl_frac' : 0.20}\n",
    "\n",
    "    difficulty = ['base'] \n",
    "\n",
    "    sim.dvd_change_few['ch2DM'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl, 'stab_max_qv' : stqv} \n",
    "        for eps in [0.00, 1.0e-25, 1.00e-4, 1.00e-3, 1.00e-2, 1.00e-1, 1.00e-0, 1.00e4]\n",
    "        for phpl in [1.00, 10.00, 100.00] for stqv in [0.00, 0.10, 1.00, 10.00]]\n",
    "\n",
    "    sim.dvd_change_few['ch2PK'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl, 'stab_max_qv' : stqv} \n",
    "        for eps in [0.00, 1.00e-4, 1.00e-3, 1.00e-2, 1.00e-1, 1.00e0, 1.00e4]\n",
    "        for phpl in [1.00, 10.00] for stqv in [0.00, 1.00, 1.00e+1]]\n",
    "\n",
    "    sim.dvd_change_few['ch2test'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : phpl, 'stab_max_qv' : stqv} \n",
    "        for eps in [1.00e-4, 1.00e-3]\n",
    "        for phpl in [10.00, 100.00] for stqv in [1.00, 10.00]] \n",
    "\n",
    "    change_few = ['ch2DM'] if RUN_TYPE == 'workstation' else ['ch2PK'] if RUN_TYPE == 'laptop' else ['ch2test']\n",
    "\n",
    "    #sim.dvd_change_many['test_many'] = [{'exch_max_qv' : 100.00}, {'fracMA' : 0.99}]\n",
    "    change_many = ['none']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim3 = simulate3()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_90930\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_90930_level0_col0\" class=\"col_heading level0 col0\" >difficulty</th>\n",
       "      <th id=\"T_90930_level0_col1\" class=\"col_heading level0 col1\" >exch_phpl_frac</th>\n",
       "      <th id=\"T_90930_level0_col2\" class=\"col_heading level0 col2\" >exch_epsilon</th>\n",
       "      <th id=\"T_90930_level0_col3\" class=\"col_heading level0 col3\" >stab_max_qv</th>\n",
       "      <th id=\"T_90930_level0_col4\" class=\"col_heading level0 col4\" >dt_med</th>\n",
       "      <th id=\"T_90930_level0_col5\" class=\"col_heading level0 col5\" >dt_std</th>\n",
       "      <th id=\"T_90930_level0_col6\" class=\"col_heading level0 col6\" >niter_med</th>\n",
       "      <th id=\"T_90930_level0_col7\" class=\"col_heading level0 col7\" >niter_max</th>\n",
       "      <th id=\"T_90930_level0_col8\" class=\"col_heading level0 col8\" >unclpM</th>\n",
       "      <th id=\"T_90930_level0_col9\" class=\"col_heading level0 col9\" >exchpM</th>\n",
       "      <th id=\"T_90930_level0_col10\" class=\"col_heading level0 col10\" >stabpM</th>\n",
       "      <th id=\"T_90930_level0_col11\" class=\"col_heading level0 col11\" >p</th>\n",
       "      <th id=\"T_90930_level0_col12\" class=\"col_heading level0 col12\" >p_std</th>\n",
       "      <th id=\"T_90930_level0_col13\" class=\"col_heading level0 col13\" >count</th>\n",
       "      <th id=\"T_90930_level0_col14\" class=\"col_heading level0 col14\" >num_exch_full</th>\n",
       "      <th id=\"T_90930_level0_col15\" class=\"col_heading level0 col15\" >num_stab_full</th>\n",
       "      <th id=\"T_90930_level0_col16\" class=\"col_heading level0 col16\" >num_stab_active</th>\n",
       "      <th id=\"T_90930_level0_col17\" class=\"col_heading level0 col17\" >bchofail</th>\n",
       "      <th id=\"T_90930_level0_col18\" class=\"col_heading level0 col18\" >bmaxiter</th>\n",
       "      <th id=\"T_90930_level0_col19\" class=\"col_heading level0 col19\" >niter</th>\n",
       "      <th id=\"T_90930_level0_col20\" class=\"col_heading level0 col20\" >unclpM_max</th>\n",
       "      <th id=\"T_90930_level0_col21\" class=\"col_heading level0 col21\" >n_bad_p</th>\n",
       "      <th id=\"T_90930_level0_col22\" class=\"col_heading level0 col22\" >nchreg</th>\n",
       "      <th id=\"T_90930_level0_col23\" class=\"col_heading level0 col23\" >dvM</th>\n",
       "      <th id=\"T_90930_level0_col24\" class=\"col_heading level0 col24\" >condnum_med</th>\n",
       "      <th id=\"T_90930_level0_col25\" class=\"col_heading level0 col25\" >dt_max</th>\n",
       "      <th id=\"T_90930_level0_col26\" class=\"col_heading level0 col26\" >dt_min</th>\n",
       "      <th id=\"T_90930_level0_col27\" class=\"col_heading level0 col27\" >dt</th>\n",
       "      <th id=\"T_90930_level0_col28\" class=\"col_heading level0 col28\" >exchpM_max</th>\n",
       "      <th id=\"T_90930_level0_col29\" class=\"col_heading level0 col29\" >exchpM_med</th>\n",
       "      <th id=\"T_90930_level0_col30\" class=\"col_heading level0 col30\" >exchpM_min</th>\n",
       "      <th id=\"T_90930_level0_col31\" class=\"col_heading level0 col31\" >exchpM_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row0\" class=\"row_heading level0 row0\" >7</th>\n",
       "      <td id=\"T_90930_row0_col0\" class=\"data row0 col0\" >base</td>\n",
       "      <td id=\"T_90930_row0_col1\" class=\"data row0 col1\" >100.0000</td>\n",
       "      <td id=\"T_90930_row0_col2\" class=\"data row0 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_90930_row0_col3\" class=\"data row0 col3\" >10.0000</td>\n",
       "      <td id=\"T_90930_row0_col4\" class=\"data row0 col4\" >0.4629</td>\n",
       "      <td id=\"T_90930_row0_col5\" class=\"data row0 col5\" >0.1289</td>\n",
       "      <td id=\"T_90930_row0_col6\" class=\"data row0 col6\" >28</td>\n",
       "      <td id=\"T_90930_row0_col7\" class=\"data row0 col7\" >30</td>\n",
       "      <td id=\"T_90930_row0_col8\" class=\"data row0 col8\" >6.8e-07</td>\n",
       "      <td id=\"T_90930_row0_col9\" class=\"data row0 col9\" >3.4e-01</td>\n",
       "      <td id=\"T_90930_row0_col10\" class=\"data row0 col10\" >8.3e+00</td>\n",
       "      <td id=\"T_90930_row0_col11\" class=\"data row0 col11\" >99.8108</td>\n",
       "      <td id=\"T_90930_row0_col12\" class=\"data row0 col12\" >9.1123</td>\n",
       "      <td id=\"T_90930_row0_col13\" class=\"data row0 col13\" >3</td>\n",
       "      <td id=\"T_90930_row0_col14\" class=\"data row0 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col15\" class=\"data row0 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col16\" class=\"data row0 col16\" >18.6667</td>\n",
       "      <td id=\"T_90930_row0_col17\" class=\"data row0 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col18\" class=\"data row0 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col19\" class=\"data row0 col19\" >28.3333</td>\n",
       "      <td id=\"T_90930_row0_col20\" class=\"data row0 col20\" >1.08e-06</td>\n",
       "      <td id=\"T_90930_row0_col21\" class=\"data row0 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col22\" class=\"data row0 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row0_col23\" class=\"data row0 col23\" >84.7445</td>\n",
       "      <td id=\"T_90930_row0_col24\" class=\"data row0 col24\" >6.23e+10</td>\n",
       "      <td id=\"T_90930_row0_col25\" class=\"data row0 col25\" >0.6163</td>\n",
       "      <td id=\"T_90930_row0_col26\" class=\"data row0 col26\" >0.3601</td>\n",
       "      <td id=\"T_90930_row0_col27\" class=\"data row0 col27\" >0.4798</td>\n",
       "      <td id=\"T_90930_row0_col28\" class=\"data row0 col28\" >0.3708</td>\n",
       "      <td id=\"T_90930_row0_col29\" class=\"data row0 col29\" >0.3347</td>\n",
       "      <td id=\"T_90930_row0_col30\" class=\"data row0 col30\" >0.3278</td>\n",
       "      <td id=\"T_90930_row0_col31\" class=\"data row0 col31\" >0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_90930_row1_col0\" class=\"data row1 col0\" >base</td>\n",
       "      <td id=\"T_90930_row1_col1\" class=\"data row1 col1\" >10.0000</td>\n",
       "      <td id=\"T_90930_row1_col2\" class=\"data row1 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_90930_row1_col3\" class=\"data row1 col3\" >10.0000</td>\n",
       "      <td id=\"T_90930_row1_col4\" class=\"data row1 col4\" >0.4614</td>\n",
       "      <td id=\"T_90930_row1_col5\" class=\"data row1 col5\" >0.1015</td>\n",
       "      <td id=\"T_90930_row1_col6\" class=\"data row1 col6\" >28</td>\n",
       "      <td id=\"T_90930_row1_col7\" class=\"data row1 col7\" >31</td>\n",
       "      <td id=\"T_90930_row1_col8\" class=\"data row1 col8\" >6.0e-07</td>\n",
       "      <td id=\"T_90930_row1_col9\" class=\"data row1 col9\" >3.4e-01</td>\n",
       "      <td id=\"T_90930_row1_col10\" class=\"data row1 col10\" >8.3e+00</td>\n",
       "      <td id=\"T_90930_row1_col11\" class=\"data row1 col11\" >99.8108</td>\n",
       "      <td id=\"T_90930_row1_col12\" class=\"data row1 col12\" >9.1123</td>\n",
       "      <td id=\"T_90930_row1_col13\" class=\"data row1 col13\" >3</td>\n",
       "      <td id=\"T_90930_row1_col14\" class=\"data row1 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col15\" class=\"data row1 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col16\" class=\"data row1 col16\" >18.6667</td>\n",
       "      <td id=\"T_90930_row1_col17\" class=\"data row1 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col18\" class=\"data row1 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col19\" class=\"data row1 col19\" >28.6667</td>\n",
       "      <td id=\"T_90930_row1_col20\" class=\"data row1 col20\" >7.35e-07</td>\n",
       "      <td id=\"T_90930_row1_col21\" class=\"data row1 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col22\" class=\"data row1 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row1_col23\" class=\"data row1 col23\" >84.7445</td>\n",
       "      <td id=\"T_90930_row1_col24\" class=\"data row1 col24\" >6.23e+10</td>\n",
       "      <td id=\"T_90930_row1_col25\" class=\"data row1 col25\" >0.5836</td>\n",
       "      <td id=\"T_90930_row1_col26\" class=\"data row1 col26\" >0.3820</td>\n",
       "      <td id=\"T_90930_row1_col27\" class=\"data row1 col27\" >0.4757</td>\n",
       "      <td id=\"T_90930_row1_col28\" class=\"data row1 col28\" >0.3708</td>\n",
       "      <td id=\"T_90930_row1_col29\" class=\"data row1 col29\" >0.3347</td>\n",
       "      <td id=\"T_90930_row1_col30\" class=\"data row1 col30\" >0.3278</td>\n",
       "      <td id=\"T_90930_row1_col31\" class=\"data row1 col31\" >0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_90930_row2_col0\" class=\"data row2 col0\" >base</td>\n",
       "      <td id=\"T_90930_row2_col1\" class=\"data row2 col1\" >10.0000</td>\n",
       "      <td id=\"T_90930_row2_col2\" class=\"data row2 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_90930_row2_col3\" class=\"data row2 col3\" >10.0000</td>\n",
       "      <td id=\"T_90930_row2_col4\" class=\"data row2 col4\" >0.5993</td>\n",
       "      <td id=\"T_90930_row2_col5\" class=\"data row2 col5\" >0.1377</td>\n",
       "      <td id=\"T_90930_row2_col6\" class=\"data row2 col6\" >29</td>\n",
       "      <td id=\"T_90930_row2_col7\" class=\"data row2 col7\" >31</td>\n",
       "      <td id=\"T_90930_row2_col8\" class=\"data row2 col8\" >6.4e-07</td>\n",
       "      <td id=\"T_90930_row2_col9\" class=\"data row2 col9\" >3.5e-02</td>\n",
       "      <td id=\"T_90930_row2_col10\" class=\"data row2 col10\" >8.3e+00</td>\n",
       "      <td id=\"T_90930_row2_col11\" class=\"data row2 col11\" >99.8108</td>\n",
       "      <td id=\"T_90930_row2_col12\" class=\"data row2 col12\" >9.3342</td>\n",
       "      <td id=\"T_90930_row2_col13\" class=\"data row2 col13\" >3</td>\n",
       "      <td id=\"T_90930_row2_col14\" class=\"data row2 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col15\" class=\"data row2 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col16\" class=\"data row2 col16\" >21.0000</td>\n",
       "      <td id=\"T_90930_row2_col17\" class=\"data row2 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col18\" class=\"data row2 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col19\" class=\"data row2 col19\" >29.6667</td>\n",
       "      <td id=\"T_90930_row2_col20\" class=\"data row2 col20\" >7.00e-07</td>\n",
       "      <td id=\"T_90930_row2_col21\" class=\"data row2 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col22\" class=\"data row2 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row2_col23\" class=\"data row2 col23\" >84.7446</td>\n",
       "      <td id=\"T_90930_row2_col24\" class=\"data row2 col24\" >6.23e+11</td>\n",
       "      <td id=\"T_90930_row2_col25\" class=\"data row2 col25\" >0.6511</td>\n",
       "      <td id=\"T_90930_row2_col26\" class=\"data row2 col26\" >0.3910</td>\n",
       "      <td id=\"T_90930_row2_col27\" class=\"data row2 col27\" >0.5471</td>\n",
       "      <td id=\"T_90930_row2_col28\" class=\"data row2 col28\" >0.0374</td>\n",
       "      <td id=\"T_90930_row2_col29\" class=\"data row2 col29\" >0.0341</td>\n",
       "      <td id=\"T_90930_row2_col30\" class=\"data row2 col30\" >0.0336</td>\n",
       "      <td id=\"T_90930_row2_col31\" class=\"data row2 col31\" >2.08e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "      <td id=\"T_90930_row3_col0\" class=\"data row3 col0\" >base</td>\n",
       "      <td id=\"T_90930_row3_col1\" class=\"data row3 col1\" >100.0000</td>\n",
       "      <td id=\"T_90930_row3_col2\" class=\"data row3 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_90930_row3_col3\" class=\"data row3 col3\" >10.0000</td>\n",
       "      <td id=\"T_90930_row3_col4\" class=\"data row3 col4\" >0.4651</td>\n",
       "      <td id=\"T_90930_row3_col5\" class=\"data row3 col5\" >0.0921</td>\n",
       "      <td id=\"T_90930_row3_col6\" class=\"data row3 col6\" >29</td>\n",
       "      <td id=\"T_90930_row3_col7\" class=\"data row3 col7\" >32</td>\n",
       "      <td id=\"T_90930_row3_col8\" class=\"data row3 col8\" >5.3e-07</td>\n",
       "      <td id=\"T_90930_row3_col9\" class=\"data row3 col9\" >3.5e-02</td>\n",
       "      <td id=\"T_90930_row3_col10\" class=\"data row3 col10\" >8.3e+00</td>\n",
       "      <td id=\"T_90930_row3_col11\" class=\"data row3 col11\" >99.8108</td>\n",
       "      <td id=\"T_90930_row3_col12\" class=\"data row3 col12\" >9.3342</td>\n",
       "      <td id=\"T_90930_row3_col13\" class=\"data row3 col13\" >3</td>\n",
       "      <td id=\"T_90930_row3_col14\" class=\"data row3 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col15\" class=\"data row3 col15\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col16\" class=\"data row3 col16\" >21.0000</td>\n",
       "      <td id=\"T_90930_row3_col17\" class=\"data row3 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col18\" class=\"data row3 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col19\" class=\"data row3 col19\" >29.6667</td>\n",
       "      <td id=\"T_90930_row3_col20\" class=\"data row3 col20\" >6.30e-07</td>\n",
       "      <td id=\"T_90930_row3_col21\" class=\"data row3 col21\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col22\" class=\"data row3 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row3_col23\" class=\"data row3 col23\" >84.7446</td>\n",
       "      <td id=\"T_90930_row3_col24\" class=\"data row3 col24\" >6.23e+11</td>\n",
       "      <td id=\"T_90930_row3_col25\" class=\"data row3 col25\" >0.4828</td>\n",
       "      <td id=\"T_90930_row3_col26\" class=\"data row3 col26\" >0.3152</td>\n",
       "      <td id=\"T_90930_row3_col27\" class=\"data row3 col27\" >0.4210</td>\n",
       "      <td id=\"T_90930_row3_col28\" class=\"data row3 col28\" >0.0374</td>\n",
       "      <td id=\"T_90930_row3_col29\" class=\"data row3 col29\" >0.0341</td>\n",
       "      <td id=\"T_90930_row3_col30\" class=\"data row3 col30\" >0.0336</td>\n",
       "      <td id=\"T_90930_row3_col31\" class=\"data row3 col31\" >2.08e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row4\" class=\"row_heading level0 row4\" >6</th>\n",
       "      <td id=\"T_90930_row4_col0\" class=\"data row4 col0\" >base</td>\n",
       "      <td id=\"T_90930_row4_col1\" class=\"data row4 col1\" >100.0000</td>\n",
       "      <td id=\"T_90930_row4_col2\" class=\"data row4 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_90930_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_90930_row4_col4\" class=\"data row4 col4\" >0.5029</td>\n",
       "      <td id=\"T_90930_row4_col5\" class=\"data row4 col5\" >0.1162</td>\n",
       "      <td id=\"T_90930_row4_col6\" class=\"data row4 col6\" >29</td>\n",
       "      <td id=\"T_90930_row4_col7\" class=\"data row4 col7\" >31</td>\n",
       "      <td id=\"T_90930_row4_col8\" class=\"data row4 col8\" >5.8e-07</td>\n",
       "      <td id=\"T_90930_row4_col9\" class=\"data row4 col9\" >3.5e-01</td>\n",
       "      <td id=\"T_90930_row4_col10\" class=\"data row4 col10\" >1.6e+00</td>\n",
       "      <td id=\"T_90930_row4_col11\" class=\"data row4 col11\" >99.8072</td>\n",
       "      <td id=\"T_90930_row4_col12\" class=\"data row4 col12\" >10.3944</td>\n",
       "      <td id=\"T_90930_row4_col13\" class=\"data row4 col13\" >3</td>\n",
       "      <td id=\"T_90930_row4_col14\" class=\"data row4 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row4_col15\" class=\"data row4 col15\" >0.6667</td>\n",
       "      <td id=\"T_90930_row4_col16\" class=\"data row4 col16\" >17.0000</td>\n",
       "      <td id=\"T_90930_row4_col17\" class=\"data row4 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row4_col18\" class=\"data row4 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row4_col19\" class=\"data row4 col19\" >29.3333</td>\n",
       "      <td id=\"T_90930_row4_col20\" class=\"data row4 col20\" >8.08e-07</td>\n",
       "      <td id=\"T_90930_row4_col21\" class=\"data row4 col21\" >0.3333</td>\n",
       "      <td id=\"T_90930_row4_col22\" class=\"data row4 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row4_col23\" class=\"data row4 col23\" >84.7451</td>\n",
       "      <td id=\"T_90930_row4_col24\" class=\"data row4 col24\" >6.22e+10</td>\n",
       "      <td id=\"T_90930_row4_col25\" class=\"data row4 col25\" >0.6242</td>\n",
       "      <td id=\"T_90930_row4_col26\" class=\"data row4 col26\" >0.3919</td>\n",
       "      <td id=\"T_90930_row4_col27\" class=\"data row4 col27\" >0.5063</td>\n",
       "      <td id=\"T_90930_row4_col28\" class=\"data row4 col28\" >0.3835</td>\n",
       "      <td id=\"T_90930_row4_col29\" class=\"data row4 col29\" >0.3353</td>\n",
       "      <td id=\"T_90930_row4_col30\" class=\"data row4 col30\" >0.3309</td>\n",
       "      <td id=\"T_90930_row4_col31\" class=\"data row4 col31\" >0.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "      <td id=\"T_90930_row5_col0\" class=\"data row5 col0\" >base</td>\n",
       "      <td id=\"T_90930_row5_col1\" class=\"data row5 col1\" >10.0000</td>\n",
       "      <td id=\"T_90930_row5_col2\" class=\"data row5 col2\" >1.00e-03</td>\n",
       "      <td id=\"T_90930_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_90930_row5_col4\" class=\"data row5 col4\" >0.4694</td>\n",
       "      <td id=\"T_90930_row5_col5\" class=\"data row5 col5\" >0.0109</td>\n",
       "      <td id=\"T_90930_row5_col6\" class=\"data row5 col6\" >30</td>\n",
       "      <td id=\"T_90930_row5_col7\" class=\"data row5 col7\" >32</td>\n",
       "      <td id=\"T_90930_row5_col8\" class=\"data row5 col8\" >6.3e-07</td>\n",
       "      <td id=\"T_90930_row5_col9\" class=\"data row5 col9\" >3.5e-01</td>\n",
       "      <td id=\"T_90930_row5_col10\" class=\"data row5 col10\" >1.6e+00</td>\n",
       "      <td id=\"T_90930_row5_col11\" class=\"data row5 col11\" >99.8072</td>\n",
       "      <td id=\"T_90930_row5_col12\" class=\"data row5 col12\" >10.3944</td>\n",
       "      <td id=\"T_90930_row5_col13\" class=\"data row5 col13\" >3</td>\n",
       "      <td id=\"T_90930_row5_col14\" class=\"data row5 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row5_col15\" class=\"data row5 col15\" >0.6667</td>\n",
       "      <td id=\"T_90930_row5_col16\" class=\"data row5 col16\" >17.0000</td>\n",
       "      <td id=\"T_90930_row5_col17\" class=\"data row5 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row5_col18\" class=\"data row5 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row5_col19\" class=\"data row5 col19\" >30.3333</td>\n",
       "      <td id=\"T_90930_row5_col20\" class=\"data row5 col20\" >9.67e-07</td>\n",
       "      <td id=\"T_90930_row5_col21\" class=\"data row5 col21\" >0.3333</td>\n",
       "      <td id=\"T_90930_row5_col22\" class=\"data row5 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row5_col23\" class=\"data row5 col23\" >84.7451</td>\n",
       "      <td id=\"T_90930_row5_col24\" class=\"data row5 col24\" >6.22e+10</td>\n",
       "      <td id=\"T_90930_row5_col25\" class=\"data row5 col25\" >0.4704</td>\n",
       "      <td id=\"T_90930_row5_col26\" class=\"data row5 col26\" >0.4510</td>\n",
       "      <td id=\"T_90930_row5_col27\" class=\"data row5 col27\" >0.4636</td>\n",
       "      <td id=\"T_90930_row5_col28\" class=\"data row5 col28\" >0.3835</td>\n",
       "      <td id=\"T_90930_row5_col29\" class=\"data row5 col29\" >0.3353</td>\n",
       "      <td id=\"T_90930_row5_col30\" class=\"data row5 col30\" >0.3309</td>\n",
       "      <td id=\"T_90930_row5_col31\" class=\"data row5 col31\" >0.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row6\" class=\"row_heading level0 row6\" >0</th>\n",
       "      <td id=\"T_90930_row6_col0\" class=\"data row6 col0\" >base</td>\n",
       "      <td id=\"T_90930_row6_col1\" class=\"data row6 col1\" >10.0000</td>\n",
       "      <td id=\"T_90930_row6_col2\" class=\"data row6 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_90930_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_90930_row6_col4\" class=\"data row6 col4\" >0.3564</td>\n",
       "      <td id=\"T_90930_row6_col5\" class=\"data row6 col5\" >0.0671</td>\n",
       "      <td id=\"T_90930_row6_col6\" class=\"data row6 col6\" >31</td>\n",
       "      <td id=\"T_90930_row6_col7\" class=\"data row6 col7\" >31</td>\n",
       "      <td id=\"T_90930_row6_col8\" class=\"data row6 col8\" >6.0e-07</td>\n",
       "      <td id=\"T_90930_row6_col9\" class=\"data row6 col9\" >3.6e-02</td>\n",
       "      <td id=\"T_90930_row6_col10\" class=\"data row6 col10\" >1.6e+00</td>\n",
       "      <td id=\"T_90930_row6_col11\" class=\"data row6 col11\" >99.8083</td>\n",
       "      <td id=\"T_90930_row6_col12\" class=\"data row6 col12\" >10.6869</td>\n",
       "      <td id=\"T_90930_row6_col13\" class=\"data row6 col13\" >3</td>\n",
       "      <td id=\"T_90930_row6_col14\" class=\"data row6 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row6_col15\" class=\"data row6 col15\" >0.6667</td>\n",
       "      <td id=\"T_90930_row6_col16\" class=\"data row6 col16\" >20.0000</td>\n",
       "      <td id=\"T_90930_row6_col17\" class=\"data row6 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row6_col18\" class=\"data row6 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row6_col19\" class=\"data row6 col19\" >30.6667</td>\n",
       "      <td id=\"T_90930_row6_col20\" class=\"data row6 col20\" >7.90e-07</td>\n",
       "      <td id=\"T_90930_row6_col21\" class=\"data row6 col21\" >0.3333</td>\n",
       "      <td id=\"T_90930_row6_col22\" class=\"data row6 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row6_col23\" class=\"data row6 col23\" >84.7450</td>\n",
       "      <td id=\"T_90930_row6_col24\" class=\"data row6 col24\" >6.22e+11</td>\n",
       "      <td id=\"T_90930_row6_col25\" class=\"data row6 col25\" >0.4720</td>\n",
       "      <td id=\"T_90930_row6_col26\" class=\"data row6 col26\" >0.3554</td>\n",
       "      <td id=\"T_90930_row6_col27\" class=\"data row6 col27\" >0.3946</td>\n",
       "      <td id=\"T_90930_row6_col28\" class=\"data row6 col28\" >0.0388</td>\n",
       "      <td id=\"T_90930_row6_col29\" class=\"data row6 col29\" >0.0344</td>\n",
       "      <td id=\"T_90930_row6_col30\" class=\"data row6 col30\" >0.0339</td>\n",
       "      <td id=\"T_90930_row6_col31\" class=\"data row6 col31\" >2.70e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_90930_level0_row7\" class=\"row_heading level0 row7\" >4</th>\n",
       "      <td id=\"T_90930_row7_col0\" class=\"data row7 col0\" >base</td>\n",
       "      <td id=\"T_90930_row7_col1\" class=\"data row7 col1\" >100.0000</td>\n",
       "      <td id=\"T_90930_row7_col2\" class=\"data row7 col2\" >1.00e-04</td>\n",
       "      <td id=\"T_90930_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_90930_row7_col4\" class=\"data row7 col4\" >0.6803</td>\n",
       "      <td id=\"T_90930_row7_col5\" class=\"data row7 col5\" >0.1964</td>\n",
       "      <td id=\"T_90930_row7_col6\" class=\"data row7 col6\" >31</td>\n",
       "      <td id=\"T_90930_row7_col7\" class=\"data row7 col7\" >32</td>\n",
       "      <td id=\"T_90930_row7_col8\" class=\"data row7 col8\" >5.6e-07</td>\n",
       "      <td id=\"T_90930_row7_col9\" class=\"data row7 col9\" >3.6e-02</td>\n",
       "      <td id=\"T_90930_row7_col10\" class=\"data row7 col10\" >1.6e+00</td>\n",
       "      <td id=\"T_90930_row7_col11\" class=\"data row7 col11\" >99.8083</td>\n",
       "      <td id=\"T_90930_row7_col12\" class=\"data row7 col12\" >10.6869</td>\n",
       "      <td id=\"T_90930_row7_col13\" class=\"data row7 col13\" >3</td>\n",
       "      <td id=\"T_90930_row7_col14\" class=\"data row7 col14\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row7_col15\" class=\"data row7 col15\" >0.6667</td>\n",
       "      <td id=\"T_90930_row7_col16\" class=\"data row7 col16\" >20.0000</td>\n",
       "      <td id=\"T_90930_row7_col17\" class=\"data row7 col17\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row7_col18\" class=\"data row7 col18\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row7_col19\" class=\"data row7 col19\" >31.0000</td>\n",
       "      <td id=\"T_90930_row7_col20\" class=\"data row7 col20\" >6.54e-07</td>\n",
       "      <td id=\"T_90930_row7_col21\" class=\"data row7 col21\" >0.3333</td>\n",
       "      <td id=\"T_90930_row7_col22\" class=\"data row7 col22\" >0.00e+00</td>\n",
       "      <td id=\"T_90930_row7_col23\" class=\"data row7 col23\" >84.7450</td>\n",
       "      <td id=\"T_90930_row7_col24\" class=\"data row7 col24\" >6.22e+11</td>\n",
       "      <td id=\"T_90930_row7_col25\" class=\"data row7 col25\" >0.7232</td>\n",
       "      <td id=\"T_90930_row7_col26\" class=\"data row7 col26\" >0.3636</td>\n",
       "      <td id=\"T_90930_row7_col27\" class=\"data row7 col27\" >0.5890</td>\n",
       "      <td id=\"T_90930_row7_col28\" class=\"data row7 col28\" >0.0388</td>\n",
       "      <td id=\"T_90930_row7_col29\" class=\"data row7 col29\" >0.0344</td>\n",
       "      <td id=\"T_90930_row7_col30\" class=\"data row7 col30\" >0.0339</td>\n",
       "      <td id=\"T_90930_row7_col31\" class=\"data row7 col31\" >2.70e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddf44b0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.01909923553466797  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_table3(sim):\n",
    "\n",
    "    vns_drop = ['ch_few', 'ch_many', 'ch_vn0', 'ch_value0']\n",
    "\n",
    "    vns_sort = ['difficulty', 'p_std']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl3\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg3 = make_table3(sim3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 4: number of orders and number of assets (no stabilizing order) \n",
    "\n",
    "1. Flip the left and right of the pictures \n",
    "2. Find out why there is a jump in the number of orders. (Unknown at this point!) \n",
    "3. All with the baseline parameters \n",
    "4. For the number of orders: increase the domain to 1e7 and add grid lines for 1e2, 1e4, 1e6, and 1e7 (Grid lines are hard to control.  Making the figure slightly larger increases the number of grid lines.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_reverseiterator object at 0x000001DDF4778EB0>\n",
      "nreps =  1\n",
      "difficulty =  ['base']\n",
      "change_few =  ['figN']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:14<00:00, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/sim4N_RZtest_2023-1204-2044.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  14.609869241714478  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate4n():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim4N\")\n",
    "\n",
    "    nreps = 1\n",
    "\n",
    "    nobs = 500 if RUN_TYPE == 'workstation' else 500 if RUN_TYPE == 'laptop' else 20\n",
    "    Nmin = 10\n",
    "    Nmax = 10000 if RUN_TYPE == 'workstation' else 5000 if RUN_TYPE == 'laptop' else 1000\n",
    "    \n",
    "    difficulty = ['base'] \n",
    "\n",
    "    sim.dvd_change_few['figN'] = reversed([{'N' : int(Nmin * (Nmax/ Nmin)**(x / (nobs-1))) } for x in range(nobs) ])\n",
    "\n",
    "    print(sim.dvd_change_few['figN'])\n",
    "    \n",
    "    change_few = ['figN']\n",
    "    \n",
    "    change_many = ['none']\n",
    "\n",
    "    df = sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim4n = simulate4n()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>dt</th>\n",
       "      <th>niter</th>\n",
       "      <th>pmean_pct</th>\n",
       "      <th>pstd_pct</th>\n",
       "      <th>unclpM</th>\n",
       "      <th>exchpM</th>\n",
       "      <th>stabpM</th>\n",
       "      <th>pairpM</th>\n",
       "      <th>dvM</th>\n",
       "      <th>cond_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>1000</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.50e-01</td>\n",
       "      <td>34</td>\n",
       "      <td>9.91e+01</td>\n",
       "      <td>1.32e+01</td>\n",
       "      <td>1.06e-06</td>\n",
       "      <td>6.10e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.38e+05</td>\n",
       "      <td>1.12e+02</td>\n",
       "      <td>8.48e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>784</td>\n",
       "      <td>100000</td>\n",
       "      <td>4.76e-01</td>\n",
       "      <td>32</td>\n",
       "      <td>9.95e+01</td>\n",
       "      <td>1.40e+01</td>\n",
       "      <td>5.70e-07</td>\n",
       "      <td>5.10e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.37e+05</td>\n",
       "      <td>1.05e+02</td>\n",
       "      <td>3.63e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>615</td>\n",
       "      <td>100000</td>\n",
       "      <td>7.53e-01</td>\n",
       "      <td>32</td>\n",
       "      <td>9.92e+01</td>\n",
       "      <td>1.30e+01</td>\n",
       "      <td>4.54e-07</td>\n",
       "      <td>4.29e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.47e+05</td>\n",
       "      <td>9.16e+01</td>\n",
       "      <td>1.60e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>483</td>\n",
       "      <td>100000</td>\n",
       "      <td>6.97e-01</td>\n",
       "      <td>32</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>8.66e+00</td>\n",
       "      <td>6.96e-07</td>\n",
       "      <td>2.97e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.49e+05</td>\n",
       "      <td>8.45e+01</td>\n",
       "      <td>7.81e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>379</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.01e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>2.09e+01</td>\n",
       "      <td>1.47e-06</td>\n",
       "      <td>3.41e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.48e+05</td>\n",
       "      <td>7.89e+01</td>\n",
       "      <td>5.36e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>297</td>\n",
       "      <td>100000</td>\n",
       "      <td>6.45e-01</td>\n",
       "      <td>30</td>\n",
       "      <td>9.98e+01</td>\n",
       "      <td>1.03e+01</td>\n",
       "      <td>8.65e-07</td>\n",
       "      <td>1.44e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.56e+05</td>\n",
       "      <td>9.61e+01</td>\n",
       "      <td>1.14e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td>233</td>\n",
       "      <td>100000</td>\n",
       "      <td>4.95e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>6.88e+00</td>\n",
       "      <td>7.24e-07</td>\n",
       "      <td>1.06e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.59e+05</td>\n",
       "      <td>8.82e+01</td>\n",
       "      <td>1.64e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base</td>\n",
       "      <td>183</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.58e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>9.95e+01</td>\n",
       "      <td>7.69e+00</td>\n",
       "      <td>6.99e-05</td>\n",
       "      <td>9.14e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.55e+05</td>\n",
       "      <td>8.62e+01</td>\n",
       "      <td>2.64e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base</td>\n",
       "      <td>143</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.16e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>9.89e+01</td>\n",
       "      <td>6.63e+00</td>\n",
       "      <td>7.18e-06</td>\n",
       "      <td>6.44e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.59e+05</td>\n",
       "      <td>7.74e+01</td>\n",
       "      <td>4.84e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base</td>\n",
       "      <td>112</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.97e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>3.51e+00</td>\n",
       "      <td>3.15e-07</td>\n",
       "      <td>3.82e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.58e+05</td>\n",
       "      <td>7.29e+01</td>\n",
       "      <td>2.25e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base</td>\n",
       "      <td>88</td>\n",
       "      <td>100000</td>\n",
       "      <td>4.98e-01</td>\n",
       "      <td>27</td>\n",
       "      <td>9.92e+01</td>\n",
       "      <td>5.19e+00</td>\n",
       "      <td>3.83e-07</td>\n",
       "      <td>4.34e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.56e+05</td>\n",
       "      <td>6.78e+01</td>\n",
       "      <td>4.61e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base</td>\n",
       "      <td>69</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.24e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.88e+01</td>\n",
       "      <td>4.16e+00</td>\n",
       "      <td>1.69e-07</td>\n",
       "      <td>2.06e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.72e+05</td>\n",
       "      <td>7.71e+01</td>\n",
       "      <td>2.02e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>base</td>\n",
       "      <td>54</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.19e-01</td>\n",
       "      <td>27</td>\n",
       "      <td>9.98e+01</td>\n",
       "      <td>2.30e+00</td>\n",
       "      <td>4.91e-04</td>\n",
       "      <td>1.20e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.73e+05</td>\n",
       "      <td>7.28e+01</td>\n",
       "      <td>1.57e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>base</td>\n",
       "      <td>42</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.30e-01</td>\n",
       "      <td>24</td>\n",
       "      <td>9.99e+01</td>\n",
       "      <td>2.63e+00</td>\n",
       "      <td>9.69e-07</td>\n",
       "      <td>1.01e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.72e+05</td>\n",
       "      <td>6.95e+01</td>\n",
       "      <td>4.49e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>base</td>\n",
       "      <td>33</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.97e-01</td>\n",
       "      <td>26</td>\n",
       "      <td>9.90e+01</td>\n",
       "      <td>2.69e+00</td>\n",
       "      <td>4.71e-08</td>\n",
       "      <td>9.76e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.72e+05</td>\n",
       "      <td>6.75e+01</td>\n",
       "      <td>1.18e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>base</td>\n",
       "      <td>26</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.30e-01</td>\n",
       "      <td>25</td>\n",
       "      <td>9.90e+01</td>\n",
       "      <td>2.35e+00</td>\n",
       "      <td>3.09e-04</td>\n",
       "      <td>6.69e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.68e+05</td>\n",
       "      <td>6.49e+01</td>\n",
       "      <td>8.15e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>base</td>\n",
       "      <td>20</td>\n",
       "      <td>100000</td>\n",
       "      <td>5.33e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>9.93e+01</td>\n",
       "      <td>1.28e+00</td>\n",
       "      <td>3.06e-05</td>\n",
       "      <td>3.88e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.69e+05</td>\n",
       "      <td>6.19e+01</td>\n",
       "      <td>2.31e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>base</td>\n",
       "      <td>16</td>\n",
       "      <td>100000</td>\n",
       "      <td>4.75e-01</td>\n",
       "      <td>23</td>\n",
       "      <td>9.91e+01</td>\n",
       "      <td>7.00e-01</td>\n",
       "      <td>2.51e-06</td>\n",
       "      <td>2.39e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.77e+05</td>\n",
       "      <td>6.30e+01</td>\n",
       "      <td>1.16e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>base</td>\n",
       "      <td>12</td>\n",
       "      <td>100000</td>\n",
       "      <td>3.78e-01</td>\n",
       "      <td>23</td>\n",
       "      <td>9.94e+01</td>\n",
       "      <td>6.89e-01</td>\n",
       "      <td>2.60e-08</td>\n",
       "      <td>1.41e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.66e+05</td>\n",
       "      <td>6.34e+01</td>\n",
       "      <td>1.66e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>base</td>\n",
       "      <td>10</td>\n",
       "      <td>100000</td>\n",
       "      <td>4.40e-01</td>\n",
       "      <td>21</td>\n",
       "      <td>9.94e+01</td>\n",
       "      <td>4.77e-01</td>\n",
       "      <td>1.36e-07</td>\n",
       "      <td>1.00e-02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.66e+05</td>\n",
       "      <td>6.22e+01</td>\n",
       "      <td>1.07e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty     N       M       dt  niter  pmean_pct  pstd_pct   unclpM   exchpM   stabpM   pairpM      dvM  cond_num\n",
       "0        base  1000  100000 5.50e-01     34   9.91e+01  1.32e+01 1.06e-06 6.10e+00 0.00e+00 1.38e+05 1.12e+02  8.48e+09\n",
       "1        base   784  100000 4.76e-01     32   9.95e+01  1.40e+01 5.70e-07 5.10e+00 0.00e+00 1.37e+05 1.05e+02  3.63e+09\n",
       "2        base   615  100000 7.53e-01     32   9.92e+01  1.30e+01 4.54e-07 4.29e+00 0.00e+00 1.47e+05 9.16e+01  1.60e+10\n",
       "3        base   483  100000 6.97e-01     32   9.97e+01  8.66e+00 6.96e-07 2.97e+00 0.00e+00 1.49e+05 8.45e+01  7.81e+09\n",
       "4        base   379  100000 5.01e-01     31   1.00e+02  2.09e+01 1.47e-06 3.41e+00 0.00e+00 1.48e+05 7.89e+01  5.36e+10\n",
       "5        base   297  100000 6.45e-01     30   9.98e+01  1.03e+01 8.65e-07 1.44e+00 0.00e+00 1.56e+05 9.61e+01  1.14e+10\n",
       "6        base   233  100000 4.95e-01     28   1.00e+02  6.88e+00 7.24e-07 1.06e+00 0.00e+00 1.59e+05 8.82e+01  1.64e+10\n",
       "7        base   183  100000 3.58e-01     28   9.95e+01  7.69e+00 6.99e-05 9.14e-01 0.00e+00 1.55e+05 8.62e+01  2.64e+06\n",
       "8        base   143  100000 3.16e-01     28   9.89e+01  6.63e+00 7.18e-06 6.44e-01 0.00e+00 1.59e+05 7.74e+01  4.84e+07\n",
       "9        base   112  100000 5.97e-01     29   9.97e+01  3.51e+00 3.15e-07 3.82e-01 0.00e+00 1.58e+05 7.29e+01  2.25e+06\n",
       "10       base    88  100000 4.98e-01     27   9.92e+01  5.19e+00 3.83e-07 4.34e-01 0.00e+00 1.56e+05 6.78e+01  4.61e+05\n",
       "11       base    69  100000 3.24e-01     29   9.88e+01  4.16e+00 1.69e-07 2.06e-01 0.00e+00 1.72e+05 7.71e+01  2.02e+07\n",
       "12       base    54  100000 3.19e-01     27   9.98e+01  2.30e+00 4.91e-04 1.20e-01 0.00e+00 1.73e+05 7.28e+01  1.57e+05\n",
       "13       base    42  100000 5.30e-01     24   9.99e+01  2.63e+00 9.69e-07 1.01e-01 0.00e+00 1.72e+05 6.95e+01  4.49e+04\n",
       "14       base    33  100000 2.97e-01     26   9.90e+01  2.69e+00 4.71e-08 9.76e-02 0.00e+00 1.72e+05 6.75e+01  1.18e+05\n",
       "15       base    26  100000 5.30e-01     25   9.90e+01  2.35e+00 3.09e-04 6.69e-02 0.00e+00 1.68e+05 6.49e+01  8.15e+04\n",
       "16       base    20  100000 5.33e-01     28   9.93e+01  1.28e+00 3.06e-05 3.88e-02 0.00e+00 1.69e+05 6.19e+01  2.31e+04\n",
       "17       base    16  100000 4.75e-01     23   9.91e+01  7.00e-01 2.51e-06 2.39e-02 0.00e+00 1.77e+05 6.30e+01  1.16e+05\n",
       "18       base    12  100000 3.78e-01     23   9.94e+01  6.89e-01 2.60e-08 1.41e-02 0.00e+00 1.66e+05 6.34e+01  1.66e+03\n",
       "19       base    10  100000 4.40e-01     21   9.94e+01  4.77e-01 1.36e-07 1.00e-02 0.00e+00 1.66e+05 6.22e+01  1.07e+04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.009595870971679688  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_table4n(sim):\n",
    "\n",
    "    #vns_drop = ['ch_few', 'ch_many', 'ch_vn0', 'ch_value0']\n",
    "    \n",
    "    #vns_sort = ['difficulty', 'N']\n",
    "    \n",
    "    #dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl4N\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    dfg = sim.df_sim\n",
    "\n",
    "    #column names for sim.df_sim:\n",
    "    #dt, niter, bmaxiter, bchofail, num_cholesky_regularizations, rxnorm, rynorm, rznorm, nubar, pmean_pct, pstd_pct, \n",
    "    #n_bad_p, num_exch_full, num_stab_full, num_stab_active, cond_num, nseed, i, difficulty, \n",
    "    #ch_few, ch_many, num_changes, ch_vn0, ch_value0, ch_vn1, ch_value1, \n",
    "    #norm, unclpM, exchpM, stabpM, pairpM, dvM, dollar_volume, exchange_dollar_volume, single_asset_dollar_volume, \n",
    "    #pairs_trade_dollar_volume, uncleared_dollar_volume, uncleared_share, exchange_share, stabilizing_share, \n",
    "    #single_asset_share, pairs_trade_share, net_dollar_volume_vec, N, M, exch_liq_model, \n",
    "    #exch_epsilon, exch_phpl_frac, stab_max_qv, stab_ph_frac, stab_pl_frac, fracMA, subfracMX, num_size_indexes, \n",
    "    #num_industry_indexes, market_index_share, size_index_subshare, ew_mkt_index_subshare, \n",
    "    #ew_size_index_subsubshare, ew_industry_index_subsubshare, ew_size_index_alpha, \n",
    "    #std_num_orders_asset, std_order_size, dv_single_asset_orders, std_limit_price, limit_bias, \n",
    "    #avg_ph_minus_pl_bp, std_ph_minus_pl, index_prices, mean_asset_price, std_asset_price, invariance_exponent, \n",
    "    #fraction_buy_orders_asset, fracMX, fracM2, MX, M2, MA, M0, M0s, M1, Mall, NX, NR, ew_mkt_index_share, \n",
    "    #vw_mkt_index_share, industry_index_subshare, ew_size_index_share, vw_size_index_share, \n",
    "    #ew_industry_index_share, vw_industry_index_share, \n",
    "    #maxiter, dtype, device, xtol, ytol, ztol, stol, eta, sigma_exponent, sigma_fac, afac, gamma, one_fac, \n",
    "    #max_alpha, alpha_fac, alpha_trunc_factor, regeps0, regeps2, regepsfactor, \n",
    "    #print_time, print_iteration_results, print_mkt_results, \n",
    "    \n",
    "    vns = ['difficulty', 'N', 'M', 'dt', 'niter', 'pmean_pct', 'pstd_pct', \n",
    "           'unclpM', 'exchpM', 'stabpM', 'pairpM', 'dvM', 'cond_num']\n",
    "    \n",
    "    display(dfg[vns])\n",
    "    \n",
    "    return dfg\n",
    "\n",
    "dfg4n = make_table4n(sim4n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_reverseiterator object at 0x000001DDF47780D0>\n",
      "nreps =  1\n",
      "difficulty =  ['base']\n",
      "change_few =  ['figM']\n",
      "change_many =  ['none']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:32<00:00, 32.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation data save to  C:/Users/richa/Documents/energy_forward_market/outputs/csv/sim4M_RZtest_2023-1204-2044.csv\n",
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  32.42188882827759  sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate4m():\n",
    "\n",
    "    sim = Simulations(name_prefix=\"sim4M\")\n",
    "\n",
    "    nreps = 1\n",
    "\n",
    "    nobs = 500 if RUN_TYPE == 'workstation' else 500 if RUN_TYPE == 'laptop' else 20\n",
    "    Mmin = 100 if RUN_TYPE == 'test' else 100\n",
    "    Mmax = 10**7 if RUN_TYPE == 'workstation' else 5 * 10**6 if RUN_TYPE == 'laptop' else 5 * 10**6\n",
    "    \n",
    "    difficulty = ['base'] \n",
    "\n",
    "    sim.dvd_change_few['figM'] = reversed([{'M' : int(Mmin * (Mmax/ Mmin)**(x / (nobs-1))) } for x in range(nobs) ])\n",
    "\n",
    "    print(sim.dvd_change_few['figM'])\n",
    "    \n",
    "    change_few = ['figM']\n",
    "    \n",
    "    change_many = ['none']\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim4m = simulate4m()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>dt</th>\n",
       "      <th>niter</th>\n",
       "      <th>pmean_pct</th>\n",
       "      <th>pstd_pct</th>\n",
       "      <th>unclpM</th>\n",
       "      <th>exchpM</th>\n",
       "      <th>stabpM</th>\n",
       "      <th>pairpM</th>\n",
       "      <th>dvM</th>\n",
       "      <th>cond_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>5000000</td>\n",
       "      <td>3.08e+00</td>\n",
       "      <td>32</td>\n",
       "      <td>9.95e+01</td>\n",
       "      <td>2.04e+00</td>\n",
       "      <td>9.20e-05</td>\n",
       "      <td>7.63e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.47e+05</td>\n",
       "      <td>8.64e+01</td>\n",
       "      <td>7.50e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>2829148</td>\n",
       "      <td>1.92e+00</td>\n",
       "      <td>33</td>\n",
       "      <td>9.94e+01</td>\n",
       "      <td>2.31e+00</td>\n",
       "      <td>5.54e-06</td>\n",
       "      <td>8.68e-01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.46e+05</td>\n",
       "      <td>8.68e+01</td>\n",
       "      <td>1.17e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>1600816</td>\n",
       "      <td>1.29e+00</td>\n",
       "      <td>32</td>\n",
       "      <td>9.92e+01</td>\n",
       "      <td>4.37e+00</td>\n",
       "      <td>5.19e-05</td>\n",
       "      <td>1.23e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.47e+05</td>\n",
       "      <td>8.63e+01</td>\n",
       "      <td>1.96e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>905789</td>\n",
       "      <td>6.56e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>9.94e+01</td>\n",
       "      <td>5.98e+00</td>\n",
       "      <td>7.10e-07</td>\n",
       "      <td>1.56e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.45e+05</td>\n",
       "      <td>8.66e+01</td>\n",
       "      <td>1.29e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>512522</td>\n",
       "      <td>7.21e-01</td>\n",
       "      <td>33</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>6.98e+00</td>\n",
       "      <td>7.08e-08</td>\n",
       "      <td>1.86e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.47e+05</td>\n",
       "      <td>8.62e+01</td>\n",
       "      <td>4.24e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>290000</td>\n",
       "      <td>4.05e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>8.63e+00</td>\n",
       "      <td>1.33e-04</td>\n",
       "      <td>2.28e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.46e+05</td>\n",
       "      <td>8.67e+01</td>\n",
       "      <td>3.22e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>164090</td>\n",
       "      <td>3.20e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.89e+01</td>\n",
       "      <td>8.28e+00</td>\n",
       "      <td>4.32e-07</td>\n",
       "      <td>2.76e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.48e+05</td>\n",
       "      <td>8.52e+01</td>\n",
       "      <td>4.17e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>92847</td>\n",
       "      <td>3.67e-01</td>\n",
       "      <td>34</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>1.26e+01</td>\n",
       "      <td>4.73e-06</td>\n",
       "      <td>3.57e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.45e+05</td>\n",
       "      <td>8.67e+01</td>\n",
       "      <td>4.20e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>52535</td>\n",
       "      <td>3.39e-01</td>\n",
       "      <td>31</td>\n",
       "      <td>9.96e+01</td>\n",
       "      <td>1.63e+01</td>\n",
       "      <td>3.30e-06</td>\n",
       "      <td>4.63e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.46e+05</td>\n",
       "      <td>8.55e+01</td>\n",
       "      <td>2.71e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>29726</td>\n",
       "      <td>3.40e-01</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>4.08e+01</td>\n",
       "      <td>2.12e-05</td>\n",
       "      <td>9.51e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.60e+05</td>\n",
       "      <td>8.18e+01</td>\n",
       "      <td>1.79e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>16820</td>\n",
       "      <td>3.44e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.97e+01</td>\n",
       "      <td>1.03e+02</td>\n",
       "      <td>1.63e-06</td>\n",
       "      <td>2.18e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.48e+05</td>\n",
       "      <td>8.21e+01</td>\n",
       "      <td>2.41e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>9517</td>\n",
       "      <td>6.26e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>1.02e+02</td>\n",
       "      <td>1.99e+02</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>3.58e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.58e+05</td>\n",
       "      <td>8.48e+01</td>\n",
       "      <td>1.77e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>5385</td>\n",
       "      <td>6.52e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>2.89e+02</td>\n",
       "      <td>4.47e-06</td>\n",
       "      <td>7.32e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.68e+05</td>\n",
       "      <td>7.39e+01</td>\n",
       "      <td>8.59e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>3047</td>\n",
       "      <td>3.65e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.52e+01</td>\n",
       "      <td>2.61e+02</td>\n",
       "      <td>5.88e-06</td>\n",
       "      <td>7.59e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.30e+05</td>\n",
       "      <td>7.55e+01</td>\n",
       "      <td>6.33e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>1724</td>\n",
       "      <td>3.10e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>1.05e+02</td>\n",
       "      <td>2.79e+02</td>\n",
       "      <td>5.73e-06</td>\n",
       "      <td>7.38e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.15e+05</td>\n",
       "      <td>8.57e+01</td>\n",
       "      <td>1.71e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>975</td>\n",
       "      <td>3.15e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.75e+01</td>\n",
       "      <td>9.80e+01</td>\n",
       "      <td>5.96e-05</td>\n",
       "      <td>6.08e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.70e+05</td>\n",
       "      <td>4.35e+01</td>\n",
       "      <td>9.16e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>552</td>\n",
       "      <td>3.04e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>9.74e+01</td>\n",
       "      <td>2.63e+02</td>\n",
       "      <td>7.91e-06</td>\n",
       "      <td>8.01e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>5.44e+04</td>\n",
       "      <td>9.64e+01</td>\n",
       "      <td>3.41e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>312</td>\n",
       "      <td>3.08e-01</td>\n",
       "      <td>29</td>\n",
       "      <td>1.03e+02</td>\n",
       "      <td>4.82e+02</td>\n",
       "      <td>1.30e-05</td>\n",
       "      <td>2.09e+02</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>2.05e+05</td>\n",
       "      <td>6.99e+01</td>\n",
       "      <td>2.77e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>176</td>\n",
       "      <td>3.37e-01</td>\n",
       "      <td>28</td>\n",
       "      <td>9.20e+01</td>\n",
       "      <td>1.33e+02</td>\n",
       "      <td>9.39e-05</td>\n",
       "      <td>9.75e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>5.72e+04</td>\n",
       "      <td>4.91e+01</td>\n",
       "      <td>4.54e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>base</td>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>3.11e-01</td>\n",
       "      <td>27</td>\n",
       "      <td>1.09e+02</td>\n",
       "      <td>8.99e+01</td>\n",
       "      <td>5.71e-05</td>\n",
       "      <td>6.96e+01</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>1.27e+04</td>\n",
       "      <td>4.27e+01</td>\n",
       "      <td>6.92e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty    N        M       dt  niter  pmean_pct  pstd_pct   unclpM   exchpM   stabpM   pairpM      dvM  cond_num\n",
       "0        base  500  5000000 3.08e+00     32   9.95e+01  2.04e+00 9.20e-05 7.63e-01 0.00e+00 1.47e+05 8.64e+01  7.50e+08\n",
       "1        base  500  2829148 1.92e+00     33   9.94e+01  2.31e+00 5.54e-06 8.68e-01 0.00e+00 1.46e+05 8.68e+01  1.17e+08\n",
       "2        base  500  1600816 1.29e+00     32   9.92e+01  4.37e+00 5.19e-05 1.23e+00 0.00e+00 1.47e+05 8.63e+01  1.96e+09\n",
       "3        base  500   905789 6.56e-01     31   9.94e+01  5.98e+00 7.10e-07 1.56e+00 0.00e+00 1.45e+05 8.66e+01  1.29e+09\n",
       "4        base  500   512522 7.21e-01     33   9.97e+01  6.98e+00 7.08e-08 1.86e+00 0.00e+00 1.47e+05 8.62e+01  4.24e+08\n",
       "5        base  500   290000 4.05e-01     31   9.97e+01  8.63e+00 1.33e-04 2.28e+00 0.00e+00 1.46e+05 8.67e+01  3.22e+11\n",
       "6        base  500   164090 3.20e-01     29   9.89e+01  8.28e+00 4.32e-07 2.76e+00 0.00e+00 1.48e+05 8.52e+01  4.17e+09\n",
       "7        base  500    92847 3.67e-01     34   9.97e+01  1.26e+01 4.73e-06 3.57e+00 0.00e+00 1.45e+05 8.67e+01  4.20e+09\n",
       "8        base  500    52535 3.39e-01     31   9.96e+01  1.63e+01 3.30e-06 4.63e+00 0.00e+00 1.46e+05 8.55e+01  2.71e+10\n",
       "9        base  500    29726 3.40e-01     30   1.00e+02  4.08e+01 2.12e-05 9.51e+00 0.00e+00 1.60e+05 8.18e+01  1.79e+10\n",
       "10       base  500    16820 3.44e-01     29   9.97e+01  1.03e+02 1.63e-06 2.18e+01 0.00e+00 1.48e+05 8.21e+01  2.41e+10\n",
       "11       base  500     9517 6.26e-01     29   1.02e+02  1.99e+02 3.26e-06 3.58e+01 0.00e+00 1.58e+05 8.48e+01  1.77e+10\n",
       "12       base  500     5385 6.52e-01     28   1.00e+02  2.89e+02 4.47e-06 7.32e+01 0.00e+00 1.68e+05 7.39e+01  8.59e+10\n",
       "13       base  500     3047 3.65e-01     29   9.52e+01  2.61e+02 5.88e-06 7.59e+01 0.00e+00 1.30e+05 7.55e+01  6.33e+10\n",
       "14       base  500     1724 3.10e-01     28   1.05e+02  2.79e+02 5.73e-06 7.38e+01 0.00e+00 1.15e+05 8.57e+01  1.71e+11\n",
       "15       base  500      975 3.15e-01     29   9.75e+01  9.80e+01 5.96e-05 6.08e+01 0.00e+00 1.70e+05 4.35e+01  9.16e+11\n",
       "16       base  500      552 3.04e-01     29   9.74e+01  2.63e+02 7.91e-06 8.01e+01 0.00e+00 5.44e+04 9.64e+01  3.41e+11\n",
       "17       base  500      312 3.08e-01     29   1.03e+02  4.82e+02 1.30e-05 2.09e+02 0.00e+00 2.05e+05 6.99e+01  2.77e+11\n",
       "18       base  500      176 3.37e-01     28   9.20e+01  1.33e+02 9.39e-05 9.75e+01 0.00e+00 5.72e+04 4.91e+01  4.54e+12\n",
       "19       base  500      100 3.11e-01     27   1.09e+02  8.99e+01 5.71e-05 6.96e+01 0.00e+00 1.27e+04 4.27e+01  6.92e+11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftimer =  0.02024102210998535  sec\n"
     ]
    }
   ],
   "source": [
    "@ftimer()\n",
    "def make_table4m(sim):\n",
    "\n",
    "    #vns_drop = ['ch_few', 'ch_many', 'ch_vn0', 'ch_value0']\n",
    "    \n",
    "    #vns_sort = ['difficulty', 'M']\n",
    "\n",
    "    #dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl4M\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    \n",
    "    dfg = sim.df_sim\n",
    "\n",
    "    #column names for sim.df_sim:\n",
    "    #dt, niter, bmaxiter, bchofail, num_cholesky_regularizations, rxnorm, rynorm, rznorm, nubar, pmean_pct, pstd_pct, \n",
    "    #n_bad_p, num_exch_full, num_stab_full, num_stab_active, cond_num, nseed, i, difficulty, \n",
    "    #ch_few, ch_many, num_changes, ch_vn0, ch_value0, ch_vn1, ch_value1, \n",
    "    #norm, unclpM, exchpM, stabpM, pairpM, dvM, dollar_volume, exchange_dollar_volume, single_asset_dollar_volume, \n",
    "    #pairs_trade_dollar_volume, uncleared_dollar_volume, uncleared_share, exchange_share, stabilizing_share, \n",
    "    #single_asset_share, pairs_trade_share, net_dollar_volume_vec, N, M, exch_liq_model, \n",
    "    #exch_epsilon, exch_phpl_frac, stab_max_qv, stab_ph_frac, stab_pl_frac, fracMA, subfracMX, num_size_indexes, \n",
    "    #num_industry_indexes, market_index_share, size_index_subshare, ew_mkt_index_subshare, \n",
    "    #ew_size_index_subsubshare, ew_industry_index_subsubshare, ew_size_index_alpha, \n",
    "    #std_num_orders_asset, std_order_size, dv_single_asset_orders, std_limit_price, limit_bias, \n",
    "    #avg_ph_minus_pl_bp, std_ph_minus_pl, index_prices, mean_asset_price, std_asset_price, invariance_exponent, \n",
    "    #fraction_buy_orders_asset, fracMX, fracM2, MX, M2, MA, M0, M0s, M1, Mall, NX, NR, ew_mkt_index_share, \n",
    "    #vw_mkt_index_share, industry_index_subshare, ew_size_index_share, vw_size_index_share, \n",
    "    #ew_industry_index_share, vw_industry_index_share, \n",
    "    #maxiter, dtype, device, xtol, ytol, ztol, stol, eta, sigma_exponent, sigma_fac, afac, gamma, one_fac, \n",
    "    #max_alpha, alpha_fac, alpha_trunc_factor, regeps0, regeps2, regepsfactor, \n",
    "    #print_time, print_iteration_results, print_mkt_results, \n",
    "    \n",
    "    vns = ['difficulty', 'N', 'M', 'dt', 'niter', 'pmean_pct', 'pstd_pct', \n",
    "           'unclpM', 'exchpM', 'stabpM', 'pairpM', 'dvM', 'cond_num']\n",
    "    \n",
    "    display(dfg[vns])\n",
    "\n",
    "    \n",
    "    return dfg\n",
    "\n",
    "dfg4m = make_table4m(sim4m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "#matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['Palatino']})  #tex file: \\usepackage{mathpazo}.\n",
    "matplotlib.rc('font',**{'family':'serif','serif':['Times']}) #tex file: \\usepackage{mathptmx}\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['fourier']}) #Does not work since fourier not allowed. Computer modern.\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['Charter']})  #tex file: \\usepackage{charter}.\n",
    "plt.rcParams['font.size'] = 12  # match base font in tex file\n",
    "#matplotlib.rc('axes.titlesize', 'large')\n",
    "plt.rcParams['axes.titlesize'] = 'medium'\n",
    "#plt.rcParams['axes.labelsize'] = 10\n",
    "matplotlib.rc('text', usetex=True)  #comment out to not use latex fonts\n",
    "\n",
    "#matplotlib.rcParams.keys()  #list of settings which can be changed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def plot_simulation_results_for_assets_and_orders(dfn, dfm): \n",
    "    \n",
    "    #fig1 = plt.figure(figsize=(8.0, 6.0))\n",
    "    fig1 = plt.figure(figsize=(5.5, 3.5))\n",
    "    (ax1, ax2) = fig1.subplots(1,2)\n",
    "\n",
    "    fig1.suptitle(\"Computation Times (sec)\")\n",
    "    \n",
    "    ylim =  (0.05, 120.00) if RUN_TYPE=='workstation' else (0.20, 200.00) if RUN_TYPE=='laptop' else (0.05, 200.0)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of orders\")\n",
    "    #ax1.set_xlabel(\"Number of assets $N$\\n$M=$\" + str(int(dfn.loc[0, 'M'])) + \" orders assumed\")\n",
    "    #ax1.set_ylabel('(sec)')\n",
    "\n",
    "    ax1.scatter(dfm['M'], dfm['dt'], c='b', s = 5.00)\n",
    "\n",
    "    #ax1.legend(loc='best')\n",
    "    #ax1.set_xscale('linear')\n",
    "    \n",
    "    ax1.set_xticks([10**i for i in [1, 2, 3, 4, 5, 6, 7]])\n",
    "    ax1.set_yticks([10**i for i in [-1, 0, 1]])\n",
    "    \n",
    "    ax1.set(ylim = ylim)\n",
    "    \n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "\n",
    "    #ax1.xaxis.set_major_locator(plt.LogLocator(base=10, numticks=3))    \n",
    "\n",
    "    ax1.grid(visible=True, color='gray', linestyle='dashed', which='major')\n",
    "    #ax1.grid(visible=True, color='gray', linestyle='dashed', which='both')\n",
    "    #ax1.grid(b=True, which='minor', color='orange', linestyle=':')    \n",
    "    \n",
    "    #ax2.set_title(\"Number of iterations\")\n",
    "    ax2.set_xlabel(\"Number of assets\")\n",
    "    #ax2.set_ylabel(\"(sec)\")\n",
    "    #ax2.scatter(dfm['MA'] + dfm['MX'] + dfm['M2'], dfm['dt'], c = 'b', s = 5.00)\n",
    "    ax2.scatter(dfn['N'], dfn['dt'], c = 'b', s = 5.00)\n",
    "    \n",
    "    ax2.set_xticks([10**i for i in [1, 2, 3, 4, 5, 6]])\n",
    "    ax2.set_yticks([10**i for i in [-1, 0, 1]])\n",
    "    \n",
    "    ax2.set(ylim=ylim)\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    \n",
    "    ax2.grid(visible=True, color='gray', linestyle='dashed', which='major')\n",
    "    #ax2.grid(visible=True, color='gray', linestyle='dashed', which='both')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    if B_SAVE_RESULTS == True:\n",
    "        #path = \"C:/Users/akyle/ask/code/flow-trading-figures/\"\n",
    "        ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "        fp = LATEX_PATH + \"dt_vs_n_m_\" + ts + \"_\" + RUN_TYPE + \".pdf\"\n",
    "        fig1.savefig(fp)\n",
    "        print(\"Figure saved to \", fp)\n",
    "        \n",
    "\n",
    "\n",
    "plot_simulation_results_for_assets_and_orders(dfg4n, dfg4m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "#matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['Palatino']})  #tex file: \\usepackage{mathpazo}.\n",
    "matplotlib.rc('font',**{'family':'serif','serif':['Times']}) #tex file: \\usepackage{mathptmx}\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['fourier']}) #Does not work since fourier not allowed. Computer modern.\n",
    "#matplotlib.rc('font',**{'family':'serif','serif':['Charter']})  #tex file: \\usepackage{charter}.\n",
    "plt.rcParams['font.size'] = 12  # match base font in tex file\n",
    "#matplotlib.rc('axes.titlesize', 'large')\n",
    "plt.rcParams['axes.titlesize'] = 'medium'\n",
    "plt.rcParams['axes.labelsize'] = 13\n",
    "matplotlib.rc('text', usetex=True)  #comment out to not use latex fonts\n",
    "\n",
    "#matplotlib.rcParams.keys()  #list of settings which can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nthreads =  2 , user_api =  blas\n",
      "ftimer =  0.11966180801391602  sec\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:250\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    467\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 74\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigure saved to \u001b[39m\u001b[38;5;124m\"\u001b[39m, fp)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#    dfN_saved = pd.read_csv(\"C:/Users/akyle/Downloads/sim4N_DMworkstation_2022-0126-0202.csv\")\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#    dfM_saved = pd.read_csv(\"C:/Users/akyle/Downloads/sim4M_DMworkstation_2022-0126-0212.csv\")\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#    plot_simulation_results_for_assets_and_orders(dfN_saved, dfM_saved)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#except:\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#    pass\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m plot_simulation_results_for_assets_and_orders(dfg4n, dfg4m)\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mFtimer.__call__.<locals>.factory.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mfthrds.<locals>.factory.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_limits(limits\u001b[38;5;241m=\u001b[39mnthreads, user_api\u001b[38;5;241m=\u001b[39muser_api): \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m bprint \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[65], line 55\u001b[0m, in \u001b[0;36mplot_simulation_results_for_assets_and_orders\u001b[1;34m(dfn, dfm)\u001b[0m\n\u001b[0;32m     52\u001b[0m ax2\u001b[38;5;241m.\u001b[39mgrid(visible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m, which\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#ax2.grid(visible=True, color='gray', linestyle='dashed', which='both')\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     57\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     59\u001b[0m B_SAVE_RESULTS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\pyplot.py:2587\u001b[0m, in \u001b[0;36mtight_layout\u001b[1;34m(pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39mtight_layout)\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtight_layout\u001b[39m(\n\u001b[0;32m   2581\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2585\u001b[0m     rect: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2586\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2587\u001b[0m     gcf()\u001b[38;5;241m.\u001b[39mtight_layout(pad\u001b[38;5;241m=\u001b[39mpad, h_pad\u001b[38;5;241m=\u001b[39mh_pad, w_pad\u001b[38;5;241m=\u001b[39mw_pad, rect\u001b[38;5;241m=\u001b[39mrect)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\figure.py:3540\u001b[0m, in \u001b[0;36mFigure.tight_layout\u001b[1;34m(self, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m   3538\u001b[0m previous_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_layout_engine()\n\u001b[0;32m   3539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_layout_engine(engine)\n\u001b[1;32m-> 3540\u001b[0m engine\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   3542\u001b[0m     previous_engine, (TightLayoutEngine, PlaceHolderLayoutEngine)\n\u001b[0;32m   3543\u001b[0m ):\n\u001b[0;32m   3544\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe figure layout has changed to tight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\layout_engine.py:183\u001b[0m, in \u001b[0;36mTightLayoutEngine.execute\u001b[1;34m(self, fig)\u001b[0m\n\u001b[0;32m    181\u001b[0m renderer \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m--> 183\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m get_tight_layout_figure(\n\u001b[0;32m    184\u001b[0m         fig, fig\u001b[38;5;241m.\u001b[39maxes, get_subplotspec_list(fig\u001b[38;5;241m.\u001b[39maxes), renderer,\n\u001b[0;32m    185\u001b[0m         pad\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m], h_pad\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh_pad\u001b[39m\u001b[38;5;124m'\u001b[39m], w_pad\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw_pad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    186\u001b[0m         rect\u001b[38;5;241m=\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrect\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    188\u001b[0m     fig\u001b[38;5;241m.\u001b[39msubplots_adjust(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\_tight_layout.py:266\u001b[0m, in \u001b[0;36mget_tight_layout_figure\u001b[1;34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m    262\u001b[0m     span_pairs\u001b[38;5;241m.\u001b[39mappend((\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mslice\u001b[39m(ss\u001b[38;5;241m.\u001b[39mrowspan\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m*\u001b[39m div_row, ss\u001b[38;5;241m.\u001b[39mrowspan\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m*\u001b[39m div_row),\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28mslice\u001b[39m(ss\u001b[38;5;241m.\u001b[39mcolspan\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m*\u001b[39m div_col, ss\u001b[38;5;241m.\u001b[39mcolspan\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m*\u001b[39m div_col)))\n\u001b[1;32m--> 266\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _auto_adjust_subplotpars(fig, renderer,\n\u001b[0;32m    267\u001b[0m                                   shape\u001b[38;5;241m=\u001b[39m(max_nrows, max_ncols),\n\u001b[0;32m    268\u001b[0m                                   span_pairs\u001b[38;5;241m=\u001b[39mspan_pairs,\n\u001b[0;32m    269\u001b[0m                                   subplot_list\u001b[38;5;241m=\u001b[39msubplot_list,\n\u001b[0;32m    270\u001b[0m                                   ax_bbox_list\u001b[38;5;241m=\u001b[39max_bbox_list,\n\u001b[0;32m    271\u001b[0m                                   pad\u001b[38;5;241m=\u001b[39mpad, h_pad\u001b[38;5;241m=\u001b[39mh_pad, w_pad\u001b[38;5;241m=\u001b[39mw_pad)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# kwargs can be none if tight_layout fails...\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# if rect is given, the whole subplots area (including\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# labels) will fit into the rect instead of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# auto_adjust_subplotpars twice, where the second run\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# with adjusted rect parameters.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\_tight_layout.py:82\u001b[0m, in \u001b[0;36m_auto_adjust_subplotpars\u001b[1;34m(fig, renderer, shape, span_pairs, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m subplots:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m---> 82\u001b[0m         bb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [martist\u001b[38;5;241m.\u001b[39m_get_tightbbox_for_layout_only(ax, renderer)]\n\u001b[0;32m     84\u001b[0m tight_bbox_raw \u001b[38;5;241m=\u001b[39m Bbox\u001b[38;5;241m.\u001b[39munion(bb)\n\u001b[0;32m     85\u001b[0m tight_bbox \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mtransFigure\u001b[38;5;241m.\u001b[39minverted()\u001b[38;5;241m.\u001b[39mtransform_bbox(tight_bbox_raw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:1411\u001b[0m, in \u001b[0;36m_get_tightbbox_for_layout_only\u001b[1;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor_layout_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axes\\_base.py:4395\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   4394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;129;01mand\u001b[39;00m axis\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m-> 4395\u001b[0m         ba \u001b[38;5;241m=\u001b[39m martist\u001b[38;5;241m.\u001b[39m_get_tightbbox_for_layout_only(axis, renderer)\n\u001b[0;32m   4396\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ba:\n\u001b[0;32m   4397\u001b[0m             bb\u001b[38;5;241m.\u001b[39mappend(ba)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:1411\u001b[0m, in \u001b[0;36m_get_tightbbox_for_layout_only\u001b[1;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor_layout_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1336\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m   1334\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:2368\u001b[0m, in \u001b[0;36mXAxis._update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m \u001b[38;5;66;03m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[0;32m   2367\u001b[0m \u001b[38;5;66;03m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[1;32m-> 2368\u001b[0m bboxes, bboxes2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tick_boxes_siblings(renderer\u001b[38;5;241m=\u001b[39mrenderer)\n\u001b[0;32m   2370\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mget_position()\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_position \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:2161\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2159\u001b[0m axis \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_axis_map[name]\n\u001b[0;32m   2160\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 2161\u001b[0m tlb, tlb2 \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   2162\u001b[0m bboxes\u001b[38;5;241m.\u001b[39mextend(tlb)\n\u001b[0;32m   2163\u001b[0m bboxes2\u001b[38;5;241m.\u001b[39mextend(tlb2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:373\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    370\u001b[0m ys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m _, lp_h, lp_d \u001b[38;5;241m=\u001b[39m _get_text_metrics_with_cache(\n\u001b[0;32m    374\u001b[0m     renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fontproperties,\n\u001b[0;32m    375\u001b[0m     ismath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_usetex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m    376\u001b[0m min_dy \u001b[38;5;241m=\u001b[39m (lp_h \u001b[38;5;241m-\u001b[39m lp_d) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_text_metrics_with_cache_impl(\n\u001b[0;32m     70\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mref(renderer), text, fontprop\u001b[38;5;241m.\u001b[39mcopy(), ismath, dpi)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m renderer_ref()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(text, fontprop, ismath)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:213\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    211\u001b[0m _api\u001b[38;5;241m.\u001b[39mcheck_in_list([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m], ismath\u001b[38;5;241m=\u001b[39mismath)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(s, prop, ismath)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n\u001b[0;32m    216\u001b[0m     ox, oy, width, height, descent, font_image \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmathtext_parser\u001b[38;5;241m.\u001b[39mparse(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpi, prop)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backend_bases.py:652\u001b[0m, in \u001b[0;36mRendererBase.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    648\u001b[0m fontsize \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mget_size_in_points()\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;66;03m# todo: handle properties\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_texmanager()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(\n\u001b[0;32m    653\u001b[0m         s, fontsize, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    655\u001b[0m dpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m72\u001b[39m)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:363\u001b[0m, in \u001b[0;36mTexManager.get_text_width_height_descent\u001b[1;34m(cls, tex, fontsize, renderer)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tex\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 363\u001b[0m dvifile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dvi(tex, fontsize)\n\u001b[0;32m    364\u001b[0m dpi_fraction \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m1.\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dviread\u001b[38;5;241m.\u001b[39mDvi(dvifile, \u001b[38;5;241m72\u001b[39m \u001b[38;5;241m*\u001b[39m dpi_fraction) \u001b[38;5;28;01mas\u001b[39;00m dvi:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:295\u001b[0m, in \u001b[0;36mTexManager.make_dvi\u001b[1;34m(cls, tex, fontsize)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDirectory(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcwd) \u001b[38;5;28;01mas\u001b[39;00m tmpdir:\n\u001b[0;32m    294\u001b[0m         tmppath \u001b[38;5;241m=\u001b[39m Path(tmpdir)\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_checked_subprocess(\n\u001b[0;32m    296\u001b[0m             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-interaction=nonstopmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--halt-on-error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    297\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--output-directory=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmppath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    298\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtexfile\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], tex, cwd\u001b[38;5;241m=\u001b[39mcwd)\n\u001b[0;32m    299\u001b[0m         (tmppath \u001b[38;5;241m/\u001b[39m Path(dvifile)\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mreplace(dvifile)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dvifile\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:254\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to process string with tex because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not be found\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m was not able to process the following string:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{tex!r}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m             exc\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackslashreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    268\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x000001DDE6AE9F80> (for post_execute):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:250\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    467\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\pyplot.py:197\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[1;32m--> 197\u001b[0m         draw_all()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[1;34m(cls, force)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[1;32m--> 132\u001b[0m         manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backend_bases.py:1893\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[1;32m-> 1893\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer)\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3071\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1388\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m   1387\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1391\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:373\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    370\u001b[0m ys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m _, lp_h, lp_d \u001b[38;5;241m=\u001b[39m _get_text_metrics_with_cache(\n\u001b[0;32m    374\u001b[0m     renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fontproperties,\n\u001b[0;32m    375\u001b[0m     ismath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_usetex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m    376\u001b[0m min_dy \u001b[38;5;241m=\u001b[39m (lp_h \u001b[38;5;241m-\u001b[39m lp_d) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_text_metrics_with_cache_impl(\n\u001b[0;32m     70\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mref(renderer), text, fontprop\u001b[38;5;241m.\u001b[39mcopy(), ismath, dpi)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m renderer_ref()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(text, fontprop, ismath)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:213\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    211\u001b[0m _api\u001b[38;5;241m.\u001b[39mcheck_in_list([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m], ismath\u001b[38;5;241m=\u001b[39mismath)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(s, prop, ismath)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n\u001b[0;32m    216\u001b[0m     ox, oy, width, height, descent, font_image \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmathtext_parser\u001b[38;5;241m.\u001b[39mparse(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpi, prop)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backend_bases.py:652\u001b[0m, in \u001b[0;36mRendererBase.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    648\u001b[0m fontsize \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mget_size_in_points()\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;66;03m# todo: handle properties\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_texmanager()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(\n\u001b[0;32m    653\u001b[0m         s, fontsize, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    655\u001b[0m dpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m72\u001b[39m)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:363\u001b[0m, in \u001b[0;36mTexManager.get_text_width_height_descent\u001b[1;34m(cls, tex, fontsize, renderer)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tex\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 363\u001b[0m dvifile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dvi(tex, fontsize)\n\u001b[0;32m    364\u001b[0m dpi_fraction \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m1.\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dviread\u001b[38;5;241m.\u001b[39mDvi(dvifile, \u001b[38;5;241m72\u001b[39m \u001b[38;5;241m*\u001b[39m dpi_fraction) \u001b[38;5;28;01mas\u001b[39;00m dvi:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:295\u001b[0m, in \u001b[0;36mTexManager.make_dvi\u001b[1;34m(cls, tex, fontsize)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDirectory(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcwd) \u001b[38;5;28;01mas\u001b[39;00m tmpdir:\n\u001b[0;32m    294\u001b[0m         tmppath \u001b[38;5;241m=\u001b[39m Path(tmpdir)\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_checked_subprocess(\n\u001b[0;32m    296\u001b[0m             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-interaction=nonstopmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--halt-on-error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    297\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--output-directory=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmppath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    298\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtexfile\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], tex, cwd\u001b[38;5;241m=\u001b[39mcwd)\n\u001b[0;32m    299\u001b[0m         (tmppath \u001b[38;5;241m/\u001b[39m Path(dvifile)\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mreplace(dvifile)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dvifile\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:254\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to process string with tex because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not be found\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m was not able to process the following string:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{tex!r}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m             exc\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackslashreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    268\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:250\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    467\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backend_bases.py:2158\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2156\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3071\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1388\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m   1387\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1391\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:373\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    370\u001b[0m ys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m _, lp_h, lp_d \u001b[38;5;241m=\u001b[39m _get_text_metrics_with_cache(\n\u001b[0;32m    374\u001b[0m     renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fontproperties,\n\u001b[0;32m    375\u001b[0m     ismath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_usetex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m    376\u001b[0m min_dy \u001b[38;5;241m=\u001b[39m (lp_h \u001b[38;5;241m-\u001b[39m lp_d) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_text_metrics_with_cache_impl(\n\u001b[0;32m     70\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mref(renderer), text, fontprop\u001b[38;5;241m.\u001b[39mcopy(), ismath, dpi)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m renderer_ref()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(text, fontprop, ismath)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:213\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    211\u001b[0m _api\u001b[38;5;241m.\u001b[39mcheck_in_list([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m], ismath\u001b[38;5;241m=\u001b[39mismath)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(s, prop, ismath)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n\u001b[0;32m    216\u001b[0m     ox, oy, width, height, descent, font_image \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmathtext_parser\u001b[38;5;241m.\u001b[39mparse(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpi, prop)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\backend_bases.py:652\u001b[0m, in \u001b[0;36mRendererBase.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    648\u001b[0m fontsize \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mget_size_in_points()\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeX\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;66;03m# todo: handle properties\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_texmanager()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(\n\u001b[0;32m    653\u001b[0m         s, fontsize, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    655\u001b[0m dpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m72\u001b[39m)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismath:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:363\u001b[0m, in \u001b[0;36mTexManager.get_text_width_height_descent\u001b[1;34m(cls, tex, fontsize, renderer)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tex\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 363\u001b[0m dvifile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dvi(tex, fontsize)\n\u001b[0;32m    364\u001b[0m dpi_fraction \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m1.\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dviread\u001b[38;5;241m.\u001b[39mDvi(dvifile, \u001b[38;5;241m72\u001b[39m \u001b[38;5;241m*\u001b[39m dpi_fraction) \u001b[38;5;28;01mas\u001b[39;00m dvi:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:295\u001b[0m, in \u001b[0;36mTexManager.make_dvi\u001b[1;34m(cls, tex, fontsize)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDirectory(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcwd) \u001b[38;5;28;01mas\u001b[39;00m tmpdir:\n\u001b[0;32m    294\u001b[0m         tmppath \u001b[38;5;241m=\u001b[39m Path(tmpdir)\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_checked_subprocess(\n\u001b[0;32m    296\u001b[0m             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-interaction=nonstopmode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--halt-on-error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    297\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--output-directory=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmppath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    298\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtexfile\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], tex, cwd\u001b[38;5;241m=\u001b[39mcwd)\n\u001b[0;32m    299\u001b[0m         (tmppath \u001b[38;5;241m/\u001b[39m Path(dvifile)\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mreplace(dvifile)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dvifile\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_env_name\\Lib\\site-packages\\matplotlib\\texmanager.py:254\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[1;34m(cls, command, tex, cwd)\u001b[0m\n\u001b[0;32m    250\u001b[0m     report \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    251\u001b[0m         command, cwd\u001b[38;5;241m=\u001b[39mcwd \u001b[38;5;28;01mif\u001b[39;00m cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_texcache,\n\u001b[0;32m    252\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to process string with tex because \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not be found\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m was not able to process the following string:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{tex!r}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m             exc\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackslashreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    268\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@ftimer()\n",
    "@fthrds()\n",
    "def plot_simulation_results_for_assets_and_orders(dfn, dfm): \n",
    "    \n",
    "    #fig1 = plt.figure(figsize=(8.0, 6.0))\n",
    "    fig1 = plt.figure(figsize=(7.0, 3.5))\n",
    "    (ax1, ax2) = fig1.subplots(1,2)\n",
    "    #(ax1, ax2) = fig1.subplots(2,1)\n",
    "\n",
    "    #fig1.suptitle(\"Computation Times (sec)\")\n",
    "    #fig1.suptitle(\"Computation Times (sec)\")\n",
    "    \n",
    "    ylim =  (0.02, 120.00) if RUN_TYPE=='workstation' else (0.02, 200.00) if RUN_TYPE=='laptop' else (0.01, 200.0)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of orders \\n (Number of assets = 500)\")\n",
    "    #ax1.set_xlabel(\"Number of assets $N$\\n$M=$\" + str(int(dfn.loc[0, 'M'])) + \" orders assumed\")\n",
    "    ax1.set_ylabel(\"Computation time (sec)\")\n",
    "\n",
    "    ax1.scatter(dfm['M'], dfm['dt'], c='b', s = 5.00)\n",
    "\n",
    "    #ax1.legend(loc='best')\n",
    "    #ax1.set_xscale('linear')\n",
    "    \n",
    "    ax1.set_xticks([10**i for i in [1, 2, 3, 4, 5, 6, 7]])\n",
    "    ax1.set_yticks([10**i for i in [-1, 0, 1]])\n",
    "    \n",
    "    ax1.set(ylim = ylim)\n",
    "    ax1.set(xlim = (2000, 1.2 * 10**7))\n",
    "    \n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "\n",
    "    #ax1.xaxis.set_major_locator(plt.LogLocator(base=10, numticks=3))    \n",
    "\n",
    "    ax1.grid(visible=True, color='gray', linestyle='dashed', which='major')\n",
    "    #ax1.grid(visible=True, color='gray', linestyle='dashed', which='both')\n",
    "    #ax1.grid(b=True, which='minor', color='orange', linestyle=':')    \n",
    "    \n",
    "    #ax2.set_title(\"Number of iterations\")\n",
    "    ax2.set_xlabel(\"Number of assets\\n(Number of orders = 100,000)\")\n",
    "    ax2.set_ylabel(\"Computation time (sec)\")\n",
    "    #ax2.scatter(dfm['MA'] + dfm['MX'] + dfm['M2'], dfm['dt'], c = 'b', s = 5.00)\n",
    "    ax2.scatter(dfn['N'], dfn['dt'], c = 'b', s = 5.00)\n",
    "    \n",
    "    ax2.set_xticks([10**i for i in [1, 2, 3, 4, 5, 6]])\n",
    "    ax2.set_yticks([10**i for i in [-1, 0, 1]])\n",
    "    \n",
    "    ax2.set(ylim=ylim)\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    \n",
    "    ax2.grid(visible=True, color='gray', linestyle='dashed', which='major')\n",
    "    #ax2.grid(visible=True, color='gray', linestyle='dashed', which='both')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    B_SAVE_RESULTS = True\n",
    "    if B_SAVE_RESULTS == True:\n",
    "        #path = \"C:/Users/akyle/ask/code/flow-trading-figures/\"\n",
    "        ts = datetime.datetime.now().strftime('%Y-%m%d-%H%M')\n",
    "        fp = LATEX_PATH + \"dt_vs_n_m_\" + ts + \"_\" + RUN_TYPE + \".pdf\"\n",
    "        fig1.savefig(fp)\n",
    "        print(\"Figure saved to \", fp)\n",
    "        \n",
    "#try:\n",
    "#    dfN_saved = pd.read_csv(\"C:/Users/akyle/Downloads/sim4N_DMworkstation_2022-0126-0202.csv\")\n",
    "#    dfM_saved = pd.read_csv(\"C:/Users/akyle/Downloads/sim4M_DMworkstation_2022-0126-0212.csv\")\n",
    "#    plot_simulation_results_for_assets_and_orders(dfN_saved, dfM_saved)\n",
    "#except:\n",
    "#    pass\n",
    "\n",
    "plot_simulation_results_for_assets_and_orders(dfg4n, dfg4m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = 100.00\n",
    "ph_minus_pl = 1.00e-2\n",
    "p = ph - 0.50 * ph_minus_pl\n",
    "q = 1.00\n",
    "x = q * (ph - p) / ph_minus_pl\n",
    "\n",
    "print(\"The following numbers are theoretically all equal to 0.50, but rounding error makes them inaccurate for small phminuspl:\")\n",
    "for ph_minus_pl in [10.00**(-n) for n in range(-1, 16, 1)]:\n",
    "    print(ph_minus_pl, (ph - (ph - 0.50 * ph_minus_pl))  / ph_minus_pl)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 5: robustness to the other parameters \n",
    "\n",
    "1. 500 assets and 100,000 orders (no stabilizing order) (PK: \"No stabilizing orders\" is implemented by having a very small q = 1.00e-99 for stabilizing orders.) \n",
    "2. Start with the baseline parameters and change one at a time + changing everything (in the table, please include the baseline)  (PK: Baseline is called 'none')\n",
    "3. Also check why the standard deviation of limit prices became suddenly important: possibly due to stabilizing order (PK: Fixed a typo in the definition of the stabilizing orders.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate5b():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim5b\")\n",
    "\n",
    "    nreps = 101 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 2\n",
    "    \n",
    "    difficulty = (['base'] if RUN_TYPE == 'workstation' \n",
    "                  else ['base'] if RUN_TYPE == 'laptop' else ['base'])\n",
    "\n",
    "    #sim.dvd_change_few['ch2'] = [{'exch_epsilon' : eps, 'exch_phpl_frac' : 1.00} for eps in [\n",
    "    #    1.0e-99, 1.00e-12, 1.00e-8, 1.00e-6, 1.00e-4, 1.00e-0, 1.00e4, 1.00e8]]\n",
    "\n",
    "    change_few = ['none']\n",
    "\n",
    "    change_many = ['none', 'high1by1', 'low1by1']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim5b = simulate5b()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def make_table5b(sim):\n",
    "\n",
    "    vns_drop = ['ch_few']\n",
    "    \n",
    "    vns_sort = ['difficulty', 'dt_med']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl5b\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg5b = make_table5b(sim5b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next table uses the hard case, adds stabilizing orders of 20X volume, changes parameters to 'low1by1' one by one, includes no parameter changes as 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate5h():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim5h\")\n",
    "\n",
    "    nreps = 51 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "    \n",
    "    difficulty = (['high'] if RUN_TYPE == 'workstation' \n",
    "                  else ['high'] if RUN_TYPE == 'laptop' else ['high'])\n",
    "\n",
    "    #sim.dvd_change_few['ch2'] = [{'stab_max_qv' : 20.00}]\n",
    "\n",
    "    change_few = ['none']\n",
    "\n",
    "    change_many = ['none', 'low1by1']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim5h = simulate5h()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "def make_table5h(sim):\n",
    "\n",
    "    vns_drop = ['ch_few']\n",
    "    \n",
    "    vns_sort = ['difficulty', 'dt_med']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl5h\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg5h = make_table5h(sim5h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate5e():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim5e\")\n",
    "\n",
    "    nreps = 51 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "\n",
    "    difficulty = (['low'] if RUN_TYPE == 'workstation' \n",
    "                  else ['low'] if RUN_TYPE == 'laptop' else ['low'])\n",
    "\n",
    "    #sim.dvd_change_few['ch2'] = [{'stab_max_qv' : 20.00}]\n",
    "\n",
    "    change_few = ['none']\n",
    "\n",
    "    #sim.dvd_change_many['test_many'] = [{'exch_max_qv' : 100.00}, {'fracMA' : 0.99}]\n",
    "\n",
    "    change_many = ['none', 'high1by1']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim5e = simulate5e()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "def make_table5e(sim):\n",
    "\n",
    "    vns_drop = ['ch_few']\n",
    "    \n",
    "    vns_sort = ['difficulty', 'dt_med']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl5e\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg5e = make_table5e(sim5e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate5hard():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim5hard\")\n",
    "\n",
    "    nreps = 101 if RUN_TYPE == 'workstation' else 21 if RUN_TYPE == 'laptop' else 3\n",
    "    \n",
    "    difficulty = (['hard'] if RUN_TYPE == 'workstation' \n",
    "                  else ['hard'] if RUN_TYPE == 'laptop' else ['hard'])\n",
    "\n",
    "    #sim.dvd_change_few['ch2'] = [{'stab_max_qv' : 20.00}]\n",
    "\n",
    "    change_few = ['none']\n",
    "\n",
    "    change_many = ['none', 'base1by1']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim5hard = simulate5hard()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "def make_table5hard(sim):\n",
    "\n",
    "    vns_drop = ['ch_few']\n",
    "    \n",
    "    vns_sort = ['difficulty', 'dt_med']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl5hard\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg5hard = make_table5hard(sim5hard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "def make_table5all(sim):\n",
    "\n",
    "    vns_drop = ['ch_few']\n",
    "    \n",
    "    #vns_sort = ['difficulty', 'niter', 'dt']\n",
    "    vns_sort = ['niter', 'dt_med']\n",
    "    \n",
    "    dfg = pd.concat([dfg5b, dfg5h, dfg5e, dfg5hard])\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=dfg, tbl_name=\"tbl5all\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "# Does not matter which sim is argument of function since dfg is specified in function:\n",
    "dfg5all = make_table5all(sim5b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assumptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result 6: Inaccurate market clearing when $p_H - p_L$ is small \n",
    "\n",
    "Use baseline parameter except change $avg_ph_minus_pl_bp$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def simulate6():\n",
    "    \n",
    "    sim = Simulations(name_prefix=\"sim6\")\n",
    "\n",
    "    nreps = 101 if RUN_TYPE == 'workstation' else 51 if RUN_TYPE == 'laptop' else 11\n",
    "    \n",
    "    difficulty = (['base'] if RUN_TYPE == 'workstation' \n",
    "                  else ['base'] if RUN_TYPE == 'laptop' else ['base'])\n",
    "\n",
    "    sim.dvd_change_few['phpl'] = [{'avg_ph_minus_pl_bp' : 10.00**n} for n in range(2, -6, -1)]\n",
    "\n",
    "    change_few = ['phpl']\n",
    "\n",
    "    #change_many = ['none', 'high1by1', 'low1by1']\n",
    "    change_many = ['none']\n",
    "\n",
    "    sim(nreps=nreps, difficulty=difficulty, change_few=change_few, change_many=change_many, nseed0=NSEED0,\n",
    "            name_suffix=NAME_SUFFIX)\n",
    "\n",
    "    return sim\n",
    "\n",
    "sim6 = simulate6()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ftimer()\n",
    "@fthrds()\n",
    "def make_table6(sim):\n",
    "\n",
    "    #vns_drop = ['ch_few']\n",
    "    vns_drop = []\n",
    "    \n",
    "    vns_sort = ['ch_few']\n",
    "    \n",
    "    dfg = sim.display_and_save_table(dfg=None, tbl_name=\"tbl6\", vns_keep=None, vns_drop=vns_drop, vns_sort=vns_sort)\n",
    "\n",
    "    return dfg\n",
    "\n",
    "dfg6 = make_table6(sim6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telapsed = time.time() - tstart\n",
    "print(\"Execution time for entire notebook = \", telapsed, \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Forward Market Simulation \n",
    "### Details\n",
    "- 2021 only. \n",
    "- ERCOT only for net load, day ahead market prices, and load. \n",
    "- We only clear monthly products, for each load zone.\n",
    "\n",
    "### Modeling (v1)\n",
    "- Only ERCOT zone, so we use hub average prices\n",
    "- 3 agents, Load Serving Entities (LSEs) are buyers, and generators are sellers. Financial arbitrageurs are also included.\n",
    "- Get a forecast of net load (defined as load less wind and solar production) and day ahead prices for all load zones, for all periods. Using historical data, we add some white noise so that forecasts are not exact. \n",
    "- In v1, we only use 3 agents, each of different type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#PTH = '/Users/richardz/Desktop/Projects/energy_forward_market/data'\n",
    "PTH = 'C://Users//richa//Documents//energy_forward_market//data'\n",
    "LOAD_FILE = 'load_2021.xlsx'\n",
    "DAM_PRICES_FILE = 'dam_spp_2021.xlsx'\n",
    "RENEW_FILE = 'wind_solar_2021.xlsx'\n",
    "\n",
    "# get the historical load data for a specific zone\n",
    "def get_load(zone): \n",
    "\tpass\n",
    "\n",
    "# get the average price of all hubs in ERCOT\n",
    "def get_dam_prices(zone='HB_BUSAVG'): \n",
    "\tmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] \n",
    "\tdf = pd.DataFrame()\n",
    "\tfor month in months: \n",
    "\t\tdam_prices = pd.read_excel(os.path.join(PTH, DAM_PRICES_FILE), sheet_name=month)\n",
    "\t\tdam_prices = dam_prices[dam_prices['Settlement Point'] == zone]\n",
    "\t\tdf = pd.concat([df, dam_prices], axis=0)\n",
    "\t\t\n",
    "\treturn df\t\n",
    "\n",
    "# get the wind and solar data\n",
    "def get_wind_solar(): \n",
    "\twind_sheet = 'Wind Data'\n",
    "\tsolar_sheet = 'Solar Data'\n",
    "\twind_data = pd.read_excel(os.path.join(PTH, RENEW_FILE), sheet_name=wind_sheet)\n",
    "\tsolar_data = pd.read_excel(os.path.join(PTH, RENEW_FILE), sheet_name=solar_sheet)\n",
    "\treturn wind_data, solar_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_prices = get_dam_prices()\n",
    "dam_prices['Delivery Date'] = pd.to_datetime(dam_prices['Delivery Date'])\n",
    "wind, solar = get_wind_solar()\n",
    "wind.set_index('Date', inplace=True)\n",
    "solar.set_index('Date', inplace=True)\n",
    "net_load = wind[['ERCOT.LOAD', 'ERCOT.WIND.GEN']].join(solar[['ERCOT.PVGR.GEN']], on='Date', lsuffix='.wind', rsuffix='.solar')\n",
    "net_load['net_load'] = net_load['ERCOT.LOAD'] - net_load['ERCOT.WIND.GEN'] - net_load['ERCOT.PVGR.GEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling agent preferences\n",
    "We assume a \"template\" offer curve for each participant type, of which there are 3 distinct types (no hybrids). Each offer (demand) curve is parameterized by only scalar risk attitudes, and capital costs. Risk attitude and capital costs are related, and determine the slope and level of the offer curve. Additionally, each participant type differs in their general offering strategy. \n",
    "\n",
    "- Financial participants are agnostic between buying or selling, but require higher payment for taking larger positions. They aim to have a position of 0 target around their expected price. \n",
    "- Generators are natural sellers willing to sell slightly below their expected price, and can even buy if they have physical assets that allow them to do so (batteries, hydro)\n",
    "- LSE are natural buyers, who offer at a premium to the other participants compared to their expected price, due to the extreme volatility of electricity prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(dam_prices['Delivery Date'], dam_prices['Settlement Point Price'])\n",
    "plt.title('Bus Avg. Day Ahead Power Price in ERCOT 2021')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, each participant uses 4 flow orders, two for \"high\" absolute quantities and two for \"low\" absolute quantities. The notion of how high or low a quantity is determined by the \"size\" of the participant, and their risk attitude. \n",
    "\n",
    "Assumptions: \n",
    "- Each participant offers in a price range from $[0, 2*E(p)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Participant(): \n",
    "    # risk_attitude: is a scalar in [0,1]. 1 is for a perfectly risk neutral participant. ~.9 for small generators\n",
    "    # capital_costs: is a scalar in [.06, .12] that shifts the offer curve up or down. \n",
    "    def __init__(self, risk_attitude, capital_costs): \n",
    "        self.risk_attitude = risk_attitude\n",
    "        self.capital_costs = capital_costs \n",
    "\n",
    "    # get_offer_points :return a set of four tuples that indicate (price, quantity) pairs that we use to construct the flow orders\n",
    "    # this is based on the expected price that the participant anticipates from a forecast. \n",
    "    # the prices must be monotonically increasing\n",
    "    # expected_price: the anticipated price of power in $/MWh\n",
    "    # net_demand: the sum (demand - supply) for each participant. \n",
    "    def get_offer_points(self, expected_price, net_demand):\n",
    "        pass\n",
    "\n",
    "    # assume that offer points are a set of 4 tuples that specify (p_i, q_i) for price and quantity\n",
    "    # assume that offer points are already sorted in decreasing order of price, increasing order of quantity (left to right on graph)\n",
    "    # we only specify the p_H, p_L, q_i, q_i of the flow order\n",
    "    def get_flow_orders(self, offer_points): \n",
    "\n",
    "        flow_orders = [] \n",
    "        # skip first offer, we essentially specify between the curve\n",
    "        for i, p_i, q_i in enumerate(offer_points[1:]): \n",
    "            p_im1, q_im1 = offer_points[i-1]\n",
    "            flow_orders.append(())\n",
    "\n",
    "        return flow_orders\n",
    "\n",
    "class Seller(Participant): \n",
    "    \n",
    "    def get_offer_points(self, expected_price, net_demand): \n",
    "        pass\n",
    "\n",
    "class Buyer(Participant): \n",
    "    \n",
    "    def get_offer_points(self, expected_price, net_demand): \n",
    "        pass \n",
    "\n",
    "# The arbitrageur offers two points at the forecasted_net_load and -forecasted_net_load\n",
    "class Arbitrageur(Participant): \n",
    "    \n",
    "    def get_offer_points(self, expected_price, net_demand, forecasted_net_load): \n",
    "        discounted_expected_price = expected_price / (1 - self.capital_costs)\n",
    "\n",
    "        # we assume that an arbitrageur has a relatively high risk attitude close to 1.\n",
    "        # From their expected price, they are willing to buy large quantities far below expected prices, \n",
    "        # and sell large quantities far above expected prices\n",
    "        # for now, just assume that within 1.5 - 2 multiples of the expected price, the arbitrageur sells with slope 1 in price. \n",
    "        \n",
    "        p1 = 1.6 * discounted_expected_price\n",
    "        p2 = 1.1 * self.risk_attitude * discounted_expected_price\n",
    "        p3 = 0.9 * discounted_expected_price \n",
    "        p4 = 0.4 * self.risk_attitude * discounted_expected_price\n",
    "        q1 = -1.3 * forecasted_net_load * self.risk_attitude + net_demand \n",
    "        q2 = -1 * forecasted_net_load * self.risk_attitude + net_demand \n",
    "        q3 = 1 * forecasted_net_load * self.risk_attitude + net_demand\n",
    "        q4 = 1.3 * forecasted_net_load * self.risk_attitude + net_demand\n",
    "\n",
    "        return [(p1, q1), (p2, q2), (p3, q3), (p4, q4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(102.1276595744681, -78.0),\n",
       " (70.21276595744682, -60),\n",
       " (57.4468085106383, 60),\n",
       " (25.531914893617024, 78.0)]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arbitrageur(1, .06).get_offer_points(60, 0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_load['net_load'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
